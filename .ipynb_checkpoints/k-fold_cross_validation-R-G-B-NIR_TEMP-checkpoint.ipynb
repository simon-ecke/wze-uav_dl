{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1acdaa3",
   "metadata": {},
   "source": [
    "# WZE-UAV Image Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2159aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0026f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b160d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wze_uav.data_loader as data_loader\n",
    "import wze_uav.models as models\n",
    "from wze_uav.engine import *\n",
    "from wze_uav.utils2 import *\n",
    "from wze_uav.log_writer import create_writer\n",
    "from wze_uav.datasplit import *\n",
    "from efficientnet import model #for custom effnet with n_channels input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4fb2f",
   "metadata": {},
   "source": [
    "#### Get PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10886b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1+cu116\n",
      "torchvision version: 0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a83cf",
   "metadata": {},
   "source": [
    "#### Preparing device agnostic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d5de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Index of current divice: 0\n",
      "Number of GPUs available: 1\n",
      "GPU Model: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# ensure device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(f\"Index of current divice: {torch.cuda.current_device()}\")\n",
    "# get number of GPUs available\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "# get the name of the device\n",
    "print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6a34",
   "metadata": {},
   "source": [
    "#### Ensure reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information, see also: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds() \n",
    "\n",
    "# Set to true -> might speed up the process but should be set to False if reproducible results are desired\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be33671",
   "metadata": {},
   "source": [
    "#### Define file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30645f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# 3 channel input (r-g-b)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb\"\n",
    "\n",
    "# 4 channel input (r-g-b-nir)\n",
    "data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-nir\"\n",
    "\n",
    "# 5 channel input (r-g-b-re-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir\"\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560ce64",
   "metadata": {},
   "source": [
    "#### Get all file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa072e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = os.listdir(data_path)\n",
    "path_list = []\n",
    "# Iterate over all datafiles\n",
    "for year in fn_list:\n",
    "    year_dir = f'{data_path}\\\\{year}'\n",
    "    for filename in os.listdir(year_dir):\n",
    "        path = f'{year_dir}\\\\{filename}'\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3937a44",
   "metadata": {},
   "source": [
    "#### Create unique hash IDs for every individual tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a50f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67986fe21b9d47268e1f8a0ffa1f5b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating unique tree IDs...:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hashID_dict = data_loader.get_unique_treeID(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cea00",
   "metadata": {},
   "source": [
    "#### Import all imagery, labels and other features from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e3eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73f204c64d54dddb1eb2affbebffba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing hdf5 datasets:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_set, label_set, species_set, kkl_set, bk_set, hash_id = data_loader.hdf5_to_img_label_v2(path_list,\n",
    "                                                                                               hashID_dict,\n",
    "                                                                                               load_sets=[\"images_masked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90e2b7",
   "metadata": {},
   "source": [
    "#### Convert nbv to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0224972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = nbv_to_sst_3classes(label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4cd85",
   "metadata": {},
   "source": [
    "#### Split data and seperate a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06eda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7087 unique values within hash_id.\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (15973, 250, 250, 4)\n",
      "Labels train dataset: (15973, 1)\n",
      "\n",
      "Images test dataset: (2832, 250, 250, 4)\n",
      "Labels test dataset: (2832, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 14465\n",
      "Stressed trees in train dataset: 1240\n",
      "Dead trees in train dataset: 268\n",
      "Healthy trees in test dataset: 2551\n",
      "Stressed trees in test dataset: 237\n",
      "Dead trees in test dataset: 44\n",
      "Ratio health trees in test dataset: 0.1499177244945933\n",
      "Ratio stressed trees in test dataset: 0.16046039268788084\n",
      "Ratio dead trees in test dataset: 0.14102564102564102\n"
     ]
    }
   ],
   "source": [
    "image_set, label_set, hash_id, species_set, test_image_set, test_label_set, test_hash_id, test_species_set = data_split(image_set, label_set, hash_id, species_set, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fbb5b",
   "metadata": {},
   "source": [
    "#### Check if any hash ID is in both train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874367cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no hash_id values in both train and test datasets. The datasplit was successful\n"
     ]
    }
   ],
   "source": [
    "hash_set = set(hash_id.flatten())\n",
    "test_hash_set = set(test_hash_id.flatten())\n",
    "intersection = hash_set.intersection(test_hash_set)\n",
    "if intersection:\n",
    "    print(f\"Hash_id values in both train and test sets: {intersection}\")\n",
    "else:\n",
    "    print(\"There are no hash_id values in both train and test datasets. The datasplit was successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b64d4",
   "metadata": {},
   "source": [
    "#### Check feature distribution of the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33ff5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset\n",
      "Test data healthy trees: 2551\n",
      "Test data stressed trees: 237\n",
      "Test data dead trees: 44\n",
      "Test data pine trees: 755\n",
      "Test data spruces: 1041\n",
      "--------------------------------------------------\n",
      "Remaining dataset\n",
      "Remaining data healthy trees: 14465\n",
      "Remaining data stressed trees: 1240\n",
      "Remaining data dead trees: 268\n",
      "Remaining data pine trees: 4036\n",
      "Remaining data spruces: 5942\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences(data, value):\n",
    "    count = 0\n",
    "    for item in data:\n",
    "        if item == value:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"Test dataset\")\n",
    "print(f\"Test data healthy trees: {count_occurrences(test_label_set, 0)}\")\n",
    "print(f\"Test data stressed trees: {count_occurrences(test_label_set, 1)}\")\n",
    "print(f\"Test data dead trees: {count_occurrences(test_label_set, 2)}\")\n",
    "print(f\"Test data pine trees: {count_occurrences(test_species_set, 134)}\")\n",
    "print(f\"Test data spruces: {count_occurrences(test_species_set, 118)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Remaining dataset\")\n",
    "print(f\"Remaining data healthy trees: {count_occurrences(label_set, 0)}\")\n",
    "print(f\"Remaining data stressed trees: {count_occurrences(label_set, 1)}\")\n",
    "print(f\"Remaining data dead trees: {count_occurrences(label_set, 2)}\")\n",
    "print(f\"Remaining data pine trees: {count_occurrences(species_set, 134)}\")\n",
    "print(f\"Remaining data spruces: {count_occurrences(species_set, 118)}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08fcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train transform with augmentation. \n",
    "transform_train = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(degrees=[0,360])])\n",
    "\n",
    "# test and val dataset transform without augmentation. \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# class names need to fit the customDataset class used e.g. 3 classes -> use CustomDataset3Classes\n",
    "#class_names = ['healthy', 'slightly_stressed', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "#class_names = ['healthy', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "class_names = ['healthy', 'stressed', 'dead']\n",
    "\n",
    "# set seeds\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "NUM_WORKERS=3 # should be changed, depending on the system used\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31779c05",
   "metadata": {},
   "source": [
    "#### Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10ae4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Memory allocated: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "# 1. Define number of epochs\n",
    "epochs = 50\n",
    "n_bands = image_set[0].shape[2] # get number of bands\n",
    "\n",
    "# 2. Define model\n",
    "num_classes = len(class_names)\n",
    "unfreeze = True # all layer weights get updated\n",
    "dropout_rate = 0.45 #define dropout rate\n",
    "model_name = \"EffNet_b7_RGB-NIR_3classes\"\n",
    "\n",
    "# 3. Define loss, optimizer and learning rate scheduler\n",
    "lr = 0.0011 # define learning rate\n",
    "min_lr = 1e-5 # minimum learning rate threshold\n",
    "gamma = 0.85 # how fast the learning rate decreases per epoch (low number=faster decrease)\n",
    "patience = 10\n",
    "\n",
    "# 4. Create target folder name were to save the tensorboard event files\n",
    "\n",
    "experiment_name = 'RGB-NIR_3classes'\n",
    "extra = \"\"\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#torch.cuda.empty_cache()\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768b1a",
   "metadata": {},
   "source": [
    "#### Run k-Fold cross-validation on EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6023 unique values within hash_id.\n",
      "\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12770, 250, 250, 4)\n",
      "Labels train dataset: (12770, 1)\n",
      "\n",
      "Images validation dataset: (3203, 250, 250, 4)\n",
      "Labels validation dataset: (3203, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 11550\n",
      "Stressed trees in train dataset: 983\n",
      "Dead trees in train dataset: 237\n",
      "Healthy trees in validation dataset: 2915\n",
      "Stressed trees in validation dataset: 257\n",
      "Dead trees in validation dataset: 31\n",
      "Ratio health trees in validation dataset: 0.20152091254752852\n",
      "Ratio stressed trees in validation dataset: 0.20725806451612902\n",
      "Ratio dead trees in validation dataset: 0.11567164179104478\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 1\n",
      "\n",
      "Creating dataloaders for fold: 1\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 1\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 4\n",
      "[INFO] Dropout rate: 0.45\n",
      "[INFO] Gamma learning rate: 0.85\n",
      "[INFO] Created SummaryWriter, saving to: runs\\2023-04-10\\RGB-NIR_3classes\\EffNet_b7_RGB-NIR_3classes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa7aeb84f774e1e95703ca282ef3d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set the random seeds\n",
    "set_seeds(42)\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "unique_values = np.unique(hash_id) # now there are less unique values left because we seperated the test dataset\n",
    "num_unique = len(unique_values)\n",
    "print(f\"There are {num_unique} unique values within hash_id.\\n\")\n",
    "\n",
    "# Loop over each fold\n",
    "for fold, (train_ids, val_ids) in enumerate(kf.split(unique_values)):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # 1. Split data into train and validation set\n",
    "    # Get the training and testing data for this fold\n",
    "    # Use np.isin() to create boolean arrays indicating which indices belong to train or test sets\n",
    "    train_indices = np.isin(hash_id, unique_values[train_ids])\n",
    "    val_indices = np.isin(hash_id, unique_values[val_ids])\n",
    "    \n",
    "    # Reshape boolean arrays to match shape of image_set and label_set\n",
    "    train_indices = train_indices.reshape(-1, 1)\n",
    "    val_indices = val_indices.reshape(-1, 1)\n",
    "  \n",
    "    # Select images and labels for train and validation sets\n",
    "    train_image_set = image_set[train_indices[:, 0]]\n",
    "    train_label_set = label_set[train_indices[:, 0]]\n",
    "    train_hash_id = hash_id[train_indices[:, 0]]\n",
    "    train_species_set = species_set[train_indices[:, 0]]\n",
    "    val_image_set = image_set[val_indices[:, 0]]\n",
    "    val_label_set = label_set[val_indices[:, 0]]\n",
    "    val_hash_id = hash_id[val_indices[:, 0]]\n",
    "    val_species_set = species_set[val_indices[:, 0]]\n",
    "    train_label_set = train_label_set.reshape(-1, 1)\n",
    "    val_label_set = val_label_set.reshape(-1, 1)\n",
    "    train_hash_id = train_hash_id.reshape(-1, 1)\n",
    "    val_hash_id = val_hash_id.reshape(-1, 1)\n",
    "    train_species_set = train_species_set.reshape(-1, 1)\n",
    "    val_species_set = val_species_set.reshape(-1, 1)\n",
    "            \n",
    "    print(\"Check shapes:\\n\")\n",
    "    print(f\"Images train dataset: {train_image_set.shape}\")\n",
    "    print(f\"Labels train dataset: {train_label_set.shape}\\n\")\n",
    "    \n",
    "    print(f\"Images validation dataset: {val_image_set.shape}\")\n",
    "    print(f\"Labels validation dataset: {val_label_set.shape}\\n\")\n",
    "    print('-'*50)\n",
    "    print (f\"Check if the split was stratified: (random_state=42)\")\n",
    "    print(f\"Healthy trees in train dataset: {np.count_nonzero(train_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in train dataset: {np.count_nonzero(train_label_set == 1)}\")\n",
    "    print(f\"Dead trees in train dataset: {np.count_nonzero(train_label_set == 2)}\")\n",
    "    print(f\"Healthy trees in validation dataset: {np.count_nonzero(val_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)}\")\n",
    "    print(f\"Dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)}\")\n",
    "    print(f\"Ratio health trees in validation dataset: {np.count_nonzero(val_label_set == 0)/np.count_nonzero(label_set == 0)}\")\n",
    "    print(f\"Ratio stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)/np.count_nonzero(label_set == 1)}\")\n",
    "    print(f\"Ratio dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)/np.count_nonzero(label_set == 2)}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    \n",
    "    # 2. Create train and validation dataset. (choose custom dataset loader with 3 - 5 classes)\n",
    "    print(f\"\\nCreating datasets for fold: {fold + 1}\\n\")\n",
    "    train_dataset = data_loader.CustomDataset3Classes_v2(data=train_image_set, labels=train_label_set, class_names=class_names, species = train_species_set,\n",
    "                                                         transform=transform_train)\n",
    "    \n",
    "    val_dataset = data_loader.CustomDataset(data=val_image_set, labels=val_label_set, class_names=class_names,\n",
    "                                                       species = val_species_set, transform=transform)\n",
    "   \n",
    "    # 3. Create train and validation dataloader\n",
    "    # create sampler for oversampling of the minority classes\n",
    "    sampler = data_loader.data_sampler(dataset=train_dataset, class_names=class_names)\n",
    "    print(f\"Creating dataloaders for fold: {fold +1}\\n\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, generator=g,\n",
    "                              sampler=sampler, shuffle=False, drop_last=True) # shuffle false because of the sampler\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, shuffle=False,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    model = model.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    #lr_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    fold += 1\n",
    "    print(f\"\\n[INFO] Fold number: {fold}\")\n",
    "    print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "    print(f\"[INFO] Batch_size: {batch_size}\")\n",
    "    print(f\"[INFO] Number of bands: {n_bands}\")\n",
    "    print(f\"[INFO] Dropout rate: {dropout_rate}\")\n",
    "    print(f\"[INFO] Gamma learning rate: {gamma}\")\n",
    "    # 4. Train model with k fold dataloaders and track experiments\n",
    "    if fold == 1:\n",
    "        fold1_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(experiment_name=experiment_name, model_name=model_name, extra=extra), early_stop_patience = patience)\n",
    "       \n",
    "    elif fold == 2:\n",
    "        fold2_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(experiment_name=experiment_name, model_name=model_name, extra=extra), early_stop_patience = patience)\n",
    "    elif fold == 3:\n",
    "        fold3_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(experiment_name=experiment_name, model_name=model_name, extra=extra), early_stop_patience = patience)\n",
    "    elif fold == 4:\n",
    "        fold4_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(experiment_name=experiment_name, model_name=model_name, extra=extra), early_stop_patience = patience)\n",
    "    else:\n",
    "        fold5_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(experiment_name=experiment_name, model_name=model_name, extra=extra), early_stop_patience = patience)\n",
    "    \n",
    "    del train_indices, val_indices, train_image_set, train_label_set, train_hash_id, train_species_set, val_image_set, val_label_set, val_hash_id, val_species_set,\n",
    "    train_dataset, val_dataset, sampler, train_dataloader, val_dataloader, model, loss_fn, optimizer, lr_scheduler\n",
    "\n",
    "    print(\"Deleting variables and emptying cache\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\")\n",
    "    print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c36ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = data_loader.CustomDataset3Classes(\n",
    "    data = test_image_set,\n",
    "    labels = test_label_set,\n",
    "    class_names=class_names, \n",
    "    species = test_species_set,\n",
    "    kkl = test_kkl_set,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# create test dataloader\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             persistent_workers=True,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67db5af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnet_b0 model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the best model filepath\n",
    "best_model_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\effnet_b0\\01_18_epochs.pth\"\n",
    "\n",
    "# Instantiate a new instance of EffNetB0 (to load the saved state_dict() to)\n",
    "unfreeze=True\n",
    "best_model = models.create_effnetb0(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "\n",
    "# Load the saved best model state_dict()\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dfbc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, \n",
    "                     test_dataloader: torch.utils.data.DataLoader,\n",
    "                     device: torch.device):\n",
    "    # 1. Make predictions with trained model\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "            # Send data and targets to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Do the forward pass\n",
    "            y_logit = model(X)\n",
    "            # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "            y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "            # Put predictions on CPU for evaluation\n",
    "            y_preds.append(y_pred.cpu())\n",
    "            y_labels.append(y.cpu())\n",
    "            \n",
    "            #other metrics\n",
    "            test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "            y_pred_class = y_pred.detach().cpu().numpy() \n",
    "            y_class = y.detach().cpu().numpy()\n",
    "            labels = np.array([0])\n",
    "            test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "            \n",
    "            #if count >= 1:\n",
    "            #    y_set = torch.cat((y_set, y))\n",
    "            #    count = count + 1\n",
    "            #else:\n",
    "            #    y_set = y\n",
    "            #    count = count + 1\n",
    "            \n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "    test_precision = test_precision / len(test_dataloader)\n",
    "    test_recall = test_recall / len(test_dataloader)\n",
    "    test_f1_score = test_f1_score / len(test_dataloader)\n",
    "    #test_kappa = test_kappa / len(dataloader)\n",
    "    test_acc = test_acc / len(test_dataloader)\n",
    "    # Concatenate list of predictions into a tensor\n",
    "    y_pred_tensor = torch.cat(y_preds)\n",
    "    y_labels_tensor = torch.cat(y_labels)\n",
    "    test_f1_score = f1_score(y_labels_tensor.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=1, labels=[0,1,2])\n",
    "    \n",
    "    # Print classification report\n",
    "    y_true = y_labels_tensor.detach().cpu().numpy()\n",
    "    report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    return y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aab9e321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b3144341ab41f3b234434aa09299e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.95      0.88      0.92      2228\n",
      "    stressed       0.32      0.56      0.41       226\n",
      "        dead       0.84      0.86      0.85        42\n",
      "\n",
      "    accuracy                           0.85      2496\n",
      "   macro avg       0.70      0.77      0.72      2496\n",
      "weighted avg       0.89      0.85      0.87      2496\n",
      "\n",
      "Test loss: 0.0\n",
      "Test precision: 0.4154684139459786\n",
      "Test recall: 0.41671078506014464\n",
      "Test F1score: 0.7247865216737815\n",
      "Test Accuracy: 0.8525641025641025\n",
      "Test Logits: tensor([[ 1.7014,  0.8877, -5.1889],\n",
      "        [ 2.3632,  0.8889, -6.1630],\n",
      "        [ 2.2219,  0.9962, -6.0906],\n",
      "        [-0.6744,  0.1306,  0.6790],\n",
      "        [ 0.9584,  1.0023, -4.1342],\n",
      "        [ 1.1653,  0.9413, -4.2456],\n",
      "        [ 1.9196,  1.0043, -5.6535],\n",
      "        [ 0.5722,  0.7214, -2.7888],\n",
      "        [ 2.0116,  1.1527, -6.1480],\n",
      "        [ 2.0599,  1.0727, -6.0320],\n",
      "        [ 2.1480,  0.9218, -5.8122],\n",
      "        [ 1.8820,  0.8687, -5.2790],\n",
      "        [ 1.5475,  1.0596, -5.1709],\n",
      "        [ 1.8884,  0.9385, -5.4567],\n",
      "        [ 1.7652,  1.0623, -5.5407],\n",
      "        [ 1.1063,  0.8732, -4.0481]], device='cuda:0')\n",
      "Test Predictions: tensor([0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Test Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "#from wze_uav.analysis import *\n",
    "y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds = make_predictions(model=best_model,\n",
    "                                 test_dataloader=test_dataloader, \n",
    "                                 device=device)\n",
    "\n",
    "y_labels_tensor = y_labels_tensor.detach().cpu().numpy()\n",
    "y_pred_tensor = y_pred_tensor.detach().cpu().numpy()\n",
    "\n",
    "#confmat = ConfusionMatrix(num_classes=num_classes, task='multiclass')\n",
    "#confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "#                         target=test_labels)\n",
    "labels = np.array([0,1,2])\n",
    "confmat = confusion_matrix(y_labels_tensor, y_pred_tensor, labels=labels)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat, # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test recall: {test_recall}\")\n",
    "print(f\"Test F1score: {test_f1_score}\")\n",
    "#print(f\"Test Kappa: {test_kappa}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Logits: {y_logit}\")\n",
    "print(f\"Test Predictions: {y_pred}\")\n",
    "print(f\"Test Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d4173b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7588116f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_set\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_set' is not defined"
     ]
    }
   ],
   "source": [
    "y_set.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c195b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6da05604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a223988f3a8b4b2eae8b8b3b3f7776de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.94      0.90      0.92      2228\n",
      "    stressed       0.42      0.31      0.35       226\n",
      "        dead       0.19      0.83      0.32        42\n",
      "\n",
      "    accuracy                           0.85      2496\n",
      "   macro avg       0.52      0.68      0.53      2496\n",
      "weighted avg       0.88      0.85      0.86      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "y_labels = []\n",
    "labels = np.array([0,1,2])\n",
    "test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "count = 0\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logit = model(X)\n",
    "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_labels.append(y.cpu())\n",
    "        \n",
    "        #other metrics\n",
    "        test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "        y_pred_class = y_pred.detach().cpu().numpy() \n",
    "        y_class = y.detach().cpu().numpy()\n",
    "        test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        \n",
    "        #if count >= 1:\n",
    "        #    y_set = torch.cat((y_set, y))\n",
    "        #    count = count + 1\n",
    "        #else:\n",
    "        #    y_set = y\n",
    "        #    count = count + 1\n",
    "        \n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_precision = test_precision / len(test_dataloader)\n",
    "test_recall = test_recall / len(test_dataloader)\n",
    "#test_f1_score = test_f1_score / len(test_dataloader)\n",
    "#test_kappa = test_kappa / len(dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "test_f1_score = f1_score(y_set.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=0, labels=[0,1,2])\n",
    "\n",
    "# Print classification report\n",
    "y_true = y_set.detach().cpu().numpy()\n",
    "report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ae97fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528680154128826"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ebafd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make = (y_class == y_pred_class)\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f8aa759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(y_logit, dim=1).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f90a54b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a806154",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (y_pred == y).sum().item()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1da35c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_class = y_pred.detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "602e096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
