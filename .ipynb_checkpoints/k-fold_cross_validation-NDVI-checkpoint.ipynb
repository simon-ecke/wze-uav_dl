{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1acdaa3",
   "metadata": {},
   "source": [
    "# WZE-UAV Image Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2159aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0026f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b160d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wze_uav.data_loader as data_loader\n",
    "import wze_uav.models as models\n",
    "from wze_uav.engine import *\n",
    "from wze_uav.utils2 import *\n",
    "#from wze_uav.log_writer import create_writer\n",
    "from wze_uav.datasplit import *\n",
    "from efficientnet import model_effnet #for custom effnet with n_channels input\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4fb2f",
   "metadata": {},
   "source": [
    "#### Get PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10886b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1+cu116\n",
      "torchvision version: 0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a83cf",
   "metadata": {},
   "source": [
    "#### Preparing device agnostic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d5de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Index of current divice: 0\n",
      "Number of GPUs available: 1\n",
      "GPU Model: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# ensure device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(f\"Index of current divice: {torch.cuda.current_device()}\")\n",
    "# get number of GPUs available\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "# get the name of the device\n",
    "print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6b169",
   "metadata": {},
   "source": [
    "#### Login to Weights & Biases to track results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59d27cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimon-ecke\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230420_184807-5bjq8mix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5bjq8mix' target=\"_blank\">avid-voice-34</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5bjq8mix' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/5bjq8mix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5bjq8mix?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x252ac1dc670>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: The proxy needs to be set in anaconda!\n",
    "# copy paste this in anaconda and restart jupyter notebook\n",
    "#set http_proxy=http://www-proxy.bayern.de:80\n",
    "#set https_proxy=http://www-proxy.bayern.de:80\n",
    "wandb.login()\n",
    "#wandb.init(settings=wandb.Settings(start_method=\"thread\"))\n",
    "wandb.init(project='wze-uav-v2', entity='simon-ecke')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6a34",
   "metadata": {},
   "source": [
    "#### Ensure reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information, see also: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(42) \n",
    "\n",
    "# Set to true -> might speed up the process but should be set to False if reproducible results are desired\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be33671",
   "metadata": {},
   "source": [
    "#### Define file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30645f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# 3 channel input (r-g-b)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb\"\n",
    "\n",
    "# 4 channel input (r-g-b-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-nir\"\n",
    "\n",
    "# 5 channel input (r-g-b-re-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir\"\n",
    "\n",
    "# 6 channel input (r-g-b-re-nir-chm)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir-chm\"\n",
    "\n",
    "# 9 channel input (r-g-b-re-nir-chm)\n",
    "data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir-ndvi-ndre-grvi-evi\"\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560ce64",
   "metadata": {},
   "source": [
    "#### Get all file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa072e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = os.listdir(data_path)\n",
    "path_list = []\n",
    "# Iterate over all datafiles\n",
    "for year in fn_list:\n",
    "    year_dir = f'{data_path}\\\\{year}'\n",
    "    for filename in os.listdir(year_dir):\n",
    "        path = f'{year_dir}\\\\{filename}'\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3937a44",
   "metadata": {},
   "source": [
    "#### Create unique hash IDs for every individual tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a50f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7062e68816e5449a9964f68b3e90aa11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating unique tree IDs...:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hashID_dict = data_loader.get_unique_treeID(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cea00",
   "metadata": {},
   "source": [
    "#### Import all imagery, labels and other features from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e3eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3f950c895043c5bdaf90a1b0f519a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing hdf5 datasets:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_set, label_set, species_set, kkl_set, bk_set, hash_id = data_loader.hdf5_to_img_label(path_list,\n",
    "                                                                                               hashID_dict,\n",
    "                                                                                               load_sets=[\"images_masked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90e2b7",
   "metadata": {},
   "source": [
    "#### Convert nbv to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0224972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = nbv_to_sst_3classes(label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4cd85",
   "metadata": {},
   "source": [
    "#### Split data into a sub set and a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d06eda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL POSITIVE RATIO: 0.42823717096516883\n",
      "Fold : 0\n",
      "TRAIN POSITIVE RATIO: 0.4286353181702019\n",
      "TEST POSITIVE RATIO : 0.4262607040913416\n",
      "LENGTH TRAIN GROUPS : 5900\n",
      "LENGTH TEST GROUPS  : 1187\n",
      "Number of True in sub_indices: 15652\n",
      "Number of False in sub_indices: 3153\n",
      "Number of True in test_indices: 1187\n",
      "Number of False in test_indices: 17618\n",
      "Check shapes:\n",
      "\n",
      "Images sub dataset: (15652, 250, 250, 9)\n",
      "Labels sub dataset: (15652, 1)\n",
      "\n",
      "Images test dataset: (1187, 250, 250, 9)\n",
      "Labels test dataset: (1187, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in sub dataset: 9208\n",
      "Stressed trees in sub dataset: 6179\n",
      "Dead trees in sub dataset: 265\n",
      "Healthy trees in test dataset: 685\n",
      "Stressed trees in test dataset: 483\n",
      "Dead trees in test dataset: 19\n",
      "Ratio health trees in test dataset: 0.07439183318853171\n",
      "Ratio stressed trees in test dataset: 0.07816798834762907\n",
      "Ratio dead trees in test dataset: 0.07169811320754717\n"
     ]
    }
   ],
   "source": [
    "sub_image_set, sub_label_set, sub_hash_id, sub_species_set, test_image_set, test_label_set, test_hash_id, test_species_set = data_split(image_set, label_set, hash_id, species_set, n_splits=6, random_state=42, seed=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fbb5b",
   "metadata": {},
   "source": [
    "#### Check if any hash ID is in both sub and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874367cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no hash_id values in both train and test datasets. The datasplit was successful\n"
     ]
    }
   ],
   "source": [
    "hash_set = set(sub_hash_id[:,0].flatten())\n",
    "test_hash_set = set(test_hash_id[:,0].flatten())\n",
    "intersection = hash_set.intersection(test_hash_set)\n",
    "if intersection:\n",
    "    print(f\"Hash_id values in both train and test sets: {len(intersection)}\")\n",
    "else:\n",
    "    print(\"There are no hash_id values in both train and test datasets. The datasplit was successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b64d4",
   "metadata": {},
   "source": [
    "#### Check feature distribution of the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a33ff5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset\n",
      "Test data healthy trees: 685\n",
      "Test data stressed trees: 483\n",
      "Test data dead trees: 19\n",
      "Test data pine trees: 301\n",
      "Test data spruces: 468\n",
      "--------------------------------------------------\n",
      "Remaining dataset\n",
      "Remaining data healthy trees: 9208\n",
      "Remaining data stressed trees: 6179\n",
      "Remaining data dead trees: 265\n",
      "Remaining data pine trees: 3958\n",
      "Remaining data spruces: 5791\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences(data, value):\n",
    "    count = 0\n",
    "    for item in data:\n",
    "        if item == value:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"Test dataset\")\n",
    "print(f\"Test data healthy trees: {count_occurrences(test_label_set, 0)}\")\n",
    "print(f\"Test data stressed trees: {count_occurrences(test_label_set, 1)}\")\n",
    "print(f\"Test data dead trees: {count_occurrences(test_label_set, 2)}\")\n",
    "print(f\"Test data pine trees: {count_occurrences(test_species_set, 134)}\")\n",
    "print(f\"Test data spruces: {count_occurrences(test_species_set, 118)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Remaining dataset\")\n",
    "print(f\"Remaining data healthy trees: {count_occurrences(sub_label_set, 0)}\")\n",
    "print(f\"Remaining data stressed trees: {count_occurrences(sub_label_set, 1)}\")\n",
    "print(f\"Remaining data dead trees: {count_occurrences(sub_label_set, 2)}\")\n",
    "print(f\"Remaining data pine trees: {count_occurrences(sub_species_set, 134)}\")\n",
    "print(f\"Remaining data spruces: {count_occurrences(sub_species_set, 118)}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e08fcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train transform with augmentation. \n",
    "transform_train = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(degrees=[0,360])])\n",
    "\n",
    "# test and val dataset transform without augmentation. \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# class names need to fit the customDataset class used e.g. 3 classes -> use CustomDataset3Classes\n",
    "#class_names = ['healthy', 'slightly_stressed', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "#class_names = ['healthy', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "class_names = ['healthy', 'stressed', 'dead']\n",
    "\n",
    "# set seeds\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "NUM_WORKERS=3 # should be changed, depending on the system used\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31779c05",
   "metadata": {},
   "source": [
    "#### Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ae4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cf6a10daa14a268af536f6dc6dbe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-voice-34</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5bjq8mix' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/5bjq8mix</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230420_184807-5bjq8mix\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Define number of epochs\n",
    "epochs = 50\n",
    "n_bands = sub_image_set[0].shape[2] # get number of bands\n",
    "\n",
    "# 2. Define model\n",
    "num_classes = len(class_names)\n",
    "unfreeze = True # all layer weights get updated\n",
    "dropout_rate = 0.5 #define dropout rate\n",
    "model_name = \"EffNet_b7_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes\"\n",
    "\n",
    "# 3. Define loss, optimizer and learning rate scheduler\n",
    "lr = 0.005 # define learning rate\n",
    "min_lr = 1e-6 # minimum learning rate threshold\n",
    "gamma = 0.75 # how fast the learning rate decreases per epoch (low number=faster decrease)\n",
    "patience = 10\n",
    "\n",
    "# 4. Create target folder name were to save the tensorboard event files\n",
    "experiment_name = 'RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes'\n",
    "extra = \"RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes\"\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#torch.cuda.empty_cache()\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\") \n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768b1a",
   "metadata": {},
   "source": [
    "#### Run k-Fold cross-validation on EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c29c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL POSITIVE RATIO: 0.4286353181702019\n",
      "Fold : 1\n",
      "TRAIN POSITIVE RATIO: 0.43211854225070084\n",
      "VAL POSITIVE RATIO  : 0.41490369434796337\n",
      "LENGTH TRAIN GROUPS : 4710\n",
      "LENGTH VAL GROUPS   : 1190\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230420_203622-2x8ffhq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/2x8ffhq3' target=\"_blank\">fold_1_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/2x8ffhq3' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/2x8ffhq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12485, 250, 250, 9)\n",
      "Labels train dataset: (12485, 1)\n",
      "\n",
      "Images validation dataset: (1190, 250, 250, 9)\n",
      "Labels validation dataset: (1190, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 7285\n",
      "Stressed trees in train dataset: 5005\n",
      "Dead trees in train dataset: 195\n",
      "Healthy trees in validation dataset: 724\n",
      "Stressed trees in validation dataset: 437\n",
      "Dead trees in validation dataset: 29\n",
      "Ratio health trees in validation dataset: 0.078627280625543\n",
      "Ratio stressed trees in validation dataset: 0.07072341802880724\n",
      "Ratio dead trees in validation dataset: 0.10943396226415095\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 1\n",
      "\n",
      "Creating dataloaders for fold: 1\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 1\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 9\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6f31e3a1c34e709059473583e8e204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.005\n",
      "Train loss: 0.7935 | Train precision: 0.5045 | Train recall: 0.4408 | Train f1score: 0.4630 | Train acc: 0.5208 | Train kappa: 0.1261 \n",
      "Val loss: 2.2767 | Val precision: 0.3669 | Val recall: 0.3398 | Val f1score: 0.2814 | Val acc: 0.6064 | Val kappa: 0.0121 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00375\n",
      "Train loss: 0.6833 | Train precision: 0.6558 | Train recall: 0.6381 | Train f1score: 0.6460 | Train acc: 0.6327 | Train kappa: 0.3799 \n",
      "Val loss: 0.7123 | Val precision: 0.6037 | Val recall: 0.6960 | Val f1score: 0.6203 | Val acc: 0.6081 | Val kappa: 0.3763 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0028125\n",
      "Train loss: 0.6540 | Train precision: 0.7036 | Train recall: 0.6918 | Train f1score: 0.6975 | Train acc: 0.6491 | Train kappa: 0.4235 \n",
      "Val loss: 0.7019 | Val precision: 0.7481 | Val recall: 0.6485 | Val f1score: 0.6409 | Val acc: 0.5701 | Val kappa: 0.3075 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.002109375\n",
      "Train loss: 0.6350 | Train precision: 0.7166 | Train recall: 0.7155 | Train f1score: 0.7157 | Train acc: 0.6533 | Train kappa: 0.4278 \n",
      "Val loss: 0.9921 | Val precision: 0.3961 | Val recall: 0.3589 | Val f1score: 0.2573 | Val acc: 0.4274 | Val kappa: 0.0697 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00158203125\n",
      "Train loss: 0.6250 | Train precision: 0.7316 | Train recall: 0.7157 | Train f1score: 0.7230 | Train acc: 0.6572 | Train kappa: 0.4382 \n",
      "Val loss: 0.6050 | Val precision: 0.7056 | Val recall: 0.7108 | Val f1score: 0.7077 | Val acc: 0.6850 | Val kappa: 0.4494 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0011865234375\n",
      "Train loss: 0.6164 | Train precision: 0.7365 | Train recall: 0.7244 | Train f1score: 0.7301 | Train acc: 0.6694 | Train kappa: 0.4578 \n",
      "Val loss: 0.6058 | Val precision: 0.7135 | Val recall: 0.7069 | Val f1score: 0.7088 | Val acc: 0.6850 | Val kappa: 0.4486 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000889892578125\n",
      "Train loss: 0.6028 | Train precision: 0.7450 | Train recall: 0.7420 | Train f1score: 0.7435 | Train acc: 0.6789 | Train kappa: 0.4738 \n",
      "Val loss: 0.6754 | Val precision: 0.7312 | Val recall: 0.7374 | Val f1score: 0.7031 | Val acc: 0.6208 | Val kappa: 0.3931 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00066741943359375\n",
      "Train loss: 0.6082 | Train precision: 0.7424 | Train recall: 0.7323 | Train f1score: 0.7367 | Train acc: 0.6682 | Train kappa: 0.4592 \n",
      "Val loss: 0.6009 | Val precision: 0.7187 | Val recall: 0.6931 | Val f1score: 0.7041 | Val acc: 0.6816 | Val kappa: 0.4386 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0005005645751953125\n",
      "Train loss: 0.5906 | Train precision: 0.7574 | Train recall: 0.7570 | Train f1score: 0.7569 | Train acc: 0.6870 | Train kappa: 0.4988 \n",
      "Val loss: 0.6366 | Val precision: 0.7256 | Val recall: 0.7176 | Val f1score: 0.7000 | Val acc: 0.6343 | Val kappa: 0.4042 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0003754234313964844\n",
      "Train loss: 0.5949 | Train precision: 0.7542 | Train recall: 0.7465 | Train f1score: 0.7500 | Train acc: 0.6791 | Train kappa: 0.4784 \n",
      "Val loss: 0.6076 | Val precision: 0.7184 | Val recall: 0.7111 | Val f1score: 0.7144 | Val acc: 0.6723 | Val kappa: 0.4368 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.0002815675735473633\n",
      "Train loss: 0.5918 | Train precision: 0.7528 | Train recall: 0.7501 | Train f1score: 0.7513 | Train acc: 0.6812 | Train kappa: 0.4903 \n",
      "Val loss: 0.6116 | Val precision: 0.7246 | Val recall: 0.7213 | Val f1score: 0.7153 | Val acc: 0.6613 | Val kappa: 0.4344 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00021117568016052246\n",
      "Train loss: 0.5881 | Train precision: 0.7604 | Train recall: 0.7553 | Train f1score: 0.7576 | Train acc: 0.6843 | Train kappa: 0.4816 \n",
      "Val loss: 0.6187 | Val precision: 0.7185 | Val recall: 0.7056 | Val f1score: 0.7052 | Val acc: 0.6571 | Val kappa: 0.4240 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015838176012039184\n",
      "Train loss: 0.5886 | Train precision: 0.7590 | Train recall: 0.7480 | Train f1score: 0.7528 | Train acc: 0.6875 | Train kappa: 0.4826 \n",
      "Val loss: 0.6077 | Val precision: 0.7232 | Val recall: 0.7101 | Val f1score: 0.7129 | Val acc: 0.6715 | Val kappa: 0.4429 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.00011878632009029388\n",
      "Train loss: 0.5869 | Train precision: 0.7448 | Train recall: 0.7518 | Train f1score: 0.7480 | Train acc: 0.6792 | Train kappa: 0.4728 \n",
      "Val loss: 0.6572 | Val precision: 0.7196 | Val recall: 0.6990 | Val f1score: 0.6815 | Val acc: 0.6166 | Val kappa: 0.3785 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 8.908974006772042e-05\n",
      "Train loss: 0.5843 | Train precision: 0.7576 | Train recall: 0.7527 | Train f1score: 0.7549 | Train acc: 0.6869 | Train kappa: 0.4967 \n",
      "Val loss: 0.6400 | Val precision: 0.7165 | Val recall: 0.7107 | Val f1score: 0.6981 | Val acc: 0.6326 | Val kappa: 0.3963 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 6.681730505079031e-05\n",
      "Train loss: 0.5806 | Train precision: 0.7585 | Train recall: 0.7618 | Train f1score: 0.7599 | Train acc: 0.6908 | Train kappa: 0.5021 \n",
      "Val loss: 0.6157 | Val precision: 0.7276 | Val recall: 0.7244 | Val f1score: 0.7170 | Val acc: 0.6630 | Val kappa: 0.4388 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 5.0112978788092735e-05\n",
      "Train loss: 0.5870 | Train precision: 0.7611 | Train recall: 0.7647 | Train f1score: 0.7622 | Train acc: 0.6855 | Train kappa: 0.4848 \n",
      "Val loss: 0.6181 | Val precision: 0.7181 | Val recall: 0.7051 | Val f1score: 0.7032 | Val acc: 0.6529 | Val kappa: 0.4193 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 3.758473409106955e-05\n",
      "Train loss: 0.5805 | Train precision: 0.7641 | Train recall: 0.7652 | Train f1score: 0.7642 | Train acc: 0.6909 | Train kappa: 0.4952 \n",
      "Val loss: 0.6194 | Val precision: 0.7176 | Val recall: 0.7044 | Val f1score: 0.7022 | Val acc: 0.6512 | Val kappa: 0.4170 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 2.8188550568302163e-05\n",
      "Train loss: 0.5832 | Train precision: 0.7677 | Train recall: 0.7629 | Train f1score: 0.7649 | Train acc: 0.6859 | Train kappa: 0.4921 \n",
      "Val loss: 0.6221 | Val precision: 0.7238 | Val recall: 0.7295 | Val f1score: 0.7167 | Val acc: 0.6529 | Val kappa: 0.4252 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 2.114141292622662e-05\n",
      "Train loss: 0.5798 | Train precision: 0.7555 | Train recall: 0.7628 | Train f1score: 0.7583 | Train acc: 0.6889 | Train kappa: 0.4911 \n",
      "Val loss: 0.6207 | Val precision: 0.7242 | Val recall: 0.7302 | Val f1score: 0.7186 | Val acc: 0.6562 | Val kappa: 0.4292 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 1.5856059694669965e-05\n",
      "Train loss: 0.5844 | Train precision: 0.7568 | Train recall: 0.7613 | Train f1score: 0.7587 | Train acc: 0.6901 | Train kappa: 0.4862 \n",
      "Val loss: 0.6117 | Val precision: 0.7245 | Val recall: 0.7119 | Val f1score: 0.7130 | Val acc: 0.6698 | Val kappa: 0.4427 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 1.1892044771002475e-05\n",
      "Train loss: 0.5766 | Train precision: 0.7660 | Train recall: 0.7634 | Train f1score: 0.7644 | Train acc: 0.6950 | Train kappa: 0.4963 \n",
      "Val loss: 0.6155 | Val precision: 0.7231 | Val recall: 0.7105 | Val f1score: 0.7099 | Val acc: 0.6639 | Val kappa: 0.4353 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 8.919033578251857e-06\n",
      "Train loss: 0.5793 | Train precision: 0.7642 | Train recall: 0.7632 | Train f1score: 0.7634 | Train acc: 0.6878 | Train kappa: 0.4951 \n",
      "Val loss: 0.6188 | Val precision: 0.7246 | Val recall: 0.7213 | Val f1score: 0.7153 | Val acc: 0.6613 | Val kappa: 0.4344 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 6.689275183688892e-06\n",
      "Train loss: 0.5743 | Train precision: 0.7688 | Train recall: 0.7654 | Train f1score: 0.7669 | Train acc: 0.6949 | Train kappa: 0.4988 \n",
      "Val loss: 0.6150 | Val precision: 0.7259 | Val recall: 0.7227 | Val f1score: 0.7176 | Val acc: 0.6655 | Val kappa: 0.4400 \n",
      "\n",
      "Epoch: 25 \n",
      "Learning rate: 5.016956387766669e-06\n",
      "Train loss: 0.5787 | Train precision: 0.7597 | Train recall: 0.7604 | Train f1score: 0.7600 | Train acc: 0.6913 | Train kappa: 0.4924 \n",
      "Val loss: 0.6162 | Val precision: 0.7231 | Val recall: 0.7105 | Val f1score: 0.7099 | Val acc: 0.6639 | Val kappa: 0.4353 \n",
      "\n",
      "Epoch: 26 \n",
      "Learning rate: 3.762717290825002e-06\n",
      "Train loss: 0.5835 | Train precision: 0.7537 | Train recall: 0.7568 | Train f1score: 0.7550 | Train acc: 0.6868 | Train kappa: 0.4852 \n",
      "Val loss: 0.6157 | Val precision: 0.7256 | Val recall: 0.7224 | Val f1score: 0.7175 | Val acc: 0.6655 | Val kappa: 0.4397 \n",
      "\n",
      "Epoch: 27 \n",
      "Learning rate: 2.8220379681187514e-06\n",
      "Train loss: 0.5823 | Train precision: 0.7603 | Train recall: 0.7532 | Train f1score: 0.7566 | Train acc: 0.6877 | Train kappa: 0.4971 \n",
      "Val loss: 0.6141 | Val precision: 0.7253 | Val recall: 0.7221 | Val f1score: 0.7174 | Val acc: 0.6655 | Val kappa: 0.4394 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      "Learning rate: 2.1165284760890633e-06\n",
      "Train loss: 0.5831 | Train precision: 0.7597 | Train recall: 0.7628 | Train f1score: 0.7612 | Train acc: 0.6881 | Train kappa: 0.4902 \n",
      "Val loss: 0.6195 | Val precision: 0.7242 | Val recall: 0.7209 | Val f1score: 0.7147 | Val acc: 0.6605 | Val kappa: 0.4331 \n",
      "\n",
      "Epoch: 29 \n",
      "Learning rate: 1.5873963570667977e-06\n",
      "Train loss: 0.5839 | Train precision: 0.7528 | Train recall: 0.7526 | Train f1score: 0.7526 | Train acc: 0.6859 | Train kappa: 0.4862 \n",
      "Val loss: 0.6181 | Val precision: 0.7234 | Val recall: 0.7108 | Val f1score: 0.7093 | Val acc: 0.6622 | Val kappa: 0.4338 \n",
      "\n",
      "Epoch: 30 \n",
      "Learning rate: 1.1905472678000981e-06\n",
      "Train loss: 0.5817 | Train precision: 0.7550 | Train recall: 0.7632 | Train f1score: 0.7588 | Train acc: 0.6889 | Train kappa: 0.4887 \n",
      "Val loss: 0.6180 | Val precision: 0.7230 | Val recall: 0.7103 | Val f1score: 0.7087 | Val acc: 0.6613 | Val kappa: 0.4325 \n",
      "\n",
      "Early stopping after epoch 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▅▆▇▇▇▇▇██████████████████████</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1_score</td><td>▁▇▇▁█████████▇████████████████</td></tr><tr><td>val_loss</td><td>█▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_f1_score</td><td>0.75884</td></tr><tr><td>train_loss</td><td>0.58173</td></tr><tr><td>val_f1_score</td><td>0.70872</td></tr><tr><td>val_loss</td><td>0.61797</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_1_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/2x8ffhq3' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/2x8ffhq3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230420_203622-2x8ffhq3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1047233536 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 2\n",
      "TRAIN POSITIVE RATIO: 0.4259363220787553\n",
      "VAL POSITIVE RATIO  : 0.43920829406220546\n",
      "LENGTH TRAIN GROUPS : 4712\n",
      "LENGTH VAL GROUPS   : 1188\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230420_232600-fog6kysx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/fog6kysx' target=\"_blank\">fold_2_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/fog6kysx' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/fog6kysx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12469, 250, 250, 9)\n",
      "Labels train dataset: (12469, 1)\n",
      "\n",
      "Images validation dataset: (1188, 250, 250, 9)\n",
      "Labels validation dataset: (1188, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 7359\n",
      "Stressed trees in train dataset: 4909\n",
      "Dead trees in train dataset: 201\n",
      "Healthy trees in validation dataset: 660\n",
      "Stressed trees in validation dataset: 502\n",
      "Dead trees in validation dataset: 26\n",
      "Ratio health trees in validation dataset: 0.07167680278019113\n",
      "Ratio stressed trees in validation dataset: 0.08124291956627286\n",
      "Ratio dead trees in validation dataset: 0.09811320754716982\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 2\n",
      "\n",
      "Creating dataloaders for fold: 2\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 2\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 9\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f2eda849214ccbbc02ccb3aa9c8b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.005\n",
      "Train loss: 0.7942 | Train precision: 0.5353 | Train recall: 0.4629 | Train f1score: 0.4883 | Train acc: 0.5356 | Train kappa: 0.1701 \n",
      "Val loss: 1.1534 | Val precision: 0.1410 | Val recall: 0.3333 | Val f1score: 0.1982 | Val acc: 0.4231 | Val kappa: 0.0000 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00375\n",
      "Train loss: 0.6865 | Train precision: 0.6613 | Train recall: 0.6393 | Train f1score: 0.6490 | Train acc: 0.6087 | Train kappa: 0.3571 \n",
      "Val loss: 0.9110 | Val precision: 0.4008 | Val recall: 0.3344 | Val f1score: 0.2114 | Val acc: 0.4274 | Val kappa: 0.0176 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0028125\n",
      "Train loss: 0.6582 | Train precision: 0.6935 | Train recall: 0.6828 | Train f1score: 0.6874 | Train acc: 0.6412 | Train kappa: 0.4087 \n",
      "Val loss: 0.6501 | Val precision: 0.4368 | Val recall: 0.4478 | Val f1score: 0.4412 | Val acc: 0.6579 | Val kappa: 0.3650 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.002109375\n",
      "Train loss: 0.6434 | Train precision: 0.6939 | Train recall: 0.6987 | Train f1score: 0.6955 | Train acc: 0.6440 | Train kappa: 0.4213 \n",
      "Val loss: 0.7689 | Val precision: 0.4497 | Val recall: 0.3963 | Val f1score: 0.3341 | Val acc: 0.5338 | Val kappa: 0.1779 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00158203125\n",
      "Train loss: 0.6262 | Train precision: 0.7231 | Train recall: 0.7186 | Train f1score: 0.7206 | Train acc: 0.6584 | Train kappa: 0.4440 \n",
      "Val loss: 0.6200 | Val precision: 0.7555 | Val recall: 0.6509 | Val f1score: 0.6918 | Val acc: 0.6723 | Val kappa: 0.4167 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0011865234375\n",
      "Train loss: 0.6164 | Train precision: 0.7313 | Train recall: 0.7234 | Train f1score: 0.7270 | Train acc: 0.6627 | Train kappa: 0.4521 \n",
      "Val loss: 0.6223 | Val precision: 0.7153 | Val recall: 0.6910 | Val f1score: 0.6491 | Val acc: 0.6292 | Val kappa: 0.3384 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000889892578125\n",
      "Train loss: 0.6148 | Train precision: 0.7264 | Train recall: 0.7243 | Train f1score: 0.7253 | Train acc: 0.6646 | Train kappa: 0.4584 \n",
      "Val loss: 0.6227 | Val precision: 0.7476 | Val recall: 0.7704 | Val f1score: 0.7517 | Val acc: 0.6706 | Val kappa: 0.4399 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00066741943359375\n",
      "Train loss: 0.5986 | Train precision: 0.7478 | Train recall: 0.7452 | Train f1score: 0.7463 | Train acc: 0.6721 | Train kappa: 0.4687 \n",
      "Val loss: 0.6733 | Val precision: 0.7566 | Val recall: 0.7171 | Val f1score: 0.6742 | Val acc: 0.5802 | Val kappa: 0.3107 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0005005645751953125\n",
      "Train loss: 0.6077 | Train precision: 0.7451 | Train recall: 0.7429 | Train f1score: 0.7434 | Train acc: 0.6718 | Train kappa: 0.4605 \n",
      "Val loss: 0.6673 | Val precision: 0.7554 | Val recall: 0.7410 | Val f1score: 0.7034 | Val acc: 0.6039 | Val kappa: 0.3479 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0003754234313964844\n",
      "Train loss: 0.5969 | Train precision: 0.7521 | Train recall: 0.7502 | Train f1score: 0.7511 | Train acc: 0.6811 | Train kappa: 0.4987 \n",
      "Val loss: 0.5945 | Val precision: 0.7511 | Val recall: 0.7392 | Val f1score: 0.7295 | Val acc: 0.6647 | Val kappa: 0.4138 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.0002815675735473633\n",
      "Train loss: 0.5899 | Train precision: 0.7636 | Train recall: 0.7573 | Train f1score: 0.7603 | Train acc: 0.6826 | Train kappa: 0.4957 \n",
      "Val loss: 0.5884 | Val precision: 0.7605 | Val recall: 0.7719 | Val f1score: 0.7661 | Val acc: 0.6892 | Val kappa: 0.4666 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00021117568016052246\n",
      "Train loss: 0.5998 | Train precision: 0.7509 | Train recall: 0.7478 | Train f1score: 0.7489 | Train acc: 0.6736 | Train kappa: 0.4772 \n",
      "Val loss: 0.5906 | Val precision: 0.7554 | Val recall: 0.7688 | Val f1score: 0.7609 | Val acc: 0.6782 | Val kappa: 0.4508 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015838176012039184\n",
      "Train loss: 0.5914 | Train precision: 0.7596 | Train recall: 0.7571 | Train f1score: 0.7581 | Train acc: 0.6824 | Train kappa: 0.4876 \n",
      "Val loss: 0.6279 | Val precision: 0.7560 | Val recall: 0.7609 | Val f1score: 0.7403 | Val acc: 0.6470 | Val kappa: 0.4120 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.00011878632009029388\n",
      "Train loss: 0.5846 | Train precision: 0.7717 | Train recall: 0.7680 | Train f1score: 0.7698 | Train acc: 0.6906 | Train kappa: 0.5041 \n",
      "Val loss: 0.5949 | Val precision: 0.7544 | Val recall: 0.7674 | Val f1score: 0.7603 | Val acc: 0.6782 | Val kappa: 0.4499 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 8.908974006772042e-05\n",
      "Train loss: 0.5884 | Train precision: 0.7612 | Train recall: 0.7531 | Train f1score: 0.7569 | Train acc: 0.6853 | Train kappa: 0.4861 \n",
      "Val loss: 0.5970 | Val precision: 0.7571 | Val recall: 0.7705 | Val f1score: 0.7626 | Val acc: 0.6807 | Val kappa: 0.4551 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 6.681730505079031e-05\n",
      "Train loss: 0.5886 | Train precision: 0.7670 | Train recall: 0.7627 | Train f1score: 0.7648 | Train acc: 0.6906 | Train kappa: 0.5048 \n",
      "Val loss: 0.5901 | Val precision: 0.7511 | Val recall: 0.7625 | Val f1score: 0.7567 | Val acc: 0.6757 | Val kappa: 0.4436 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 5.0112978788092735e-05\n",
      "Train loss: 0.5905 | Train precision: 0.7590 | Train recall: 0.7556 | Train f1score: 0.7570 | Train acc: 0.6853 | Train kappa: 0.4891 \n",
      "Val loss: 0.5949 | Val precision: 0.7562 | Val recall: 0.7697 | Val f1score: 0.7609 | Val acc: 0.6774 | Val kappa: 0.4504 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 3.758473409106955e-05\n",
      "Train loss: 0.5924 | Train precision: 0.7537 | Train recall: 0.7525 | Train f1score: 0.7528 | Train acc: 0.6845 | Train kappa: 0.4854 \n",
      "Val loss: 0.6026 | Val precision: 0.7564 | Val recall: 0.7684 | Val f1score: 0.7556 | Val acc: 0.6681 | Val kappa: 0.4424 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 2.8188550568302163e-05\n",
      "Train loss: 0.5850 | Train precision: 0.7679 | Train recall: 0.7576 | Train f1score: 0.7622 | Train acc: 0.6876 | Train kappa: 0.4948 \n",
      "Val loss: 0.5953 | Val precision: 0.7626 | Val recall: 0.7762 | Val f1score: 0.7673 | Val acc: 0.6867 | Val kappa: 0.4661 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 2.114141292622662e-05\n",
      "Train loss: 0.5918 | Train precision: 0.7599 | Train recall: 0.7556 | Train f1score: 0.7574 | Train acc: 0.6822 | Train kappa: 0.4836 \n",
      "Val loss: 0.6012 | Val precision: 0.7613 | Val recall: 0.7738 | Val f1score: 0.7618 | Val acc: 0.6774 | Val kappa: 0.4574 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 1.5856059694669965e-05\n",
      "Train loss: 0.5872 | Train precision: 0.7589 | Train recall: 0.7539 | Train f1score: 0.7559 | Train acc: 0.6826 | Train kappa: 0.4816 \n",
      "Val loss: 0.5961 | Val precision: 0.7634 | Val recall: 0.7770 | Val f1score: 0.7671 | Val acc: 0.6858 | Val kappa: 0.4656 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 1.1892044771002475e-05\n",
      "Train loss: 0.5788 | Train precision: 0.7643 | Train recall: 0.7656 | Train f1score: 0.7647 | Train acc: 0.6960 | Train kappa: 0.5045 \n",
      "Val loss: 0.5985 | Val precision: 0.7627 | Val recall: 0.7761 | Val f1score: 0.7656 | Val acc: 0.6833 | Val kappa: 0.4619 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 8.919033578251857e-06\n",
      "Train loss: 0.5890 | Train precision: 0.7589 | Train recall: 0.7509 | Train f1score: 0.7546 | Train acc: 0.6853 | Train kappa: 0.4861 \n",
      "Val loss: 0.6007 | Val precision: 0.7633 | Val recall: 0.7760 | Val f1score: 0.7641 | Val acc: 0.6807 | Val kappa: 0.4630 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 6.689275183688892e-06\n",
      "Train loss: 0.5860 | Train precision: 0.7543 | Train recall: 0.7526 | Train f1score: 0.7532 | Train acc: 0.6819 | Train kappa: 0.4847 \n",
      "Val loss: 0.6016 | Val precision: 0.7631 | Val recall: 0.7758 | Val f1score: 0.7641 | Val acc: 0.6807 | Val kappa: 0.4629 \n",
      "\n",
      "Epoch: 25 \n",
      "Learning rate: 5.016956387766669e-06\n",
      "Train loss: 0.5868 | Train precision: 0.7581 | Train recall: 0.7642 | Train f1score: 0.7606 | Train acc: 0.6881 | Train kappa: 0.4868 \n",
      "Val loss: 0.5991 | Val precision: 0.7616 | Val recall: 0.7747 | Val f1score: 0.7639 | Val acc: 0.6807 | Val kappa: 0.4622 \n",
      "\n",
      "Epoch: 26 \n",
      "Learning rate: 3.762717290825002e-06\n",
      "Train loss: 0.5980 | Train precision: 0.7572 | Train recall: 0.7446 | Train f1score: 0.7505 | Train acc: 0.6791 | Train kappa: 0.4769 \n",
      "Val loss: 0.5982 | Val precision: 0.7607 | Val recall: 0.7741 | Val f1score: 0.7638 | Val acc: 0.6807 | Val kappa: 0.4574 \n",
      "\n",
      "Epoch: 27 \n",
      "Learning rate: 2.8220379681187514e-06\n",
      "Train loss: 0.5822 | Train precision: 0.7594 | Train recall: 0.7515 | Train f1score: 0.7552 | Train acc: 0.6828 | Train kappa: 0.4905 \n",
      "Val loss: 0.5988 | Val precision: 0.7629 | Val recall: 0.7763 | Val f1score: 0.7656 | Val acc: 0.6833 | Val kappa: 0.4620 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      "Learning rate: 2.1165284760890633e-06\n",
      "Train loss: 0.5905 | Train precision: 0.7675 | Train recall: 0.7503 | Train f1score: 0.7585 | Train acc: 0.6841 | Train kappa: 0.4892 \n",
      "Val loss: 0.5989 | Val precision: 0.7611 | Val recall: 0.7744 | Val f1score: 0.7639 | Val acc: 0.6807 | Val kappa: 0.4576 \n",
      "\n",
      "Epoch: 29 \n",
      "Learning rate: 1.5873963570667977e-06\n",
      "Train loss: 0.5945 | Train precision: 0.7519 | Train recall: 0.7553 | Train f1score: 0.7533 | Train acc: 0.6808 | Train kappa: 0.4843 \n",
      "Val loss: 0.5989 | Val precision: 0.7609 | Val recall: 0.7743 | Val f1score: 0.7638 | Val acc: 0.6807 | Val kappa: 0.4575 \n",
      "\n",
      "Early stopping after epoch 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▅▆▆▇▇▇▇▇██▇█████████████████</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂</td></tr><tr><td>val_f1_score</td><td>▁▁▄▃▇▇█▇▇████████████████████</td></tr><tr><td>val_loss</td><td>█▅▂▃▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_f1_score</td><td>0.75333</td></tr><tr><td>train_loss</td><td>0.59447</td></tr><tr><td>val_f1_score</td><td>0.76383</td></tr><tr><td>val_loss</td><td>0.59886</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_2_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/fog6kysx' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/fog6kysx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230420_232600-fog6kysx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1052938752 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 3\n",
      "TRAIN POSITIVE RATIO: 0.42986172168491726\n",
      "VAL POSITIVE RATIO  : 0.42375039796243236\n",
      "LENGTH TRAIN GROUPS : 4713\n",
      "LENGTH VAL GROUPS   : 1187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230421_020437-5arudpuo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5arudpuo' target=\"_blank\">fold_3_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5arudpuo' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/5arudpuo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12511, 250, 250, 9)\n",
      "Labels train dataset: (12511, 1)\n",
      "\n",
      "Images validation dataset: (1187, 250, 250, 9)\n",
      "Labels validation dataset: (1187, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 7352\n",
      "Stressed trees in train dataset: 4940\n",
      "Dead trees in train dataset: 219\n",
      "Healthy trees in validation dataset: 691\n",
      "Stressed trees in validation dataset: 472\n",
      "Dead trees in validation dataset: 24\n",
      "Ratio health trees in validation dataset: 0.07504344048653346\n",
      "Ratio stressed trees in validation dataset: 0.0763877650105195\n",
      "Ratio dead trees in validation dataset: 0.09056603773584905\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 3\n",
      "\n",
      "Creating dataloaders for fold: 3\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 3\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 9\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a58d6b928cc49929e111fc1c8fe704b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.005\n",
      "Train loss: 0.7868 | Train precision: 0.5466 | Train recall: 0.4880 | Train f1score: 0.5110 | Train acc: 0.5352 | Train kappa: 0.1838 \n",
      "Val loss: 1.2257 | Val precision: 0.2095 | Val recall: 0.4962 | Val f1score: 0.2946 | Val acc: 0.3885 | Val kappa: 0.0636 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00375\n",
      "Train loss: 0.6819 | Train precision: 0.6699 | Train recall: 0.6471 | Train f1score: 0.6575 | Train acc: 0.6151 | Train kappa: 0.3738 \n",
      "Val loss: 0.6708 | Val precision: 0.5980 | Val recall: 0.6087 | Val f1score: 0.5904 | Val acc: 0.5895 | Val kappa: 0.2451 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0028125\n",
      "Train loss: 0.6557 | Train precision: 0.7115 | Train recall: 0.6898 | Train f1score: 0.6997 | Train acc: 0.6373 | Train kappa: 0.4108 \n",
      "Val loss: 1.2781 | Val precision: 0.4359 | Val recall: 0.6147 | Val f1score: 0.3268 | Val acc: 0.3902 | Val kappa: 0.2027 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.002109375\n",
      "Train loss: 0.6375 | Train precision: 0.7252 | Train recall: 0.7114 | Train f1score: 0.7178 | Train acc: 0.6567 | Train kappa: 0.4509 \n",
      "Val loss: 0.6077 | Val precision: 0.7134 | Val recall: 0.6941 | Val f1score: 0.7008 | Val acc: 0.6748 | Val kappa: 0.4223 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00158203125\n",
      "Train loss: 0.6255 | Train precision: 0.7235 | Train recall: 0.7279 | Train f1score: 0.7252 | Train acc: 0.6567 | Train kappa: 0.4448 \n",
      "Val loss: 0.6049 | Val precision: 0.7332 | Val recall: 0.6641 | Val f1score: 0.6921 | Val acc: 0.6655 | Val kappa: 0.4121 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0011865234375\n",
      "Train loss: 0.6181 | Train precision: 0.7345 | Train recall: 0.7230 | Train f1score: 0.7285 | Train acc: 0.6647 | Train kappa: 0.4607 \n",
      "Val loss: 0.6716 | Val precision: 0.6734 | Val recall: 0.7235 | Val f1score: 0.6720 | Val acc: 0.6233 | Val kappa: 0.3804 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000889892578125\n",
      "Train loss: 0.6161 | Train precision: 0.7368 | Train recall: 0.7268 | Train f1score: 0.7316 | Train acc: 0.6638 | Train kappa: 0.4642 \n",
      "Val loss: 0.6499 | Val precision: 0.6921 | Val recall: 0.7408 | Val f1score: 0.6966 | Val acc: 0.6343 | Val kappa: 0.3929 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00066741943359375\n",
      "Train loss: 0.6111 | Train precision: 0.7461 | Train recall: 0.7383 | Train f1score: 0.7418 | Train acc: 0.6651 | Train kappa: 0.4644 \n",
      "Val loss: 0.5947 | Val precision: 0.7392 | Val recall: 0.6937 | Val f1score: 0.7127 | Val acc: 0.6689 | Val kappa: 0.4223 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0005005645751953125\n",
      "Train loss: 0.6021 | Train precision: 0.7535 | Train recall: 0.7493 | Train f1score: 0.7509 | Train acc: 0.6728 | Train kappa: 0.4670 \n",
      "Val loss: 0.6111 | Val precision: 0.7130 | Val recall: 0.7572 | Val f1score: 0.7330 | Val acc: 0.6883 | Val kappa: 0.4625 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0003754234313964844\n",
      "Train loss: 0.5896 | Train precision: 0.7620 | Train recall: 0.7581 | Train f1score: 0.7592 | Train acc: 0.6821 | Train kappa: 0.4917 \n",
      "Val loss: 0.6620 | Val precision: 0.6873 | Val recall: 0.7397 | Val f1score: 0.6853 | Val acc: 0.6258 | Val kappa: 0.3813 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.0002815675735473633\n",
      "Train loss: 0.5952 | Train precision: 0.7554 | Train recall: 0.7519 | Train f1score: 0.7530 | Train acc: 0.6800 | Train kappa: 0.4873 \n",
      "Val loss: 0.6293 | Val precision: 0.7013 | Val recall: 0.7528 | Val f1score: 0.7120 | Val acc: 0.6571 | Val kappa: 0.4269 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00021117568016052246\n",
      "Train loss: 0.5859 | Train precision: 0.7631 | Train recall: 0.7562 | Train f1score: 0.7589 | Train acc: 0.6874 | Train kappa: 0.5030 \n",
      "Val loss: 0.5902 | Val precision: 0.7017 | Val recall: 0.7629 | Val f1score: 0.7284 | Val acc: 0.6959 | Val kappa: 0.4792 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015838176012039184\n",
      "Train loss: 0.5888 | Train precision: 0.7624 | Train recall: 0.7656 | Train f1score: 0.7637 | Train acc: 0.6848 | Train kappa: 0.4953 \n",
      "Val loss: 0.6113 | Val precision: 0.7316 | Val recall: 0.7330 | Val f1score: 0.7213 | Val acc: 0.6495 | Val kappa: 0.4084 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.00011878632009029388\n",
      "Train loss: 0.5942 | Train precision: 0.7564 | Train recall: 0.7501 | Train f1score: 0.7529 | Train acc: 0.6786 | Train kappa: 0.4814 \n",
      "Val loss: 0.5905 | Val precision: 0.7201 | Val recall: 0.7566 | Val f1score: 0.7340 | Val acc: 0.6774 | Val kappa: 0.4526 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 8.908974006772042e-05\n",
      "Train loss: 0.5917 | Train precision: 0.7525 | Train recall: 0.7455 | Train f1score: 0.7486 | Train acc: 0.6808 | Train kappa: 0.4864 \n",
      "Val loss: 0.6054 | Val precision: 0.7071 | Val recall: 0.7522 | Val f1score: 0.7209 | Val acc: 0.6639 | Val kappa: 0.4317 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 6.681730505079031e-05\n",
      "Train loss: 0.5897 | Train precision: 0.7615 | Train recall: 0.7523 | Train f1score: 0.7564 | Train acc: 0.6834 | Train kappa: 0.4948 \n",
      "Val loss: 0.5938 | Val precision: 0.7099 | Val recall: 0.7557 | Val f1score: 0.7283 | Val acc: 0.6774 | Val kappa: 0.4492 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 5.0112978788092735e-05\n",
      "Train loss: 0.5875 | Train precision: 0.7558 | Train recall: 0.7599 | Train f1score: 0.7574 | Train acc: 0.6851 | Train kappa: 0.5018 \n",
      "Val loss: 0.5889 | Val precision: 0.7313 | Val recall: 0.7572 | Val f1score: 0.7425 | Val acc: 0.6841 | Val kappa: 0.4588 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 3.758473409106955e-05\n",
      "Train loss: 0.5824 | Train precision: 0.7624 | Train recall: 0.7577 | Train f1score: 0.7600 | Train acc: 0.6880 | Train kappa: 0.5058 \n",
      "Val loss: 0.5958 | Val precision: 0.7229 | Val recall: 0.7596 | Val f1score: 0.7354 | Val acc: 0.6782 | Val kappa: 0.4517 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 2.8188550568302163e-05\n",
      "Train loss: 0.5892 | Train precision: 0.7588 | Train recall: 0.7552 | Train f1score: 0.7567 | Train acc: 0.6800 | Train kappa: 0.4908 \n",
      "Val loss: 0.5927 | Val precision: 0.7257 | Val recall: 0.7624 | Val f1score: 0.7401 | Val acc: 0.6867 | Val kappa: 0.4634 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 2.114141292622662e-05\n",
      "Train loss: 0.5819 | Train precision: 0.7622 | Train recall: 0.7620 | Train f1score: 0.7620 | Train acc: 0.6900 | Train kappa: 0.5085 \n",
      "Val loss: 0.5915 | Val precision: 0.7243 | Val recall: 0.7607 | Val f1score: 0.7398 | Val acc: 0.6875 | Val kappa: 0.4628 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 1.5856059694669965e-05\n",
      "Train loss: 0.5796 | Train precision: 0.7629 | Train recall: 0.7684 | Train f1score: 0.7653 | Train acc: 0.6906 | Train kappa: 0.5112 \n",
      "Val loss: 0.5988 | Val precision: 0.7193 | Val recall: 0.7556 | Val f1score: 0.7306 | Val acc: 0.6706 | Val kappa: 0.4401 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 1.1892044771002475e-05\n",
      "Train loss: 0.5799 | Train precision: 0.7630 | Train recall: 0.7661 | Train f1score: 0.7643 | Train acc: 0.6876 | Train kappa: 0.5007 \n",
      "Val loss: 0.5874 | Val precision: 0.7250 | Val recall: 0.7610 | Val f1score: 0.7409 | Val acc: 0.6900 | Val kappa: 0.4659 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 8.919033578251857e-06\n",
      "Train loss: 0.5798 | Train precision: 0.7723 | Train recall: 0.7588 | Train f1score: 0.7652 | Train acc: 0.6877 | Train kappa: 0.5068 \n",
      "Val loss: 0.5897 | Val precision: 0.7257 | Val recall: 0.7617 | Val f1score: 0.7415 | Val acc: 0.6909 | Val kappa: 0.4675 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 6.689275183688892e-06\n",
      "Train loss: 0.5860 | Train precision: 0.7663 | Train recall: 0.7615 | Train f1score: 0.7638 | Train acc: 0.6829 | Train kappa: 0.4983 \n",
      "Val loss: 0.5894 | Val precision: 0.7285 | Val recall: 0.7648 | Val f1score: 0.7442 | Val acc: 0.6943 | Val kappa: 0.4738 \n",
      "\n",
      "Epoch: 25 \n",
      "Learning rate: 5.016956387766669e-06\n",
      "Train loss: 0.5870 | Train precision: 0.7592 | Train recall: 0.7593 | Train f1score: 0.7591 | Train acc: 0.6840 | Train kappa: 0.5011 \n",
      "Val loss: 0.5881 | Val precision: 0.7236 | Val recall: 0.7594 | Val f1score: 0.7395 | Val acc: 0.6883 | Val kappa: 0.4627 \n",
      "\n",
      "Epoch: 26 \n",
      "Learning rate: 3.762717290825002e-06\n",
      "Train loss: 0.5837 | Train precision: 0.7652 | Train recall: 0.7623 | Train f1score: 0.7636 | Train acc: 0.6907 | Train kappa: 0.5041 \n",
      "Val loss: 0.5918 | Val precision: 0.7260 | Val recall: 0.7625 | Val f1score: 0.7412 | Val acc: 0.6892 | Val kappa: 0.4663 \n",
      "\n",
      "Epoch: 27 \n",
      "Learning rate: 2.8220379681187514e-06\n",
      "Train loss: 0.5850 | Train precision: 0.7597 | Train recall: 0.7646 | Train f1score: 0.7619 | Train acc: 0.6866 | Train kappa: 0.4936 \n",
      "Val loss: 0.5893 | Val precision: 0.7280 | Val recall: 0.7643 | Val f1score: 0.7436 | Val acc: 0.6934 | Val kappa: 0.4724 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      "Learning rate: 2.1165284760890633e-06\n",
      "Train loss: 0.5875 | Train precision: 0.7596 | Train recall: 0.7498 | Train f1score: 0.7544 | Train acc: 0.6800 | Train kappa: 0.4868 \n",
      "Val loss: 0.5932 | Val precision: 0.7242 | Val recall: 0.7609 | Val f1score: 0.7385 | Val acc: 0.6841 | Val kappa: 0.4593 \n",
      "\n",
      "Epoch: 29 \n",
      "Learning rate: 1.5873963570667977e-06\n",
      "Train loss: 0.5851 | Train precision: 0.7579 | Train recall: 0.7624 | Train f1score: 0.7600 | Train acc: 0.6857 | Train kappa: 0.5008 \n",
      "Val loss: 0.5910 | Val precision: 0.7254 | Val recall: 0.7620 | Val f1score: 0.7403 | Val acc: 0.6875 | Val kappa: 0.4639 \n",
      "\n",
      "Epoch: 30 \n",
      "Learning rate: 1.1905472678000981e-06\n",
      "Train loss: 0.5900 | Train precision: 0.7572 | Train recall: 0.7519 | Train f1score: 0.7541 | Train acc: 0.6844 | Train kappa: 0.4881 \n",
      "Val loss: 0.5922 | Val precision: 0.7255 | Val recall: 0.7622 | Val f1score: 0.7401 | Val acc: 0.6867 | Val kappa: 0.4632 \n",
      "\n",
      "Epoch: 31 \n",
      "Learning rate: 1e-06\n",
      "Train loss: 0.5871 | Train precision: 0.7596 | Train recall: 0.7580 | Train f1score: 0.7586 | Train acc: 0.6811 | Train kappa: 0.4897 \n",
      "Val loss: 0.5917 | Val precision: 0.7258 | Val recall: 0.7624 | Val f1score: 0.7405 | Val acc: 0.6875 | Val kappa: 0.4643 \n",
      "\n",
      "Epoch: 32 \n",
      "Learning rate: 1e-06\n",
      "Train loss: 0.5792 | Train precision: 0.7638 | Train recall: 0.7610 | Train f1score: 0.7622 | Train acc: 0.6896 | Train kappa: 0.5075 \n",
      "Val loss: 0.5910 | Val precision: 0.7261 | Val recall: 0.7627 | Val f1score: 0.7410 | Val acc: 0.6883 | Val kappa: 0.4655 \n",
      "\n",
      "Epoch: 33 \n",
      "Learning rate: 1e-06\n",
      "Train loss: 0.5863 | Train precision: 0.7627 | Train recall: 0.7577 | Train f1score: 0.7598 | Train acc: 0.6885 | Train kappa: 0.5041 \n",
      "Val loss: 0.5920 | Val precision: 0.7241 | Val recall: 0.7608 | Val f1score: 0.7388 | Val acc: 0.6850 | Val kappa: 0.4601 \n",
      "\n",
      "Epoch: 34 \n",
      "Learning rate: 1e-06\n",
      "Train loss: 0.5826 | Train precision: 0.7686 | Train recall: 0.7596 | Train f1score: 0.7639 | Train acc: 0.6907 | Train kappa: 0.5066 \n",
      "Val loss: 0.5912 | Val precision: 0.7256 | Val recall: 0.7622 | Val f1score: 0.7404 | Val acc: 0.6875 | Val kappa: 0.4641 \n",
      "\n",
      "Early stopping after epoch 34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14b0fbdf72b4715ae3f31e233e0ca6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▅▆▇▇▇▇▇██████████████████████████</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1_score</td><td>▁▆▂▇▇▇▇██▇▇███████████████████████</td></tr><tr><td>val_loss</td><td>▇▂█▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_f1_score</td><td>0.76385</td></tr><tr><td>train_loss</td><td>0.58255</td></tr><tr><td>val_f1_score</td><td>0.74043</td></tr><tr><td>val_loss</td><td>0.59123</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_3_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/5arudpuo' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/5arudpuo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230421_020437-5arudpuo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1054061056 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 4\n",
      "TRAIN POSITIVE RATIO: 0.42982176957352003\n",
      "VAL POSITIVE RATIO  : 0.42380025940337224\n",
      "LENGTH TRAIN GROUPS : 4733\n",
      "LENGTH VAL GROUPS   : 1167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230421_051111-ckqbrupt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/ckqbrupt' target=\"_blank\">fold_4_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/ckqbrupt' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/ckqbrupt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12568, 250, 250, 9)\n",
      "Labels train dataset: (12568, 1)\n",
      "\n",
      "Images validation dataset: (1167, 250, 250, 9)\n",
      "Labels validation dataset: (1167, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 7387\n",
      "Stressed trees in train dataset: 4960\n",
      "Dead trees in train dataset: 221\n",
      "Healthy trees in validation dataset: 685\n",
      "Stressed trees in validation dataset: 464\n",
      "Dead trees in validation dataset: 18\n",
      "Ratio health trees in validation dataset: 0.07439183318853171\n",
      "Ratio stressed trees in validation dataset: 0.07509305712898527\n",
      "Ratio dead trees in validation dataset: 0.06792452830188679\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 4\n",
      "\n",
      "Creating dataloaders for fold: 4\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 4\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 9\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f21b9e917743f5a36c21774359fb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.005\n",
      "Train loss: 0.7802 | Train precision: 0.4982 | Train recall: 0.4521 | Train f1score: 0.4686 | Train acc: 0.5554 | Train kappa: 0.2101 \n",
      "Val loss: 0.8692 | Val precision: 0.6697 | Val recall: 0.5127 | Val f1score: 0.4435 | Val acc: 0.4635 | Val kappa: 0.1224 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00375\n",
      "Train loss: 0.7011 | Train precision: 0.6288 | Train recall: 0.5948 | Train f1score: 0.6100 | Train acc: 0.6063 | Train kappa: 0.3415 \n",
      "Val loss: 4.0793 | Val precision: 0.3587 | Val recall: 0.3659 | Val f1score: 0.0610 | Val acc: 0.0556 | Val kappa: 0.0216 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0028125\n",
      "Train loss: 0.6630 | Train precision: 0.6842 | Train recall: 0.6684 | Train f1score: 0.6759 | Train acc: 0.6322 | Train kappa: 0.4073 \n",
      "Val loss: 0.6382 | Val precision: 0.6670 | Val recall: 0.7328 | Val f1score: 0.6900 | Val acc: 0.6493 | Val kappa: 0.3846 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.002109375\n",
      "Train loss: 0.6444 | Train precision: 0.7000 | Train recall: 0.6824 | Train f1score: 0.6906 | Train acc: 0.6484 | Train kappa: 0.4246 \n",
      "Val loss: 0.8739 | Val precision: 0.5748 | Val recall: 0.7010 | Val f1score: 0.5441 | Val acc: 0.5599 | Val kappa: 0.3012 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00158203125\n",
      "Train loss: 0.6358 | Train precision: 0.7226 | Train recall: 0.7038 | Train f1score: 0.7124 | Train acc: 0.6489 | Train kappa: 0.4283 \n",
      "Val loss: 0.6109 | Val precision: 0.7302 | Val recall: 0.6947 | Val f1score: 0.7017 | Val acc: 0.6693 | Val kappa: 0.3768 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0011865234375\n",
      "Train loss: 0.6269 | Train precision: 0.7309 | Train recall: 0.7167 | Train f1score: 0.7231 | Train acc: 0.6574 | Train kappa: 0.4554 \n",
      "Val loss: 0.7302 | Val precision: 0.7491 | Val recall: 0.7049 | Val f1score: 0.6484 | Val acc: 0.5547 | Val kappa: 0.2692 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000889892578125\n",
      "Train loss: 0.6154 | Train precision: 0.7424 | Train recall: 0.7290 | Train f1score: 0.7352 | Train acc: 0.6629 | Train kappa: 0.4614 \n",
      "Val loss: 0.6158 | Val precision: 0.7769 | Val recall: 0.5461 | Val f1score: 0.6007 | Val acc: 0.6806 | Val kappa: 0.3745 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00066741943359375\n",
      "Train loss: 0.6070 | Train precision: 0.7414 | Train recall: 0.7394 | Train f1score: 0.7403 | Train acc: 0.6657 | Train kappa: 0.4708 \n",
      "Val loss: 0.6850 | Val precision: 0.7639 | Val recall: 0.6894 | Val f1score: 0.6515 | Val acc: 0.5599 | Val kappa: 0.2715 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0005005645751953125\n",
      "Train loss: 0.6099 | Train precision: 0.7477 | Train recall: 0.7333 | Train f1score: 0.7401 | Train acc: 0.6687 | Train kappa: 0.4735 \n",
      "Val loss: 0.6609 | Val precision: 0.7043 | Val recall: 0.7386 | Val f1score: 0.6883 | Val acc: 0.6033 | Val kappa: 0.3341 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0003754234313964844\n",
      "Train loss: 0.5947 | Train precision: 0.7555 | Train recall: 0.7500 | Train f1score: 0.7525 | Train acc: 0.6783 | Train kappa: 0.4911 \n",
      "Val loss: 0.5895 | Val precision: 0.7552 | Val recall: 0.7659 | Val f1score: 0.7592 | Val acc: 0.7014 | Val kappa: 0.4550 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.0002815675735473633\n",
      "Train loss: 0.5943 | Train precision: 0.7585 | Train recall: 0.7495 | Train f1score: 0.7539 | Train acc: 0.6806 | Train kappa: 0.4985 \n",
      "Val loss: 0.6164 | Val precision: 0.6885 | Val recall: 0.7585 | Val f1score: 0.7137 | Val acc: 0.6615 | Val kappa: 0.4139 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00021117568016052246\n",
      "Train loss: 0.5951 | Train precision: 0.7581 | Train recall: 0.7498 | Train f1score: 0.7538 | Train acc: 0.6831 | Train kappa: 0.4949 \n",
      "Val loss: 0.6074 | Val precision: 0.7287 | Val recall: 0.7624 | Val f1score: 0.7359 | Val acc: 0.6615 | Val kappa: 0.4121 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015838176012039184\n",
      "Train loss: 0.5928 | Train precision: 0.7582 | Train recall: 0.7521 | Train f1score: 0.7550 | Train acc: 0.6811 | Train kappa: 0.4931 \n",
      "Val loss: 0.5985 | Val precision: 0.7720 | Val recall: 0.7215 | Val f1score: 0.7396 | Val acc: 0.6615 | Val kappa: 0.3963 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.00011878632009029388\n",
      "Train loss: 0.5866 | Train precision: 0.7602 | Train recall: 0.7483 | Train f1score: 0.7537 | Train acc: 0.6817 | Train kappa: 0.4867 \n",
      "Val loss: 0.6020 | Val precision: 0.7395 | Val recall: 0.7433 | Val f1score: 0.7357 | Val acc: 0.6649 | Val kappa: 0.4103 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 8.908974006772042e-05\n",
      "Train loss: 0.5906 | Train precision: 0.7621 | Train recall: 0.7523 | Train f1score: 0.7569 | Train acc: 0.6783 | Train kappa: 0.4866 \n",
      "Val loss: 0.6012 | Val precision: 0.7402 | Val recall: 0.7442 | Val f1score: 0.7380 | Val acc: 0.6693 | Val kappa: 0.4155 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 6.681730505079031e-05\n",
      "Train loss: 0.5901 | Train precision: 0.7522 | Train recall: 0.7469 | Train f1score: 0.7495 | Train acc: 0.6781 | Train kappa: 0.4773 \n",
      "Val loss: 0.6118 | Val precision: 0.7461 | Val recall: 0.7648 | Val f1score: 0.7447 | Val acc: 0.6623 | Val kappa: 0.4135 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 5.0112978788092735e-05\n",
      "Train loss: 0.5873 | Train precision: 0.7616 | Train recall: 0.7516 | Train f1score: 0.7565 | Train acc: 0.6783 | Train kappa: 0.4899 \n",
      "Val loss: 0.6033 | Val precision: 0.7453 | Val recall: 0.7652 | Val f1score: 0.7481 | Val acc: 0.6684 | Val kappa: 0.4199 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 3.758473409106955e-05\n",
      "Train loss: 0.5870 | Train precision: 0.7568 | Train recall: 0.7496 | Train f1score: 0.7528 | Train acc: 0.6821 | Train kappa: 0.5005 \n",
      "Val loss: 0.5907 | Val precision: 0.7438 | Val recall: 0.7475 | Val f1score: 0.7439 | Val acc: 0.6806 | Val kappa: 0.4306 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 2.8188550568302163e-05\n",
      "Train loss: 0.5959 | Train precision: 0.7522 | Train recall: 0.7464 | Train f1score: 0.7490 | Train acc: 0.6751 | Train kappa: 0.4822 \n",
      "Val loss: 0.5969 | Val precision: 0.7381 | Val recall: 0.7261 | Val f1score: 0.7269 | Val acc: 0.6675 | Val kappa: 0.4117 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 2.114141292622662e-05\n",
      "Train loss: 0.5880 | Train precision: 0.7657 | Train recall: 0.7538 | Train f1score: 0.7594 | Train acc: 0.6827 | Train kappa: 0.4930 \n",
      "Val loss: 0.5960 | Val precision: 0.7386 | Val recall: 0.7266 | Val f1score: 0.7279 | Val acc: 0.6693 | Val kappa: 0.4140 \n",
      "\n",
      "Early stopping after epoch 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8440c05736e842d8acb0693b133b9e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▄▆▆▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1_score</td><td>▅▁▇▆▇▇▆▇▇███████████</td></tr><tr><td>val_loss</td><td>▂█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_f1_score</td><td>0.75938</td></tr><tr><td>train_loss</td><td>0.58805</td></tr><tr><td>val_f1_score</td><td>0.72788</td></tr><tr><td>val_loss</td><td>0.59602</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_4_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/ckqbrupt' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/ckqbrupt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230421_051111-ckqbrupt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1055650304 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 5\n",
      "TRAIN POSITIVE RATIO: 0.4254473161033797\n",
      "VAL POSITIVE RATIO  : 0.44166395840103995\n",
      "LENGTH TRAIN GROUPS : 4732\n",
      "LENGTH VAL GROUPS   : 1168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230421_070220-8r6ktmdm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/8r6ktmdm' target=\"_blank\">fold_5_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-v2' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/8r6ktmdm' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/8r6ktmdm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12575, 250, 250, 9)\n",
      "Labels train dataset: (12575, 1)\n",
      "\n",
      "Images validation dataset: (1169, 250, 250, 9)\n",
      "Labels validation dataset: (1169, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 7449\n",
      "Stressed trees in train dataset: 4902\n",
      "Dead trees in train dataset: 224\n",
      "Healthy trees in validation dataset: 672\n",
      "Stressed trees in validation dataset: 480\n",
      "Dead trees in validation dataset: 17\n",
      "Ratio health trees in validation dataset: 0.07298001737619461\n",
      "Ratio stressed trees in validation dataset: 0.07768247289205372\n",
      "Ratio dead trees in validation dataset: 0.06415094339622641\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 5\n",
      "\n",
      "Creating dataloaders for fold: 5\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 5\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 9\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c392721c80441458c4060ff49a38a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.005\n",
      "Train loss: 0.7893 | Train precision: 0.5471 | Train recall: 0.5016 | Train f1score: 0.5207 | Train acc: 0.5371 | Train kappa: 0.1936 \n",
      "Val loss: 0.7248 | Val precision: 0.6502 | Val recall: 0.5198 | Val f1score: 0.5450 | Val acc: 0.6076 | Val kappa: 0.2235 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00375\n",
      "Train loss: 0.6905 | Train precision: 0.6544 | Train recall: 0.6257 | Train f1score: 0.6387 | Train acc: 0.6114 | Train kappa: 0.3584 \n",
      "Val loss: 1.0248 | Val precision: 0.4147 | Val recall: 0.3745 | Val f1score: 0.3141 | Val acc: 0.5747 | Val kappa: 0.0539 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0028125\n",
      "Train loss: 0.6543 | Train precision: 0.7075 | Train recall: 0.6902 | Train f1score: 0.6982 | Train acc: 0.6460 | Train kappa: 0.4243 \n",
      "Val loss: 0.6570 | Val precision: 0.7292 | Val recall: 0.7435 | Val f1score: 0.7177 | Val acc: 0.6267 | Val kappa: 0.3458 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.002109375\n",
      "Train loss: 0.6302 | Train precision: 0.7240 | Train recall: 0.7068 | Train f1score: 0.7148 | Train acc: 0.6549 | Train kappa: 0.4487 \n",
      "Val loss: 0.6164 | Val precision: 0.7479 | Val recall: 0.7506 | Val f1score: 0.7474 | Val acc: 0.6597 | Val kappa: 0.3833 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00158203125\n",
      "Train loss: 0.6249 | Train precision: 0.7314 | Train recall: 0.7216 | Train f1score: 0.7264 | Train acc: 0.6582 | Train kappa: 0.4619 \n",
      "Val loss: 0.6051 | Val precision: 0.7301 | Val recall: 0.7242 | Val f1score: 0.7253 | Val acc: 0.6710 | Val kappa: 0.3825 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0011865234375\n",
      "Train loss: 0.6164 | Train precision: 0.7417 | Train recall: 0.7257 | Train f1score: 0.7334 | Train acc: 0.6687 | Train kappa: 0.4768 \n",
      "Val loss: 0.7263 | Val precision: 0.7481 | Val recall: 0.7157 | Val f1score: 0.6495 | Val acc: 0.5538 | Val kappa: 0.2504 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000889892578125\n",
      "Train loss: 0.6085 | Train precision: 0.7372 | Train recall: 0.7319 | Train f1score: 0.7344 | Train acc: 0.6683 | Train kappa: 0.4738 \n",
      "Val loss: 0.7194 | Val precision: 0.6596 | Val recall: 0.7640 | Val f1score: 0.6686 | Val acc: 0.6189 | Val kappa: 0.3473 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00066741943359375\n",
      "Train loss: 0.6077 | Train precision: 0.7502 | Train recall: 0.7354 | Train f1score: 0.7423 | Train acc: 0.6713 | Train kappa: 0.4671 \n",
      "Val loss: 0.6006 | Val precision: 0.7593 | Val recall: 0.7800 | Val f1score: 0.7691 | Val acc: 0.6797 | Val kappa: 0.4207 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0005005645751953125\n",
      "Train loss: 0.5914 | Train precision: 0.7588 | Train recall: 0.7568 | Train f1score: 0.7576 | Train acc: 0.6890 | Train kappa: 0.5171 \n",
      "Val loss: 0.6437 | Val precision: 0.7067 | Val recall: 0.7790 | Val f1score: 0.7178 | Val acc: 0.6484 | Val kappa: 0.3919 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0003754234313964844\n",
      "Train loss: 0.5972 | Train precision: 0.7513 | Train recall: 0.7371 | Train f1score: 0.7437 | Train acc: 0.6814 | Train kappa: 0.4935 \n",
      "Val loss: 0.6182 | Val precision: 0.6901 | Val recall: 0.7764 | Val f1score: 0.7107 | Val acc: 0.6484 | Val kappa: 0.3865 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.0002815675735473633\n",
      "Train loss: 0.5899 | Train precision: 0.7573 | Train recall: 0.7508 | Train f1score: 0.7535 | Train acc: 0.6879 | Train kappa: 0.5031 \n",
      "Val loss: 0.6974 | Val precision: 0.7071 | Val recall: 0.7612 | Val f1score: 0.6834 | Val acc: 0.6059 | Val kappa: 0.3286 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00021117568016052246\n",
      "Train loss: 0.5810 | Train precision: 0.7653 | Train recall: 0.7600 | Train f1score: 0.7625 | Train acc: 0.6896 | Train kappa: 0.5114 \n",
      "Val loss: 0.6260 | Val precision: 0.7251 | Val recall: 0.7754 | Val f1score: 0.7343 | Val acc: 0.6484 | Val kappa: 0.3838 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015838176012039184\n",
      "Train loss: 0.5870 | Train precision: 0.7639 | Train recall: 0.7585 | Train f1score: 0.7610 | Train acc: 0.6880 | Train kappa: 0.5070 \n",
      "Val loss: 0.6157 | Val precision: 0.6951 | Val recall: 0.7740 | Val f1score: 0.7210 | Val acc: 0.6528 | Val kappa: 0.3859 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.00011878632009029388\n",
      "Train loss: 0.5734 | Train precision: 0.7698 | Train recall: 0.7653 | Train f1score: 0.7674 | Train acc: 0.6977 | Train kappa: 0.5284 \n",
      "Val loss: 0.6244 | Val precision: 0.7477 | Val recall: 0.7844 | Val f1score: 0.7542 | Val acc: 0.6649 | Val kappa: 0.4125 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 8.908974006772042e-05\n",
      "Train loss: 0.5882 | Train precision: 0.7631 | Train recall: 0.7507 | Train f1score: 0.7567 | Train acc: 0.6893 | Train kappa: 0.4983 \n",
      "Val loss: 0.6021 | Val precision: 0.7239 | Val recall: 0.7782 | Val f1score: 0.7449 | Val acc: 0.6658 | Val kappa: 0.4039 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 6.681730505079031e-05\n",
      "Train loss: 0.5746 | Train precision: 0.7733 | Train recall: 0.7676 | Train f1score: 0.7702 | Train acc: 0.6978 | Train kappa: 0.5292 \n",
      "Val loss: 0.6187 | Val precision: 0.7230 | Val recall: 0.7732 | Val f1score: 0.7319 | Val acc: 0.6450 | Val kappa: 0.3780 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 5.0112978788092735e-05\n",
      "Train loss: 0.5776 | Train precision: 0.7666 | Train recall: 0.7592 | Train f1score: 0.7625 | Train acc: 0.6891 | Train kappa: 0.5016 \n",
      "Val loss: 0.6222 | Val precision: 0.7260 | Val recall: 0.7751 | Val f1score: 0.7324 | Val acc: 0.6458 | Val kappa: 0.3810 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 3.758473409106955e-05\n",
      "Train loss: 0.5725 | Train precision: 0.7659 | Train recall: 0.7597 | Train f1score: 0.7626 | Train acc: 0.6971 | Train kappa: 0.5180 \n",
      "Val loss: 0.6186 | Val precision: 0.7246 | Val recall: 0.7756 | Val f1score: 0.7355 | Val acc: 0.6502 | Val kappa: 0.3858 \n",
      "\n",
      "Early stopping after epoch 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97037a6b049b4773bb3e7267a7df0466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.117936…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▄▆▆▇▇▇▇█▇████████</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>val_f1_score</td><td>▅▁▇█▇▆▆█▇▇▇▇▇██▇▇▇</td></tr><tr><td>val_loss</td><td>▃█▂▁▁▃▃▁▂▁▃▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>4e-05</td></tr><tr><td>train_f1_score</td><td>0.76258</td></tr><tr><td>train_loss</td><td>0.57249</td></tr><tr><td>val_f1_score</td><td>0.73549</td></tr><tr><td>val_loss</td><td>0.6186</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_5_RGB-RE-NIR-NDVI-NDRE-GRVI-EVI_3classes</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-v2/runs/8r6ktmdm' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-v2/runs/8r6ktmdm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230421_070220-8r6ktmdm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1055196160 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "CPU times: total: 6h 15min 43s\n",
      "Wall time: 12h 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set the random seeds\n",
    "set_seeds(42)\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "# group the hashIDs to get the unique values of hashIDs remaining in the subset  \n",
    "groups = sub_hash_id[:, 0] \n",
    "print(\"ORIGINAL POSITIVE RATIO:\", sub_label_set.mean())\n",
    "# create a StratifiedGroupKFold instance\n",
    "kf = StratifiedGroupKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# loop through the folds\n",
    "for fold, (train_ids, val_ids) in enumerate(kf.split(sub_image_set, sub_label_set, groups)):\n",
    "    print(\"Fold :\", fold+1)\n",
    "    print(\"TRAIN POSITIVE RATIO:\", sub_label_set[train_ids].mean())\n",
    "    print(\"VAL POSITIVE RATIO  :\", sub_label_set[val_ids].mean())\n",
    "    print(\"LENGTH TRAIN GROUPS :\", len(set(groups[train_ids])))\n",
    "    print(\"LENGTH VAL GROUPS   :\", len(set(groups[val_ids])))\n",
    "    \n",
    "    train_ids = sub_hash_id[:, 0][train_ids]\n",
    "    val_ids = np.unique(sub_hash_id[:, 0][val_ids])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Initialize a new wandb run for this fold\n",
    "    wandb.init(project='wze-uav-v2', name=f\"fold_{fold + 1}_{extra}\")\n",
    "    \n",
    "    # 1. Split data into train and validation set\n",
    "    # Get the training and testing data for this fold\n",
    "    # Use np.isin() to create boolean arrays indicating which indices belong to train or test sets\n",
    "    train_indices = np.isin(sub_hash_id[:,0], train_ids)\n",
    "    \n",
    "    val_indices = np.zeros_like(train_indices)  # initialize to all False\n",
    "    for hash_id_val in val_ids:\n",
    "        # select one image ID randomly from either 2020 or 2021 or 2022 for each unique hash ID in the test set\n",
    "        temp = np.unique(sub_hash_id[(sub_hash_id[:, 0] == hash_id_val), 1]) # check how many years are available per hashID\n",
    "        if len(temp) == 1:\n",
    "            year = temp[0]\n",
    "        elif len(temp) == 2:\n",
    "            year = np.random.choice(temp)\n",
    "        else:\n",
    "            year = np.random.choice(temp)\n",
    "        \n",
    "        # select image ID using the conditions\n",
    "        image_ids = sub_hash_id[(sub_hash_id[:,0] == hash_id_val) & (sub_hash_id[:,1] == year), 0]\n",
    "    \n",
    "        # mark the index corresponding to the selected image ID and hash ID as True in the test indices array\n",
    "        val_indices[(sub_hash_id[:,0] == hash_id_val) & (sub_hash_id[:,1] == year) & (np.isin(sub_hash_id[:,0], image_ids))] = True \n",
    "    \n",
    "    # Reshape boolean arrays to match shape of image_set and label_set\n",
    "    train_indices = train_indices.reshape(-1, 1)\n",
    "    val_indices = val_indices.reshape(-1, 1)\n",
    "    \n",
    "    # Select images and labels for train and validation sets\n",
    "    train_image_set = sub_image_set[train_indices[:, 0]]\n",
    "    train_label_set = sub_label_set[train_indices[:, 0]]\n",
    "    train_hash_id = sub_hash_id[train_indices[:, 0]][:,0]\n",
    "    train_species_set = sub_species_set[train_indices[:, 0]]\n",
    "    val_image_set = sub_image_set[val_indices[:, 0]]\n",
    "    val_label_set = sub_label_set[val_indices[:, 0]]\n",
    "    val_hash_id = sub_hash_id[val_indices[:, 0]][:,0]\n",
    "    val_species_set = sub_species_set[val_indices[:, 0]]\n",
    "    # reshape \n",
    "    train_label_set = train_label_set.reshape(-1, 1)\n",
    "    val_label_set = val_label_set.reshape(-1, 1)\n",
    "    train_species_set = train_species_set.reshape(-1, 1)\n",
    "    val_species_set = val_species_set.reshape(-1, 1)\n",
    "    \n",
    "    # check if there are any group overlaps between the data splits\n",
    "    hash_set = set(train_hash_id)\n",
    "    val_hash_set = set(val_hash_id)\n",
    "    test_hash_set = set(test_hash_id[:, 0].flatten())\n",
    "    intersection = hash_set.intersection(val_hash_set)\n",
    "    intersection2 = test_hash_set.intersection(val_hash_set)\n",
    "    intersection3 = hash_set.intersection(test_hash_set)\n",
    "    if intersection:\n",
    "        print(f\"Hash_id values in both train and val sets: {len(intersection)}\")\n",
    "        print(f\"Hash_id values in both test and val sets: {len(intersection2)}\")\n",
    "        print(f\"Hash_id values in both train and test sets: {len(intersection3)}\")\n",
    "    else:\n",
    "        print(\"There are no same hash_id values in train, val or test datasets. The datasplit was successful\")\n",
    "    \n",
    "         \n",
    "    print(\"Check shapes:\\n\")\n",
    "    print(f\"Images train dataset: {train_image_set.shape}\")\n",
    "    print(f\"Labels train dataset: {train_label_set.shape}\\n\")\n",
    "    \n",
    "    print(f\"Images validation dataset: {val_image_set.shape}\")\n",
    "    print(f\"Labels validation dataset: {val_label_set.shape}\\n\")\n",
    "    print('-'*50)\n",
    "    print (f\"Check if the split was stratified: (random_state=42)\")\n",
    "    print(f\"Healthy trees in train dataset: {np.count_nonzero(train_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in train dataset: {np.count_nonzero(train_label_set == 1)}\")\n",
    "    print(f\"Dead trees in train dataset: {np.count_nonzero(train_label_set == 2)}\")\n",
    "    print(f\"Healthy trees in validation dataset: {np.count_nonzero(val_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)}\")\n",
    "    print(f\"Dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)}\")\n",
    "    print(f\"Ratio health trees in validation dataset: {np.count_nonzero(val_label_set == 0)/np.count_nonzero(sub_label_set == 0)}\")\n",
    "    print(f\"Ratio stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)/np.count_nonzero(sub_label_set == 1)}\")\n",
    "    print(f\"Ratio dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)/np.count_nonzero(sub_label_set == 2)}\")\n",
    "    print(\"-\"*50)\n",
    "   \n",
    "    # 2. Create train and validation dataset. (choose custom dataset loader with 3 - 5 classes)\n",
    "    print(f\"\\nCreating datasets for fold: {fold + 1}\\n\")\n",
    "    train_dataset = data_loader.CustomDataset(data=train_image_set, labels=train_label_set, class_names=class_names, species = train_species_set,\n",
    "                                                         transform=transform_train)\n",
    "    \n",
    "    val_dataset = data_loader.CustomDataset(data=val_image_set, labels=val_label_set, class_names=class_names,\n",
    "                                                       species = val_species_set, transform=transform)\n",
    "   \n",
    "    # 3. Create train and validation dataloader\n",
    "    # create sampler for oversampling of the minority classes\n",
    "    sampler = data_loader.data_sampler(dataset=train_dataset, class_names=class_names)\n",
    "    print(f\"Creating dataloaders for fold: {fold +1}\\n\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, generator=g,\n",
    "                              sampler=sampler, shuffle=False, drop_last=True) # shuffle false because of the sampler\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, shuffle=False,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    model = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    lr_scheduler = CustomExponentialLR(optimizer, gamma=gamma, min_lr=min_lr)\n",
    "\n",
    "    fold += 1\n",
    "    print(f\"\\n[INFO] Fold number: {fold}\")\n",
    "    print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "    print(f\"[INFO] Batch_size: {batch_size}\")\n",
    "    print(f\"[INFO] Number of bands: {n_bands}\")\n",
    "    print(f\"[INFO] Dropout rate: {dropout_rate}\")\n",
    "    print(f\"[INFO] Gamma learning rate: {gamma}\")\n",
    "    print(f\"[INFO] Memory allocated: {torch.cuda.memory_allocated()} bytes\")\n",
    "    # 4. Train model with k fold dataloaders and track experiments\n",
    "    \n",
    "    if fold == 1:\n",
    "        fold1_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "       \n",
    "    elif fold == 2:\n",
    "        fold2_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    elif fold == 3:\n",
    "        fold3_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    elif fold == 4:\n",
    "        fold4_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    else:\n",
    "        fold5_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    \n",
    "    del train_indices, val_indices, train_image_set, train_label_set, train_hash_id, train_species_set, val_image_set, val_label_set, val_hash_id, val_species_set,\n",
    "    train_dataset, val_dataset, sampler, train_dataloader, val_dataloader, model, loss_fn, optimizer, lr_scheduler\n",
    "    \n",
    "    #finish the wandb run\n",
    "    wandb.finish()\n",
    "    print(\"Deleting variables and emptying cache\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\")\n",
    "    print(\"-\"*50 + \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph to visualize the training and validation loss for each fold\n",
    "wandb.run.summary[\"graph\"] = wandb.plot.line_series(\n",
    "    xs=\"epoch\",\n",
    "    ys=[\"train_loss\", \"val_loss\"],\n",
    "    group=\"fold\",\n",
    "    xaxis=\"Epoch\",\n",
    "    yaxis=\"Loss\",\n",
    "    title=\"Training and Validation Loss by Fold\",\n",
    ")\n",
    "\n",
    "# Create a graph to visualize the training and validation f1 score for each fold\n",
    "wandb.run.summary[\"graph\"] = wandb.plot.line_series(\n",
    "    xs=\"epoch\",\n",
    "    ys=[\"train_f1_score\", \"val_f1_score\"],\n",
    "    group=\"fold\",\n",
    "    xaxis=\"Epoch\",\n",
    "    yaxis=\"Loss\",\n",
    "    title=\"Training and Validation F1-Score by Fold\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c36ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = data_loader.CustomTestDataset(\n",
    "    data = test_image_set,\n",
    "    labels = test_label_set,\n",
    "    class_names=class_names, \n",
    "    species = test_species_set,\n",
    "    kkl = None,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# create test dataloader\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             persistent_workers=True,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the best model filepath\n",
    "best_model_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\effnet_b0\\01_18_epochs.pth\"\n",
    "\n",
    "# Instantiate a new instance of EffNetB0 (to load the saved state_dict() to)\n",
    "unfreeze=True\n",
    "best_model = models.create_effnetb0(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "\n",
    "# Load the saved best model state_dict()\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, \n",
    "                     test_dataloader: torch.utils.data.DataLoader,\n",
    "                     device: torch.device):\n",
    "    # 1. Make predictions with trained model\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    species_list = []\n",
    "    test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y, species in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "            # Send data and targets to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Do the forward pass\n",
    "            y_logit = model(X)\n",
    "            # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "            y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "            # Put predictions on CPU for evaluation\n",
    "            y_preds.append(y_pred.cpu())\n",
    "            y_labels.append(y.cpu())\n",
    "            species_list.append(species)\n",
    "            \n",
    "            #other metrics\n",
    "            test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "            y_pred_class = y_pred.detach().cpu().numpy() \n",
    "            y_class = y.detach().cpu().numpy()\n",
    "            labels = np.array([0])\n",
    "            test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "            \n",
    "            #if count >= 1:\n",
    "            #    y_set = torch.cat((y_set, y))\n",
    "            #    count = count + 1\n",
    "            #else:\n",
    "            #    y_set = y\n",
    "            #    count = count + 1\n",
    "            \n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "    test_precision = test_precision / len(test_dataloader)\n",
    "    test_recall = test_recall / len(test_dataloader)\n",
    "    test_f1_score = test_f1_score / len(test_dataloader)\n",
    "    #test_kappa = test_kappa / len(dataloader)\n",
    "    test_acc = test_acc / len(test_dataloader)\n",
    "    # Concatenate list of predictions into a tensor\n",
    "    y_pred_tensor = torch.cat(y_preds)\n",
    "    y_labels_tensor = torch.cat(y_labels)\n",
    "    test_f1_score = f1_score(y_labels_tensor.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=1, labels=[0,1,2])\n",
    "    \n",
    "    # Print classification report\n",
    "    y_true = y_labels_tensor.detach().cpu().numpy()\n",
    "    report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    return y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "#from wze_uav.analysis import *\n",
    "y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds = make_predictions(model=best_model,\n",
    "                                 test_dataloader=test_dataloader, \n",
    "                                 device=device)\n",
    "\n",
    "y_labels_tensor = y_labels_tensor.detach().cpu().numpy()\n",
    "y_pred_tensor = y_pred_tensor.detach().cpu().numpy()\n",
    "\n",
    "#confmat = ConfusionMatrix(num_classes=num_classes, task='multiclass')\n",
    "#confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "#                         target=test_labels)\n",
    "labels = np.array([0,1,2])\n",
    "confmat = confusion_matrix(y_labels_tensor, y_pred_tensor, labels=labels)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat, # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test recall: {test_recall}\")\n",
    "print(f\"Test F1score: {test_f1_score}\")\n",
    "#print(f\"Test Kappa: {test_kappa}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Logits: {y_logit}\")\n",
    "print(f\"Test Predictions: {y_pred}\")\n",
    "print(f\"Test Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4173b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c195b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da05604",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_labels = []\n",
    "labels = np.array([0,1,2])\n",
    "test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "count = 0\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logit = model(X)\n",
    "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_labels.append(y.cpu())\n",
    "        \n",
    "        #other metrics\n",
    "        test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "        y_pred_class = y_pred.detach().cpu().numpy() \n",
    "        y_class = y.detach().cpu().numpy()\n",
    "        test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        \n",
    "        #if count >= 1:\n",
    "        #    y_set = torch.cat((y_set, y))\n",
    "        #    count = count + 1\n",
    "        #else:\n",
    "        #    y_set = y\n",
    "        #    count = count + 1\n",
    "        \n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_precision = test_precision / len(test_dataloader)\n",
    "test_recall = test_recall / len(test_dataloader)\n",
    "#test_f1_score = test_f1_score / len(test_dataloader)\n",
    "#test_kappa = test_kappa / len(dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "test_f1_score = f1_score(y_set.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=0, labels=[0,1,2])\n",
    "\n",
    "# Print classification report\n",
    "y_true = y_set.detach().cpu().numpy()\n",
    "report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae97fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebafd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make = (y_class == y_pred_class)\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8aa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(y_logit, dim=1).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a806154",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (y_pred == y).sum().item()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_class = y_pred.detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
