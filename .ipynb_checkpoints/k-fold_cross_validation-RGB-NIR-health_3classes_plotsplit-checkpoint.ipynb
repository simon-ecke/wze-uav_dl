{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1acdaa3",
   "metadata": {},
   "source": [
    "# WZE-UAV Image Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2159aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0026f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b160d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wze_uav.data_loader as data_loader\n",
    "import wze_uav.models as models\n",
    "from wze_uav.engine import *\n",
    "from wze_uav.utils2 import *\n",
    "#from wze_uav.log_writer import create_writer\n",
    "from wze_uav.datasplit import *\n",
    "from efficientnet import model_effnet #for custom effnet with n_channels input\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4fb2f",
   "metadata": {},
   "source": [
    "#### Get PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10886b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1+cu116\n",
      "torchvision version: 0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a83cf",
   "metadata": {},
   "source": [
    "#### Preparing device agnostic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d5de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Index of current divice: 0\n",
      "Number of GPUs available: 1\n",
      "GPU Model: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# ensure device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(f\"Index of current divice: {torch.cuda.current_device()}\")\n",
    "# get number of GPUs available\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "# get the name of the device\n",
    "print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6b169",
   "metadata": {},
   "source": [
    "#### Login to Weights & Biases to track results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59d27cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimon-ecke\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230524_145956-tc1ue8p8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/tc1ue8p8' target=\"_blank\">legendary-mountain-1</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/tc1ue8p8' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/tc1ue8p8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/tc1ue8p8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x259d39a5a60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: The proxy needs to be set in anaconda!\n",
    "# copy paste this in anaconda and restart jupyter notebook\n",
    "#set http_proxy=http://www-proxy.bayern.de:80\n",
    "#set https_proxy=http://www-proxy.bayern.de:80\n",
    "wandb.login()\n",
    "#wandb.init(settings=wandb.Settings(start_method=\"thread\"))\n",
    "wandb.init(project='wze-uav-health-3classes', entity='simon-ecke')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6a34",
   "metadata": {},
   "source": [
    "#### Ensure reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information, see also: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(42) \n",
    "\n",
    "# Set to true -> might speed up the process but should be set to False if reproducible results are desired\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be33671",
   "metadata": {},
   "source": [
    "#### Define file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30645f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# 3 channel input (r-g-b)\n",
    "data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb\"\n",
    "\n",
    "# 4 channel input (r-g-b-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-nir\"\n",
    "\n",
    "# 5 channel input (r-g-b-re-nir)\n",
    "#'data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir\"\n",
    "\n",
    "# 6 channel input (r-g-b-re-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir-chm\"\n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560ce64",
   "metadata": {},
   "source": [
    "#### Get all file paths, years and plotIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa072e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = os.listdir(data_path)\n",
    "path_list = []\n",
    "#year_list = []\n",
    "#plotID_list = []\n",
    "# Iterate over all datafiles\n",
    "for year in fn_list:\n",
    "    year_dir = f'{data_path}\\\\{year}'\n",
    "    for filename in os.listdir(year_dir):\n",
    "        path = f'{year_dir}\\\\{filename}'\n",
    "        #plotID = path.rsplit('_',1)[0].rsplit('r',1)[1]\n",
    "        path_list.append(path)\n",
    "        #year_list.append(year)\n",
    "        #plotID_list.append(plotID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3937a44",
   "metadata": {},
   "source": [
    "#### Get unique plotIDs and years per available trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a50f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0de8426bfc04908bc1ebfc00db599f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating unique tree IDs...:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotID_dict = data_loader.get_plotID(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cea00",
   "metadata": {},
   "source": [
    "#### Import all imagery, labels and other features from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e3eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0441eeb223840fe8d788f9d171865f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing hdf5 datasets:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_set, label_set, species_set, kkl_set, bk_set, hash_id = data_loader.hdf5_to_img_label(path_list,\n",
    "                                                                                               plotID_dict,\n",
    "                                                                                               load_sets=[\"images_masked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c38e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbv_to_sst_3classesv2(image_set: np.array, label_set: np.array, species_set: np.array, kkl_set: np.array, bk_set: np.array, hash_id: np.array):\n",
    "    \n",
    "    label_list = []\n",
    "    species_list = [20, 48, 51, 100, 118, 134]\n",
    "    for i in range(0, len(label_set)):\n",
    "        if label_set[i] >= 99: # all dead trees\n",
    "            label = 2\n",
    "            label_list.append(label)\n",
    "        elif species_set[i] in species_list and label_set[i] >= 0 and label_set[i] <= 25: # healthy trees\n",
    "            label = 0\n",
    "            label_list.append(label)\n",
    "        elif species_set[i] in species_list and label_set[i] >= 30 and label_set[i] <= 95: # stressed trees\n",
    "            label = 1\n",
    "            label_list.append(label)\n",
    "        else:\n",
    "            label = 999\n",
    "            label_list.append(label)\n",
    "            \n",
    "    label_set = np.array(label_list)\n",
    "    \n",
    "    np_filter = []\n",
    "    for i in range(0, len(bk_set)):\n",
    "        if label_set[i] in [0,1,2]:\n",
    "            np_filter.append(True)\n",
    "        else:\n",
    "            np_filter.append(False)\n",
    "         \n",
    "    image_set = image_set[np_filter]\n",
    "    label_set = label_set[np_filter]\n",
    "    species_set = species_set[np_filter]\n",
    "    kkl_set = kkl_set[np_filter]\n",
    "    bk_set = bk_set[np_filter]\n",
    "    hash_id = hash_id[np_filter]\n",
    "    \n",
    "    return image_set, label_set, species_set, kkl_set, bk_set, hash_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90e2b7",
   "metadata": {},
   "source": [
    "#### Convert nbv to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0224972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbv_set = label_set\n",
    "image_set, label_set, species_set, kkl_set, bk_set, hash_id = nbv_to_sst_3classesv2(image_set, label_set, species_set, kkl_set, bk_set, hash_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4cd85",
   "metadata": {},
   "source": [
    "#### Split data into subset (used for training and validation in the 5-fold cross-validation) and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d06eda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL POSITIVE RATIO: 0.44291350531107737\n",
      "Fold : 0\n",
      "TRAIN POSITIVE RATIO: 0.45229863920559027\n",
      "TEST POSITIVE RATIO : 0.39861111111111114\n",
      "LENGTH TRAIN GROUPS : 194\n",
      "LENGTH TEST GROUPS  : 41\n",
      "Number of True in sub_indices: 13595\n",
      "Number of False in sub_indices: 2880\n",
      "Number of True in test_indices: 1061\n",
      "Number of False in test_indices: 15414\n",
      "Check shapes:\n",
      "\n",
      "Images sub dataset: (13595, 250, 250, 3)\n",
      "Labels sub dataset: (13595, 1)\n",
      "\n",
      "Images test dataset: (1061, 250, 250, 3)\n",
      "Labels test dataset: (1061, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in sub dataset: 7695\n",
      "Stressed trees in sub dataset: 5651\n",
      "Dead trees in sub dataset: 249\n",
      "Healthy trees in test dataset: 674\n",
      "Stressed trees in test dataset: 365\n",
      "Dead trees in test dataset: 22\n",
      "Ratio health trees in test dataset: 0.08758934372969461\n",
      "Ratio stressed trees in test dataset: 0.06459033799327553\n",
      "Ratio dead trees in test dataset: 0.08835341365461848\n"
     ]
    }
   ],
   "source": [
    "sub_image_set, sub_label_set, sub_hash_id, sub_species_set, test_image_set, test_label_set, test_hash_id, test_species_set = data_split(image_set, label_set, hash_id, species_set, n_splits=6, random_state=42, seed=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fbb5b",
   "metadata": {},
   "source": [
    "#### Check if any hash ID is in both sub and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "874367cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no hash_id values in both train and test datasets. The datasplit was successful\n"
     ]
    }
   ],
   "source": [
    "hash_set = set(sub_hash_id[:,0].flatten())\n",
    "test_hash_set = set(test_hash_id[:,0].flatten())\n",
    "intersection = hash_set.intersection(test_hash_set)\n",
    "if intersection:\n",
    "    print(f\"Hash_id values in both train and test sets: {len(intersection)}\")\n",
    "else:\n",
    "    print(\"There are no hash_id values in both train and test datasets. The datasplit was successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b64d4",
   "metadata": {},
   "source": [
    "#### Check feature distribution of the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a33ff5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset\n",
      "Test data healthy trees: 674\n",
      "Test data stressed trees: 365\n",
      "Test data dead trees: 22\n",
      "--------------------------------------------------\n",
      "Remaining dataset\n",
      "Remaining data healthy trees: 7695\n",
      "Remaining data stressed trees: 5651\n",
      "Remaining data dead trees: 249\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences(data, value):\n",
    "    count = 0\n",
    "    for item in data:\n",
    "        if item == value:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"Test dataset\")\n",
    "#print(f\"Test data Picea abies healthy: {count_occurrences(test_label_set, 0)}\")\n",
    "#print(f\"Test data Picea abies stressed: {count_occurrences(test_label_set, 1)}\")\n",
    "#print(f\"Test data Pinus sylvestris healthy: {count_occurrences(test_label_set, 2)}\")\n",
    "#print(f\"Test data Pinus sylvestris stressed: {count_occurrences(test_label_set, 3)}\")\n",
    "#print(f\"Test data Abies alba healthy: {count_occurrences(test_label_set, 4)}\")\n",
    "#print(f\"Test data Abies alba stressed: {count_occurrences(test_label_set, 5)}\")\n",
    "#print(f\"Test data Fagus sylvatica healthy: {count_occurrences(test_label_set, 6)}\")\n",
    "#print(f\"Test data Fagus sylvatica stressed: {count_occurrences(test_label_set, 7)}\")\n",
    "#print(f\"Test data Quercus robur/petraea healthy: {count_occurrences(test_label_set, 8)}\")\n",
    "#print(f\"Test data Quercus robur/petraea stressed: {count_occurrences(test_label_set, 9)}\")\n",
    "#print(f\"Test data Larix spp.: {count_occurrences(test_label_set, 10)}\")\n",
    "#print(f\"Test data Acer spp.: {count_occurrences(test_label_set, 11)}\")\n",
    "#print(f\"Test data Betula pendula: {count_occurrences(test_label_set, 12)}\")\n",
    "print(f\"Test data healthy trees: {count_occurrences(test_label_set, 0)}\")\n",
    "print(f\"Test data stressed trees: {count_occurrences(test_label_set, 1)}\")\n",
    "print(f\"Test data dead trees: {count_occurrences(test_label_set, 2)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Remaining dataset\")\n",
    "#print(f\"Remaining data Picea abies healthy: {count_occurrences(sub_label_set, 0)}\")\n",
    "#print(f\"Remaining data Picea abies stressed: {count_occurrences(sub_label_set, 1)}\")\n",
    "#print(f\"Remaining data Pinus sylvestris healthy: {count_occurrences(sub_label_set, 2)}\")\n",
    "#print(f\"Remaining data Pinus sylvestris stressed: {count_occurrences(sub_label_set, 3)}\")\n",
    "#print(f\"Remaining data Abies alba healthy: {count_occurrences(sub_label_set, 4)}\")\n",
    "#print(f\"Remaining data Abies alba stressed: {count_occurrences(sub_label_set, 5)}\")\n",
    "#print(f\"Remaining data Fagus sylvatica healthy: {count_occurrences(sub_label_set, 6)}\")\n",
    "#print(f\"Remaining data Fagus sylvatica stressed: {count_occurrences(sub_label_set, 7)}\")\n",
    "#print(f\"Remaining data Quercus robur/petraea healthy: {count_occurrences(sub_label_set, 8)}\")\n",
    "#print(f\"Remaining data Quercus robur/petraea stressed: {count_occurrences(sub_label_set, 9)}\")\n",
    "#print(f\"Test data Larix spp.: {count_occurrences(sub_label_set, 10)}\")\n",
    "#print(f\"Test data Acer spp.: {count_occurrences(sub_label_set, 11)}\")\n",
    "#print(f\"Test data Betula pendula: {count_occurrences(sub_label_set, 12)}\")\n",
    "print(f\"Remaining data healthy trees: {count_occurrences(sub_label_set, 0)}\")\n",
    "print(f\"Remaining data stressed trees: {count_occurrences(sub_label_set, 1)}\")\n",
    "print(f\"Remaining data dead trees: {count_occurrences(sub_label_set, 2)}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e08fcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train transform with augmentation. \n",
    "transform_train = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(degrees=[0,360])])\n",
    "\n",
    "# test and val dataset transform without augmentation. \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# class names need to fit the customDataset class used e.g. 3 classes -> use CustomDataset3Classes\n",
    "#class_names = ['healthy', 'slightly_stressed', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "#class_names = ['healthy', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "class_names = ['healthy', 'stressed', 'dead']\n",
    "#class_names = ['Picea abies healthy', 'Picea abies stressed', 'Pinus sylvestris healthy', 'Pinus sylvestris stressed', \n",
    "#               'Abies alba healthy', 'Abies alba stressed', 'Fagus sylvatica healthy', 'Fagus sylvatica stressed',\n",
    "#               'Quercus robur/petraea healthy', 'Quercus robur/petraea stressed', 'Larix spp.', 'Acer spp.',\n",
    "#               'Betula pendula', 'dead trees']\n",
    "\n",
    "# set seeds\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "NUM_WORKERS=3 # should be changed, depending on the system used\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31779c05",
   "metadata": {},
   "source": [
    "#### Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10ae4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "# 1. Define number of epochs\n",
    "epochs = 50\n",
    "n_bands = sub_image_set[0].shape[2] # get number of bands\n",
    "\n",
    "# 2. Define model\n",
    "num_classes = len(class_names)\n",
    "unfreeze = True # all layer weights get updated\n",
    "dropout_rate = 0.5 #define dropout rate\n",
    "model_name = \"EffNet_b7_RGB-3classes_health_plotsplit\"\n",
    "\n",
    "# 3. Define loss, optimizer and learning rate scheduler\n",
    "lr = 0.001 # define learning rate\n",
    "min_lr = 1e-6 # minimum learning rate threshold\n",
    "gamma = 0.75 # how fast the learning rate decreases per epoch (low number=faster decrease)\n",
    "patience = 10\n",
    "\n",
    "# 4. Create target folder name were to save the tensorboard event files\n",
    "experiment_name = 'RGB-3classes_health_plotsplit'\n",
    "extra = \"RGB-3classes_health_plotsplit\"\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#torch.cuda.empty_cache()\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768b1a",
   "metadata": {},
   "source": [
    "#### Run k-Fold cross-validation on EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c29c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL POSITIVE RATIO: 0.45229863920559027\n",
      "Fold : 1\n",
      "TRAIN POSITIVE RATIO: 0.45625111150631337\n",
      "VAL POSITIVE RATIO  : 0.4333759046402725\n",
      "LENGTH TRAIN GROUPS : 154\n",
      "LENGTH VAL GROUPS   : 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:tc1ue8p8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d8d8fb211a4a0f98262343ed92db64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-mountain-1</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/tc1ue8p8' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/tc1ue8p8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_145956-tc1ue8p8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:tc1ue8p8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230524_155449-g3n8doz6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g3n8doz6' target=\"_blank\">fold_1_RGB-3classes_health_plotsplit</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g3n8doz6' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g3n8doz6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (11246, 250, 250, 3)\n",
      "Labels train dataset: (11246, 1)\n",
      "\n",
      "Images validation dataset: (876, 250, 250, 3)\n",
      "Labels validation dataset: (876, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 6337\n",
      "Stressed trees in train dataset: 4687\n",
      "Dead trees in train dataset: 222\n",
      "Healthy trees in validation dataset: 510\n",
      "Stressed trees in validation dataset: 356\n",
      "Dead trees in validation dataset: 10\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 1\n",
      "\n",
      "Creating dataloaders for fold: 1\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 1\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dffaeaadbca41e8aacddcaaf1584000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.001\n",
      "Train loss: 0.7274 | Train precision: 0.6131 | Train recall: 0.6007 | Train f1score: 0.6066 | Train acc: 0.6013 | Train kappa: 0.3399 \n",
      "Val loss: 0.7455 | Val precision: 0.5074 | Val recall: 0.5986 | Val f1score: 0.4678 | Val acc: 0.6111 | Val kappa: 0.2427 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00075\n",
      "Train loss: 0.6670 | Train precision: 0.6801 | Train recall: 0.6765 | Train f1score: 0.6781 | Train acc: 0.6363 | Train kappa: 0.4167 \n",
      "Val loss: 0.6586 | Val precision: 0.7683 | Val recall: 0.5734 | Val f1score: 0.6217 | Val acc: 0.6470 | Val kappa: 0.3375 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0005625000000000001\n",
      "Train loss: 0.6306 | Train precision: 0.7189 | Train recall: 0.7185 | Train f1score: 0.7184 | Train acc: 0.6672 | Train kappa: 0.4746 \n",
      "Val loss: 0.6253 | Val precision: 0.6721 | Val recall: 0.6187 | Val f1score: 0.5977 | Val acc: 0.6366 | Val kappa: 0.2558 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.000421875\n",
      "Train loss: 0.6149 | Train precision: 0.7426 | Train recall: 0.7350 | Train f1score: 0.7386 | Train acc: 0.6795 | Train kappa: 0.4873 \n",
      "Val loss: 0.6146 | Val precision: 0.6255 | Val recall: 0.7369 | Val f1score: 0.6622 | Val acc: 0.6806 | Val kappa: 0.4022 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00031640625\n",
      "Train loss: 0.6055 | Train precision: 0.7519 | Train recall: 0.7407 | Train f1score: 0.7462 | Train acc: 0.6782 | Train kappa: 0.4852 \n",
      "Val loss: 0.5986 | Val precision: 0.7326 | Val recall: 0.7176 | Val f1score: 0.6973 | Val acc: 0.6748 | Val kappa: 0.3595 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0002373046875\n",
      "Train loss: 0.5926 | Train precision: 0.7521 | Train recall: 0.7435 | Train f1score: 0.7476 | Train acc: 0.6872 | Train kappa: 0.5080 \n",
      "Val loss: 0.6012 | Val precision: 0.7257 | Val recall: 0.7439 | Val f1score: 0.7314 | Val acc: 0.6898 | Val kappa: 0.4094 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000177978515625\n",
      "Train loss: 0.5834 | Train precision: 0.7624 | Train recall: 0.7508 | Train f1score: 0.7565 | Train acc: 0.6950 | Train kappa: 0.5141 \n",
      "Val loss: 0.6383 | Val precision: 0.6355 | Val recall: 0.7354 | Val f1score: 0.6740 | Val acc: 0.6562 | Val kappa: 0.3651 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00013348388671875\n",
      "Train loss: 0.5806 | Train precision: 0.7599 | Train recall: 0.7612 | Train f1score: 0.7605 | Train acc: 0.6974 | Train kappa: 0.5222 \n",
      "Val loss: 0.6111 | Val precision: 0.6926 | Val recall: 0.7408 | Val f1score: 0.7144 | Val acc: 0.6748 | Val kappa: 0.3869 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0001001129150390625\n",
      "Train loss: 0.5636 | Train precision: 0.7848 | Train recall: 0.7786 | Train f1score: 0.7817 | Train acc: 0.7124 | Train kappa: 0.5515 \n",
      "Val loss: 0.5930 | Val precision: 0.7089 | Val recall: 0.7464 | Val f1score: 0.7214 | Val acc: 0.6956 | Val kappa: 0.4146 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 7.508468627929687e-05\n",
      "Train loss: 0.5691 | Train precision: 0.7725 | Train recall: 0.7738 | Train f1score: 0.7731 | Train acc: 0.7057 | Train kappa: 0.5379 \n",
      "Val loss: 0.5956 | Val precision: 0.6714 | Val recall: 0.7475 | Val f1score: 0.7002 | Val acc: 0.6933 | Val kappa: 0.4127 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 5.6313514709472656e-05\n",
      "Train loss: 0.5590 | Train precision: 0.7817 | Train recall: 0.7798 | Train f1score: 0.7807 | Train acc: 0.7131 | Train kappa: 0.5524 \n",
      "Val loss: 0.5895 | Val precision: 0.6384 | Val recall: 0.7446 | Val f1score: 0.6779 | Val acc: 0.6840 | Val kappa: 0.3991 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 4.223513603210449e-05\n",
      "Train loss: 0.5494 | Train precision: 0.7865 | Train recall: 0.7819 | Train f1score: 0.7842 | Train acc: 0.7130 | Train kappa: 0.5561 \n",
      "Val loss: 0.5874 | Val precision: 0.6532 | Val recall: 0.7386 | Val f1score: 0.6813 | Val acc: 0.6852 | Val kappa: 0.3898 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 3.167635202407837e-05\n",
      "Train loss: 0.5574 | Train precision: 0.7785 | Train recall: 0.7753 | Train f1score: 0.7769 | Train acc: 0.7104 | Train kappa: 0.5515 \n",
      "Val loss: 0.5956 | Val precision: 0.6467 | Val recall: 0.7479 | Val f1score: 0.6820 | Val acc: 0.6944 | Val kappa: 0.4134 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 2.3757264018058778e-05\n",
      "Train loss: 0.5495 | Train precision: 0.7903 | Train recall: 0.7836 | Train f1score: 0.7869 | Train acc: 0.7179 | Train kappa: 0.5601 \n",
      "Val loss: 0.5951 | Val precision: 0.6401 | Val recall: 0.7470 | Val f1score: 0.6802 | Val acc: 0.6863 | Val kappa: 0.4043 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 1.7817948013544083e-05\n",
      "Train loss: 0.5534 | Train precision: 0.7833 | Train recall: 0.7838 | Train f1score: 0.7834 | Train acc: 0.7128 | Train kappa: 0.5436 \n",
      "Val loss: 0.5964 | Val precision: 0.6472 | Val recall: 0.7400 | Val f1score: 0.6825 | Val acc: 0.6794 | Val kappa: 0.3860 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 1.3363461010158063e-05\n",
      "Train loss: 0.5490 | Train precision: 0.7882 | Train recall: 0.7816 | Train f1score: 0.7848 | Train acc: 0.7137 | Train kappa: 0.5455 \n",
      "Val loss: 0.6010 | Val precision: 0.6480 | Val recall: 0.7420 | Val f1score: 0.6844 | Val acc: 0.6806 | Val kappa: 0.3897 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 1.0022595757618546e-05\n",
      "Train loss: 0.5423 | Train precision: 0.7929 | Train recall: 0.7871 | Train f1score: 0.7899 | Train acc: 0.7170 | Train kappa: 0.5552 \n",
      "Val loss: 0.5981 | Val precision: 0.6521 | Val recall: 0.7100 | Val f1score: 0.6768 | Val acc: 0.6794 | Val kappa: 0.3835 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 7.51694681821391e-06\n",
      "Train loss: 0.5379 | Train precision: 0.7944 | Train recall: 0.7903 | Train f1score: 0.7923 | Train acc: 0.7208 | Train kappa: 0.5636 \n",
      "Val loss: 0.5923 | Val precision: 0.6428 | Val recall: 0.7138 | Val f1score: 0.6714 | Val acc: 0.6863 | Val kappa: 0.3979 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.637710113660432e-06\n",
      "Train loss: 0.5534 | Train precision: 0.7866 | Train recall: 0.7809 | Train f1score: 0.7836 | Train acc: 0.7129 | Train kappa: 0.5567 \n",
      "Val loss: 0.5915 | Val precision: 0.6513 | Val recall: 0.7455 | Val f1score: 0.6879 | Val acc: 0.6852 | Val kappa: 0.3985 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 4.228282585245324e-06\n",
      "Train loss: 0.5539 | Train precision: 0.7867 | Train recall: 0.7800 | Train f1score: 0.7833 | Train acc: 0.7129 | Train kappa: 0.5329 \n",
      "Val loss: 0.5949 | Val precision: 0.6521 | Val recall: 0.7470 | Val f1score: 0.6892 | Val acc: 0.6863 | Val kappa: 0.4014 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 3.1712119389339933e-06\n",
      "Train loss: 0.5402 | Train precision: 0.7916 | Train recall: 0.7888 | Train f1score: 0.7902 | Train acc: 0.7255 | Train kappa: 0.5647 \n",
      "Val loss: 0.5946 | Val precision: 0.6546 | Val recall: 0.7498 | Val f1score: 0.6919 | Val acc: 0.6898 | Val kappa: 0.4083 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 2.378408954200495e-06\n",
      "Train loss: 0.5446 | Train precision: 0.7872 | Train recall: 0.7907 | Train f1score: 0.7889 | Train acc: 0.7180 | Train kappa: 0.5555 \n",
      "Val loss: 0.5960 | Val precision: 0.6420 | Val recall: 0.7134 | Val f1score: 0.6709 | Val acc: 0.6852 | Val kappa: 0.3963 \n",
      "\n",
      "Early stopping after epoch 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ebf4bd63044ecf87dfbfff2a58cdb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▄▅▆▆▆▇▇█▇██▇█████████</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▃▃▃▂▂▂▁▂▁▂▁▁▁▂▂▁▁</td></tr><tr><td>val_f1_score</td><td>▁▅▄▆▇█▆██▇▇▇▇▇▇▇▇▆▇▇▇▆</td></tr><tr><td>val_loss</td><td>█▄▃▂▁▂▃▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_f1_score</td><td>0.78886</td></tr><tr><td>train_loss</td><td>0.54458</td></tr><tr><td>val_f1_score</td><td>0.67091</td></tr><tr><td>val_loss</td><td>0.59596</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_1_RGB-3classes_health_plotsplit</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g3n8doz6' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g3n8doz6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_155449-g3n8doz6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1047551488 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 2\n",
      "TRAIN POSITIVE RATIO: 0.44192477876106195\n",
      "VAL POSITIVE RATIO  : 0.4932653804149982\n",
      "LENGTH TRAIN GROUPS : 158\n",
      "LENGTH VAL GROUPS   : 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230524_174009-3ca80sjn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/3ca80sjn' target=\"_blank\">fold_2_RGB-3classes_health_plotsplit</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/3ca80sjn' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/3ca80sjn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (10848, 250, 250, 3)\n",
      "Labels train dataset: (10848, 1)\n",
      "\n",
      "Images validation dataset: (939, 250, 250, 3)\n",
      "Labels validation dataset: (939, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 6211\n",
      "Stressed trees in train dataset: 4480\n",
      "Dead trees in train dataset: 157\n",
      "Healthy trees in validation dataset: 521\n",
      "Stressed trees in validation dataset: 384\n",
      "Dead trees in validation dataset: 34\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 2\n",
      "\n",
      "Creating dataloaders for fold: 2\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 2\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcabf59bdbc4987bfe5b1fbcae9cb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.001\n",
      "Train loss: 0.7382 | Train precision: 0.5240 | Train recall: 0.4737 | Train f1score: 0.4915 | Train acc: 0.5892 | Train kappa: 0.2471 \n",
      "Val loss: 0.7445 | Val precision: 0.3724 | Val recall: 0.3849 | Val f1score: 0.3772 | Val acc: 0.5744 | Val kappa: 0.1843 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00075\n",
      "Train loss: 0.6792 | Train precision: 0.6478 | Train recall: 0.6303 | Train f1score: 0.6381 | Train acc: 0.6228 | Train kappa: 0.3612 \n",
      "Val loss: 0.6886 | Val precision: 0.5808 | Val recall: 0.7244 | Val f1score: 0.6264 | Val acc: 0.6239 | Val kappa: 0.4047 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0005625000000000001\n",
      "Train loss: 0.6416 | Train precision: 0.6963 | Train recall: 0.6804 | Train f1score: 0.6877 | Train acc: 0.6590 | Train kappa: 0.4190 \n",
      "Val loss: 0.7632 | Val precision: 0.7114 | Val recall: 0.7331 | Val f1score: 0.6987 | Val acc: 0.6293 | Val kappa: 0.4201 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.000421875\n",
      "Train loss: 0.6319 | Train precision: 0.7072 | Train recall: 0.6933 | Train f1score: 0.7000 | Train acc: 0.6681 | Train kappa: 0.4417 \n",
      "Val loss: 0.7446 | Val precision: 0.7148 | Val recall: 0.7051 | Val f1score: 0.6729 | Val acc: 0.5938 | Val kappa: 0.3716 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00031640625\n",
      "Train loss: 0.6062 | Train precision: 0.7217 | Train recall: 0.7192 | Train f1score: 0.7205 | Train acc: 0.6746 | Train kappa: 0.4597 \n",
      "Val loss: 0.6798 | Val precision: 0.7557 | Val recall: 0.7040 | Val f1score: 0.7259 | Val acc: 0.6552 | Val kappa: 0.4553 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0002373046875\n",
      "Train loss: 0.5962 | Train precision: 0.7347 | Train recall: 0.7394 | Train f1score: 0.7370 | Train acc: 0.6851 | Train kappa: 0.4685 \n",
      "Val loss: 0.6753 | Val precision: 0.7124 | Val recall: 0.7054 | Val f1score: 0.6867 | Val acc: 0.5894 | Val kappa: 0.3662 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000177978515625\n",
      "Train loss: 0.5996 | Train precision: 0.7445 | Train recall: 0.7408 | Train f1score: 0.7426 | Train acc: 0.6804 | Train kappa: 0.4666 \n",
      "Val loss: 0.6803 | Val precision: 0.7467 | Val recall: 0.7088 | Val f1score: 0.7150 | Val acc: 0.6293 | Val kappa: 0.4227 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00013348388671875\n",
      "Train loss: 0.5911 | Train precision: 0.7511 | Train recall: 0.7418 | Train f1score: 0.7464 | Train acc: 0.6885 | Train kappa: 0.4784 \n",
      "Val loss: 0.6368 | Val precision: 0.7059 | Val recall: 0.7315 | Val f1score: 0.7154 | Val acc: 0.6347 | Val kappa: 0.4325 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0001001129150390625\n",
      "Train loss: 0.5795 | Train precision: 0.7667 | Train recall: 0.7546 | Train f1score: 0.7605 | Train acc: 0.6993 | Train kappa: 0.4982 \n",
      "Val loss: 0.6805 | Val precision: 0.7218 | Val recall: 0.7208 | Val f1score: 0.7111 | Val acc: 0.6218 | Val kappa: 0.4137 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 7.508468627929687e-05\n",
      "Train loss: 0.5689 | Train precision: 0.7665 | Train recall: 0.7663 | Train f1score: 0.7662 | Train acc: 0.7081 | Train kappa: 0.5158 \n",
      "Val loss: 0.6584 | Val precision: 0.7391 | Val recall: 0.7135 | Val f1score: 0.7222 | Val acc: 0.6336 | Val kappa: 0.4294 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 5.6313514709472656e-05\n",
      "Train loss: 0.5670 | Train precision: 0.7635 | Train recall: 0.7609 | Train f1score: 0.7622 | Train acc: 0.7072 | Train kappa: 0.5189 \n",
      "Val loss: 0.6336 | Val precision: 0.7282 | Val recall: 0.7294 | Val f1score: 0.7235 | Val acc: 0.6401 | Val kappa: 0.4358 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 4.223513603210449e-05\n",
      "Train loss: 0.5718 | Train precision: 0.7622 | Train recall: 0.7594 | Train f1score: 0.7606 | Train acc: 0.7069 | Train kappa: 0.5120 \n",
      "Val loss: 0.6330 | Val precision: 0.7510 | Val recall: 0.7258 | Val f1score: 0.7362 | Val acc: 0.6552 | Val kappa: 0.4572 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 3.167635202407837e-05\n",
      "Train loss: 0.5685 | Train precision: 0.7710 | Train recall: 0.7740 | Train f1score: 0.7725 | Train acc: 0.7079 | Train kappa: 0.5107 \n",
      "Val loss: 0.6347 | Val precision: 0.7532 | Val recall: 0.7282 | Val f1score: 0.7380 | Val acc: 0.6573 | Val kappa: 0.4557 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 2.3757264018058778e-05\n",
      "Train loss: 0.5628 | Train precision: 0.7704 | Train recall: 0.7649 | Train f1score: 0.7675 | Train acc: 0.7091 | Train kappa: 0.5180 \n",
      "Val loss: 0.6418 | Val precision: 0.7351 | Val recall: 0.7372 | Val f1score: 0.7332 | Val acc: 0.6552 | Val kappa: 0.4533 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 1.7817948013544083e-05\n",
      "Train loss: 0.5537 | Train precision: 0.7737 | Train recall: 0.7850 | Train f1score: 0.7791 | Train acc: 0.7164 | Train kappa: 0.5244 \n",
      "Val loss: 0.6467 | Val precision: 0.7582 | Val recall: 0.7228 | Val f1score: 0.7358 | Val acc: 0.6466 | Val kappa: 0.4375 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 1.3363461010158063e-05\n",
      "Train loss: 0.5583 | Train precision: 0.7712 | Train recall: 0.7776 | Train f1score: 0.7739 | Train acc: 0.7100 | Train kappa: 0.5101 \n",
      "Val loss: 0.6411 | Val precision: 0.7638 | Val recall: 0.7286 | Val f1score: 0.7432 | Val acc: 0.6584 | Val kappa: 0.4554 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 1.0022595757618546e-05\n",
      "Train loss: 0.5586 | Train precision: 0.7700 | Train recall: 0.7751 | Train f1score: 0.7725 | Train acc: 0.7092 | Train kappa: 0.5124 \n",
      "Val loss: 0.6426 | Val precision: 0.7562 | Val recall: 0.7208 | Val f1score: 0.7352 | Val acc: 0.6466 | Val kappa: 0.4370 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 7.51694681821391e-06\n",
      "Train loss: 0.5623 | Train precision: 0.7751 | Train recall: 0.7711 | Train f1score: 0.7730 | Train acc: 0.7089 | Train kappa: 0.5141 \n",
      "Val loss: 0.6377 | Val precision: 0.7476 | Val recall: 0.7223 | Val f1score: 0.7334 | Val acc: 0.6519 | Val kappa: 0.4468 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.637710113660432e-06\n",
      "Train loss: 0.5595 | Train precision: 0.7722 | Train recall: 0.7767 | Train f1score: 0.7744 | Train acc: 0.7123 | Train kappa: 0.5265 \n",
      "Val loss: 0.6385 | Val precision: 0.7565 | Val recall: 0.7210 | Val f1score: 0.7362 | Val acc: 0.6487 | Val kappa: 0.4400 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 4.228282585245324e-06\n",
      "Train loss: 0.5586 | Train precision: 0.7739 | Train recall: 0.7701 | Train f1score: 0.7718 | Train acc: 0.7082 | Train kappa: 0.5196 \n",
      "Val loss: 0.6433 | Val precision: 0.7532 | Val recall: 0.7178 | Val f1score: 0.7326 | Val acc: 0.6433 | Val kappa: 0.4318 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 3.1712119389339933e-06\n",
      "Train loss: 0.5521 | Train precision: 0.7789 | Train recall: 0.7731 | Train f1score: 0.7758 | Train acc: 0.7175 | Train kappa: 0.5278 \n",
      "Val loss: 0.6463 | Val precision: 0.7436 | Val recall: 0.7184 | Val f1score: 0.7279 | Val acc: 0.6422 | Val kappa: 0.4324 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 2.378408954200495e-06\n",
      "Train loss: 0.5581 | Train precision: 0.7692 | Train recall: 0.7672 | Train f1score: 0.7682 | Train acc: 0.7110 | Train kappa: 0.5099 \n",
      "Val loss: 0.6412 | Val precision: 0.7471 | Val recall: 0.7219 | Val f1score: 0.7310 | Val acc: 0.6466 | Val kappa: 0.4392 \n",
      "\n",
      "Early stopping after epoch 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c766fb05ca4b1e9fead678f8ce0c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▅▆▆▇▇▇▇██████████████</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1_score</td><td>▁▆▇▇█▇▇▇▇█████████████</td></tr><tr><td>val_loss</td><td>▇▄█▇▄▃▄▁▄▂▁▁▁▁▂▁▂▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_f1_score</td><td>0.76818</td></tr><tr><td>train_loss</td><td>0.55812</td></tr><tr><td>val_f1_score</td><td>0.73101</td></tr><tr><td>val_loss</td><td>0.64122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_2_RGB-3classes_health_plotsplit</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/3ca80sjn' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/3ca80sjn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_174009-3ca80sjn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1057682944 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 3\n",
      "TRAIN POSITIVE RATIO: 0.4569357177380377\n",
      "VAL POSITIVE RATIO  : 0.43753846153846154\n",
      "LENGTH TRAIN GROUPS : 155\n",
      "LENGTH VAL GROUPS   : 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230524_192124-m3m5viby</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/m3m5viby' target=\"_blank\">fold_3_RGB-3classes_health_plotsplit</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/m3m5viby' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/m3m5viby</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (10345, 250, 250, 3)\n",
      "Labels train dataset: (10345, 1)\n",
      "\n",
      "Images validation dataset: (1213, 250, 250, 3)\n",
      "Labels validation dataset: (1213, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 5823\n",
      "Stressed trees in train dataset: 4317\n",
      "Dead trees in train dataset: 205\n",
      "Healthy trees in validation dataset: 673\n",
      "Stressed trees in validation dataset: 518\n",
      "Dead trees in validation dataset: 22\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 3\n",
      "\n",
      "Creating dataloaders for fold: 3\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 3\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f475685477174cc2a7ce8616b6f43daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.001\n",
      "Train loss: 0.7292 | Train precision: 0.5921 | Train recall: 0.5921 | Train f1score: 0.5921 | Train acc: 0.5851 | Train kappa: 0.3125 \n",
      "Val loss: 0.7385 | Val precision: 0.7827 | Val recall: 0.3941 | Val f1score: 0.3597 | Val acc: 0.5861 | Val kappa: 0.1296 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00075\n",
      "Train loss: 0.6663 | Train precision: 0.6858 | Train recall: 0.6736 | Train f1score: 0.6789 | Train acc: 0.6425 | Train kappa: 0.4218 \n",
      "Val loss: 0.6432 | Val precision: 0.6297 | Val recall: 0.7579 | Val f1score: 0.6693 | Val acc: 0.6791 | Val kappa: 0.4354 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0005625000000000001\n",
      "Train loss: 0.6385 | Train precision: 0.7146 | Train recall: 0.7165 | Train f1score: 0.7155 | Train acc: 0.6540 | Train kappa: 0.4521 \n",
      "Val loss: 0.6151 | Val precision: 0.7913 | Val recall: 0.7612 | Val f1score: 0.7686 | Val acc: 0.6816 | Val kappa: 0.4428 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.000421875\n",
      "Train loss: 0.6198 | Train precision: 0.7337 | Train recall: 0.7283 | Train f1score: 0.7310 | Train acc: 0.6645 | Train kappa: 0.4771 \n",
      "Val loss: 0.6458 | Val precision: 0.7440 | Val recall: 0.7451 | Val f1score: 0.7417 | Val acc: 0.6630 | Val kappa: 0.4118 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00031640625\n",
      "Train loss: 0.6142 | Train precision: 0.7384 | Train recall: 0.7354 | Train f1score: 0.7367 | Train acc: 0.6721 | Train kappa: 0.4811 \n",
      "Val loss: 0.5938 | Val precision: 0.7567 | Val recall: 0.7581 | Val f1score: 0.7552 | Val acc: 0.6833 | Val kappa: 0.4463 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0002373046875\n",
      "Train loss: 0.5927 | Train precision: 0.7543 | Train recall: 0.7479 | Train f1score: 0.7510 | Train acc: 0.6850 | Train kappa: 0.4936 \n",
      "Val loss: 0.5982 | Val precision: 0.7672 | Val recall: 0.7611 | Val f1score: 0.7497 | Val acc: 0.6757 | Val kappa: 0.4388 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000177978515625\n",
      "Train loss: 0.5855 | Train precision: 0.7519 | Train recall: 0.7504 | Train f1score: 0.7510 | Train acc: 0.6857 | Train kappa: 0.5093 \n",
      "Val loss: 0.5957 | Val precision: 0.7043 | Val recall: 0.7769 | Val f1score: 0.7351 | Val acc: 0.6993 | Val kappa: 0.4721 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00013348388671875\n",
      "Train loss: 0.5668 | Train precision: 0.7714 | Train recall: 0.7735 | Train f1score: 0.7724 | Train acc: 0.7017 | Train kappa: 0.5365 \n",
      "Val loss: 0.6078 | Val precision: 0.7302 | Val recall: 0.7547 | Val f1score: 0.7366 | Val acc: 0.6740 | Val kappa: 0.4357 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0001001129150390625\n",
      "Train loss: 0.5639 | Train precision: 0.7757 | Train recall: 0.7763 | Train f1score: 0.7759 | Train acc: 0.7021 | Train kappa: 0.5355 \n",
      "Val loss: 0.6021 | Val precision: 0.7545 | Val recall: 0.7594 | Val f1score: 0.7530 | Val acc: 0.6816 | Val kappa: 0.4366 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 7.508468627929687e-05\n",
      "Train loss: 0.5584 | Train precision: 0.7784 | Train recall: 0.7721 | Train f1score: 0.7751 | Train acc: 0.7052 | Train kappa: 0.5374 \n",
      "Val loss: 0.6178 | Val precision: 0.6784 | Val recall: 0.7613 | Val f1score: 0.7109 | Val acc: 0.6664 | Val kappa: 0.4268 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 5.6313514709472656e-05\n",
      "Train loss: 0.5556 | Train precision: 0.7725 | Train recall: 0.7755 | Train f1score: 0.7739 | Train acc: 0.7073 | Train kappa: 0.5373 \n",
      "Val loss: 0.6151 | Val precision: 0.7060 | Val recall: 0.7711 | Val f1score: 0.7344 | Val acc: 0.6900 | Val kappa: 0.4593 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 4.223513603210449e-05\n",
      "Train loss: 0.5572 | Train precision: 0.7768 | Train recall: 0.7709 | Train f1score: 0.7737 | Train acc: 0.7114 | Train kappa: 0.5462 \n",
      "Val loss: 0.6083 | Val precision: 0.7368 | Val recall: 0.7619 | Val f1score: 0.7487 | Val acc: 0.6765 | Val kappa: 0.4337 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 3.167635202407837e-05\n",
      "Train loss: 0.5444 | Train precision: 0.7793 | Train recall: 0.7809 | Train f1score: 0.7800 | Train acc: 0.7118 | Train kappa: 0.5447 \n",
      "Val loss: 0.6225 | Val precision: 0.6957 | Val recall: 0.7709 | Val f1score: 0.7276 | Val acc: 0.6850 | Val kappa: 0.4545 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 2.3757264018058778e-05\n",
      "Train loss: 0.5435 | Train precision: 0.7867 | Train recall: 0.7867 | Train f1score: 0.7867 | Train acc: 0.7162 | Train kappa: 0.5630 \n",
      "Val loss: 0.6243 | Val precision: 0.7198 | Val recall: 0.7667 | Val f1score: 0.7412 | Val acc: 0.6833 | Val kappa: 0.4445 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 1.7817948013544083e-05\n",
      "Train loss: 0.5376 | Train precision: 0.7879 | Train recall: 0.7879 | Train f1score: 0.7879 | Train acc: 0.7249 | Train kappa: 0.5608 \n",
      "Val loss: 0.6248 | Val precision: 0.7244 | Val recall: 0.7731 | Val f1score: 0.7461 | Val acc: 0.6875 | Val kappa: 0.4586 \n",
      "\n",
      "Early stopping after epoch 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0aa88b16ed47a3bcdb55452df7343b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▄▅▆▆▇▇▇██▇▇███</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>val_f1_score</td><td>▁▆████▇▇█▇▇█▇██</td></tr><tr><td>val_loss</td><td>█▃▂▄▁▁▁▂▁▂▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_f1_score</td><td>0.7879</td></tr><tr><td>train_loss</td><td>0.53755</td></tr><tr><td>val_f1_score</td><td>0.74608</td></tr><tr><td>val_loss</td><td>0.62485</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_3_RGB-3classes_health_plotsplit</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/m3m5viby' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/m3m5viby</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_192124-m3m5viby\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1051870720 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 4\n",
      "TRAIN POSITIVE RATIO: 0.4568810636004312\n",
      "VAL POSITIVE RATIO  : 0.43158749492488835\n",
      "LENGTH TRAIN GROUPS : 155\n",
      "LENGTH VAL GROUPS   : 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230524_202903-g5bb0ft3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g5bb0ft3' target=\"_blank\">fold_4_RGB-3classes_health_plotsplit</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g5bb0ft3' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g5bb0ft3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (11132, 250, 250, 3)\n",
      "Labels train dataset: (11132, 1)\n",
      "\n",
      "Images validation dataset: (877, 250, 250, 3)\n",
      "Labels validation dataset: (877, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 6259\n",
      "Stressed trees in train dataset: 4660\n",
      "Dead trees in train dataset: 213\n",
      "Healthy trees in validation dataset: 533\n",
      "Stressed trees in validation dataset: 332\n",
      "Dead trees in validation dataset: 12\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 4\n",
      "\n",
      "Creating dataloaders for fold: 4\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 4\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a63654af4d84770b7f3d7ed0bad49c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.001\n",
      "Train loss: 0.7253 | Train precision: 0.5910 | Train recall: 0.5843 | Train f1score: 0.5871 | Train acc: 0.5971 | Train kappa: 0.3224 \n",
      "Val loss: 0.7966 | Val precision: 0.4512 | Val recall: 0.3714 | Val f1score: 0.3309 | Val acc: 0.6424 | Val kappa: 0.1858 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00075\n",
      "Train loss: 0.6605 | Train precision: 0.6853 | Train recall: 0.6764 | Train f1score: 0.6807 | Train acc: 0.6392 | Train kappa: 0.4177 \n",
      "Val loss: 0.6475 | Val precision: 0.7134 | Val recall: 0.5854 | Val f1score: 0.5838 | Val acc: 0.6343 | Val kappa: 0.2232 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0005625000000000001\n",
      "Train loss: 0.6310 | Train precision: 0.7199 | Train recall: 0.7147 | Train f1score: 0.7173 | Train acc: 0.6555 | Train kappa: 0.4581 \n",
      "Val loss: 0.6755 | Val precision: 0.5401 | Val recall: 0.6766 | Val f1score: 0.5827 | Val acc: 0.6262 | Val kappa: 0.3017 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.000421875\n",
      "Train loss: 0.6213 | Train precision: 0.7355 | Train recall: 0.7177 | Train f1score: 0.7263 | Train acc: 0.6610 | Train kappa: 0.4642 \n",
      "Val loss: 0.7767 | Val precision: 0.6743 | Val recall: 0.6059 | Val f1score: 0.5671 | Val acc: 0.5081 | Val kappa: 0.1770 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00031640625\n",
      "Train loss: 0.6034 | Train precision: 0.7459 | Train recall: 0.7374 | Train f1score: 0.7416 | Train acc: 0.6772 | Train kappa: 0.4855 \n",
      "Val loss: 0.6707 | Val precision: 0.6774 | Val recall: 0.7019 | Val f1score: 0.6873 | Val acc: 0.6424 | Val kappa: 0.3419 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0002373046875\n",
      "Train loss: 0.5880 | Train precision: 0.7585 | Train recall: 0.7443 | Train f1score: 0.7512 | Train acc: 0.6839 | Train kappa: 0.5008 \n",
      "Val loss: 0.7417 | Val precision: 0.6498 | Val recall: 0.7084 | Val f1score: 0.6541 | Val acc: 0.5775 | Val kappa: 0.2697 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000177978515625\n",
      "Train loss: 0.5902 | Train precision: 0.7482 | Train recall: 0.7460 | Train f1score: 0.7471 | Train acc: 0.6846 | Train kappa: 0.5004 \n",
      "Val loss: 0.6255 | Val precision: 0.7024 | Val recall: 0.6805 | Val f1score: 0.6909 | Val acc: 0.6632 | Val kappa: 0.3548 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00013348388671875\n",
      "Train loss: 0.5683 | Train precision: 0.7730 | Train recall: 0.7699 | Train f1score: 0.7713 | Train acc: 0.6960 | Train kappa: 0.5221 \n",
      "Val loss: 0.6325 | Val precision: 0.6658 | Val recall: 0.7395 | Val f1score: 0.6972 | Val acc: 0.6725 | Val kappa: 0.3787 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0001001129150390625\n",
      "Train loss: 0.5755 | Train precision: 0.7678 | Train recall: 0.7601 | Train f1score: 0.7639 | Train acc: 0.6970 | Train kappa: 0.5223 \n",
      "Val loss: 0.6362 | Val precision: 0.6750 | Val recall: 0.6640 | Val f1score: 0.6652 | Val acc: 0.6609 | Val kappa: 0.3332 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 7.508468627929687e-05\n",
      "Train loss: 0.5695 | Train precision: 0.7794 | Train recall: 0.7665 | Train f1score: 0.7728 | Train acc: 0.7034 | Train kappa: 0.5318 \n",
      "Val loss: 0.6678 | Val precision: 0.5903 | Val recall: 0.7165 | Val f1score: 0.6355 | Val acc: 0.6400 | Val kappa: 0.3362 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 5.6313514709472656e-05\n",
      "Train loss: 0.5519 | Train precision: 0.7872 | Train recall: 0.7788 | Train f1score: 0.7829 | Train acc: 0.7196 | Train kappa: 0.5585 \n",
      "Val loss: 0.6513 | Val precision: 0.6424 | Val recall: 0.7196 | Val f1score: 0.6746 | Val acc: 0.6331 | Val kappa: 0.3247 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 4.223513603210449e-05\n",
      "Train loss: 0.5561 | Train precision: 0.7791 | Train recall: 0.7770 | Train f1score: 0.7781 | Train acc: 0.7079 | Train kappa: 0.5400 \n",
      "Val loss: 0.6517 | Val precision: 0.6441 | Val recall: 0.7019 | Val f1score: 0.6681 | Val acc: 0.6424 | Val kappa: 0.3354 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 3.167635202407837e-05\n",
      "Train loss: 0.5455 | Train precision: 0.7884 | Train recall: 0.7824 | Train f1score: 0.7854 | Train acc: 0.7154 | Train kappa: 0.5504 \n",
      "Val loss: 0.6510 | Val precision: 0.6678 | Val recall: 0.7315 | Val f1score: 0.6937 | Val acc: 0.6435 | Val kappa: 0.3525 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 2.3757264018058778e-05\n",
      "Train loss: 0.5484 | Train precision: 0.7852 | Train recall: 0.7808 | Train f1score: 0.7830 | Train acc: 0.7130 | Train kappa: 0.5501 \n",
      "Val loss: 0.6436 | Val precision: 0.7007 | Val recall: 0.7036 | Val f1score: 0.7013 | Val acc: 0.6493 | Val kappa: 0.3403 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 1.7817948013544083e-05\n",
      "Train loss: 0.5463 | Train precision: 0.7864 | Train recall: 0.7746 | Train f1score: 0.7803 | Train acc: 0.7126 | Train kappa: 0.5469 \n",
      "Val loss: 0.6494 | Val precision: 0.6850 | Val recall: 0.7313 | Val f1score: 0.7049 | Val acc: 0.6470 | Val kappa: 0.3520 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 1.3363461010158063e-05\n",
      "Train loss: 0.5509 | Train precision: 0.7839 | Train recall: 0.7749 | Train f1score: 0.7793 | Train acc: 0.7102 | Train kappa: 0.5437 \n",
      "Val loss: 0.6390 | Val precision: 0.6800 | Val recall: 0.7022 | Val f1score: 0.6905 | Val acc: 0.6528 | Val kappa: 0.3448 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 1.0022595757618546e-05\n",
      "Train loss: 0.5441 | Train precision: 0.7889 | Train recall: 0.7821 | Train f1score: 0.7854 | Train acc: 0.7161 | Train kappa: 0.5521 \n",
      "Val loss: 0.6508 | Val precision: 0.6756 | Val recall: 0.6998 | Val f1score: 0.6859 | Val acc: 0.6412 | Val kappa: 0.3316 \n",
      "\n",
      "Early stopping after epoch 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6249679272f4a3f919df22880867097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.119974…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▄▆▆▆▇▇█▇████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_f1_score</td><td>▁▆▆▅█▇██▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▂▃▇▃▆▁▁▁▃▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>train_f1_score</td><td>0.7854</td></tr><tr><td>train_loss</td><td>0.54412</td></tr><tr><td>val_f1_score</td><td>0.68591</td></tr><tr><td>val_loss</td><td>0.65084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_4_RGB-3classes_health_plotsplit</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g5bb0ft3' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/g5bb0ft3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_202903-g5bb0ft3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1053745664 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "Fold : 5\n",
      "TRAIN POSITIVE RATIO: 0.4494402812471089\n",
      "VAL POSITIVE RATIO  : 0.4633883704235463\n",
      "LENGTH TRAIN GROUPS : 154\n",
      "LENGTH VAL GROUPS   : 40\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\wandb\\run-20230524_214905-inhir7yy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/inhir7yy' target=\"_blank\">fold_5_RGB-3classes_health_plotsplit</a></strong> to <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/inhir7yy' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/inhir7yy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no same hash_id values in train, val or test datasets. The datasplit was successful\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (10809, 250, 250, 3)\n",
      "Labels train dataset: (10809, 1)\n",
      "\n",
      "Images validation dataset: (1040, 250, 250, 3)\n",
      "Labels validation dataset: (1040, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 6150\n",
      "Stressed trees in train dataset: 4460\n",
      "Dead trees in train dataset: 199\n",
      "Healthy trees in validation dataset: 586\n",
      "Stressed trees in validation dataset: 436\n",
      "Dead trees in validation dataset: 18\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 5\n",
      "\n",
      "Creating dataloaders for fold: 5\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "\n",
      "[INFO] Fold number: 5\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.75\n",
      "[INFO] Memory allocated: 0 bytes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcaafdb873647b49c00432e8cc2480a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.001\n",
      "Train loss: 0.7245 | Train precision: 0.5957 | Train recall: 0.5842 | Train f1score: 0.5895 | Train acc: 0.5914 | Train kappa: 0.2984 \n",
      "Val loss: 0.7284 | Val precision: 0.4215 | Val recall: 0.4098 | Val f1score: 0.4012 | Val acc: 0.6348 | Val kappa: 0.2547 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.00075\n",
      "Train loss: 0.6624 | Train precision: 0.6836 | Train recall: 0.6819 | Train f1score: 0.6823 | Train acc: 0.6457 | Train kappa: 0.4167 \n",
      "Val loss: 0.6630 | Val precision: 0.6561 | Val recall: 0.6718 | Val f1score: 0.6301 | Val acc: 0.6387 | Val kappa: 0.3403 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.0005625000000000001\n",
      "Train loss: 0.6378 | Train precision: 0.7075 | Train recall: 0.7153 | Train f1score: 0.7111 | Train acc: 0.6557 | Train kappa: 0.4380 \n",
      "Val loss: 0.6547 | Val precision: 0.6692 | Val recall: 0.6828 | Val f1score: 0.6695 | Val acc: 0.6348 | Val kappa: 0.3647 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.000421875\n",
      "Train loss: 0.6231 | Train precision: 0.7302 | Train recall: 0.7245 | Train f1score: 0.7272 | Train acc: 0.6653 | Train kappa: 0.4671 \n",
      "Val loss: 0.7097 | Val precision: 0.6858 | Val recall: 0.6682 | Val f1score: 0.6427 | Val acc: 0.5928 | Val kappa: 0.3045 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.00031640625\n",
      "Train loss: 0.6112 | Train precision: 0.7399 | Train recall: 0.7339 | Train f1score: 0.7367 | Train acc: 0.6708 | Train kappa: 0.4718 \n",
      "Val loss: 0.6415 | Val precision: 0.6702 | Val recall: 0.6714 | Val f1score: 0.6703 | Val acc: 0.6572 | Val kappa: 0.3890 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0002373046875\n",
      "Train loss: 0.5925 | Train precision: 0.7508 | Train recall: 0.7485 | Train f1score: 0.7495 | Train acc: 0.6821 | Train kappa: 0.4943 \n",
      "Val loss: 0.6467 | Val precision: 0.6919 | Val recall: 0.6579 | Val f1score: 0.6611 | Val acc: 0.6191 | Val kappa: 0.3352 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.000177978515625\n",
      "Train loss: 0.5896 | Train precision: 0.7656 | Train recall: 0.7527 | Train f1score: 0.7589 | Train acc: 0.6891 | Train kappa: 0.5039 \n",
      "Val loss: 0.6183 | Val precision: 0.6774 | Val recall: 0.6829 | Val f1score: 0.6759 | Val acc: 0.6631 | Val kappa: 0.3959 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.00013348388671875\n",
      "Train loss: 0.5914 | Train precision: 0.7550 | Train recall: 0.7526 | Train f1score: 0.7538 | Train acc: 0.6866 | Train kappa: 0.4940 \n",
      "Val loss: 0.6445 | Val precision: 0.6588 | Val recall: 0.7212 | Val f1score: 0.6751 | Val acc: 0.6309 | Val kappa: 0.3651 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0001001129150390625\n",
      "Train loss: 0.5799 | Train precision: 0.7675 | Train recall: 0.7606 | Train f1score: 0.7637 | Train acc: 0.6913 | Train kappa: 0.5013 \n",
      "Val loss: 0.6260 | Val precision: 0.6570 | Val recall: 0.7076 | Val f1score: 0.6795 | Val acc: 0.6592 | Val kappa: 0.3983 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 7.508468627929687e-05\n",
      "Train loss: 0.5667 | Train precision: 0.7756 | Train recall: 0.7693 | Train f1score: 0.7724 | Train acc: 0.7000 | Train kappa: 0.5341 \n",
      "Val loss: 0.6357 | Val precision: 0.6635 | Val recall: 0.6960 | Val f1score: 0.6742 | Val acc: 0.6543 | Val kappa: 0.3849 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 5.6313514709472656e-05\n",
      "Train loss: 0.5763 | Train precision: 0.7739 | Train recall: 0.7595 | Train f1score: 0.7665 | Train acc: 0.6962 | Train kappa: 0.5103 \n",
      "Val loss: 0.6272 | Val precision: 0.6579 | Val recall: 0.7092 | Val f1score: 0.6807 | Val acc: 0.6592 | Val kappa: 0.3947 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 4.223513603210449e-05\n",
      "Train loss: 0.5657 | Train precision: 0.7777 | Train recall: 0.7634 | Train f1score: 0.7704 | Train acc: 0.7030 | Train kappa: 0.5266 \n",
      "Val loss: 0.6176 | Val precision: 0.6854 | Val recall: 0.7107 | Val f1score: 0.6965 | Val acc: 0.6689 | Val kappa: 0.4130 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 3.167635202407837e-05\n",
      "Train loss: 0.5641 | Train precision: 0.7815 | Train recall: 0.7749 | Train f1score: 0.7781 | Train acc: 0.7044 | Train kappa: 0.5259 \n",
      "Val loss: 0.6292 | Val precision: 0.6912 | Val recall: 0.7065 | Val f1score: 0.6986 | Val acc: 0.6562 | Val kappa: 0.3926 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 2.3757264018058778e-05\n",
      "Train loss: 0.5607 | Train precision: 0.7802 | Train recall: 0.7763 | Train f1score: 0.7782 | Train acc: 0.7090 | Train kappa: 0.5349 \n",
      "Val loss: 0.6256 | Val precision: 0.6820 | Val recall: 0.7097 | Val f1score: 0.6950 | Val acc: 0.6631 | Val kappa: 0.4055 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 1.7817948013544083e-05\n",
      "Train loss: 0.5705 | Train precision: 0.7693 | Train recall: 0.7684 | Train f1score: 0.7689 | Train acc: 0.6947 | Train kappa: 0.5097 \n",
      "Val loss: 0.6224 | Val precision: 0.6844 | Val recall: 0.7115 | Val f1score: 0.6970 | Val acc: 0.6670 | Val kappa: 0.4115 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 1.3363461010158063e-05\n",
      "Train loss: 0.5569 | Train precision: 0.7774 | Train recall: 0.7739 | Train f1score: 0.7756 | Train acc: 0.7076 | Train kappa: 0.5429 \n",
      "Val loss: 0.6285 | Val precision: 0.6711 | Val recall: 0.7094 | Val f1score: 0.6883 | Val acc: 0.6650 | Val kappa: 0.4044 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 1.0022595757618546e-05\n",
      "Train loss: 0.5557 | Train precision: 0.7845 | Train recall: 0.7801 | Train f1score: 0.7823 | Train acc: 0.7134 | Train kappa: 0.5490 \n",
      "Val loss: 0.6296 | Val precision: 0.6701 | Val recall: 0.7095 | Val f1score: 0.6881 | Val acc: 0.6631 | Val kappa: 0.4075 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 7.51694681821391e-06\n",
      "Train loss: 0.5553 | Train precision: 0.7829 | Train recall: 0.7787 | Train f1score: 0.7808 | Train acc: 0.7124 | Train kappa: 0.5546 \n",
      "Val loss: 0.6290 | Val precision: 0.6695 | Val recall: 0.7091 | Val f1score: 0.6876 | Val acc: 0.6621 | Val kappa: 0.4061 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.637710113660432e-06\n",
      "Train loss: 0.5574 | Train precision: 0.7854 | Train recall: 0.7760 | Train f1score: 0.7806 | Train acc: 0.7086 | Train kappa: 0.5370 \n",
      "Val loss: 0.6248 | Val precision: 0.6722 | Val recall: 0.7097 | Val f1score: 0.6887 | Val acc: 0.6670 | Val kappa: 0.4121 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 4.228282585245324e-06\n",
      "Train loss: 0.5513 | Train precision: 0.7795 | Train recall: 0.7834 | Train f1score: 0.7814 | Train acc: 0.7128 | Train kappa: 0.5444 \n",
      "Val loss: 0.6249 | Val precision: 0.6843 | Val recall: 0.7108 | Val f1score: 0.6964 | Val acc: 0.6670 | Val kappa: 0.4109 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 3.1712119389339933e-06\n",
      "Train loss: 0.5534 | Train precision: 0.7868 | Train recall: 0.7746 | Train f1score: 0.7806 | Train acc: 0.7078 | Train kappa: 0.5401 \n",
      "Val loss: 0.6273 | Val precision: 0.6842 | Val recall: 0.7104 | Val f1score: 0.6961 | Val acc: 0.6670 | Val kappa: 0.4105 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 2.378408954200495e-06\n",
      "Train loss: 0.5626 | Train precision: 0.7794 | Train recall: 0.7794 | Train f1score: 0.7793 | Train acc: 0.7073 | Train kappa: 0.5307 \n",
      "Val loss: 0.6286 | Val precision: 0.6824 | Val recall: 0.7094 | Val f1score: 0.6949 | Val acc: 0.6641 | Val kappa: 0.4063 \n",
      "\n",
      "Early stopping after epoch 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0a705229bc4eb399a1c63b987cc969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_f1_score</td><td>▁▄▅▆▆▇▇▇▇█▇███████████</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_f1_score</td><td>▁▆▇▇▇▇▇▇█▇████████████</td></tr><tr><td>val_loss</td><td>█▄▃▇▃▃▁▃▂▂▂▁▂▂▁▂▂▂▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_f1_score</td><td>0.77934</td></tr><tr><td>train_loss</td><td>0.5626</td></tr><tr><td>val_f1_score</td><td>0.69494</td></tr><tr><td>val_loss</td><td>0.62858</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_5_RGB-3classes_health_plotsplit</strong> at: <a href='https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/inhir7yy' target=\"_blank\">https://wandb.ai/simon-ecke/wze-uav-health-3classes/runs/inhir7yy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230524_214905-inhir7yy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting variables and emptying cache\n",
      "Memory allocated: 1051714048 bytes\n",
      "--------------------------------------------------\n",
      "\n",
      "CPU times: total: 3h 39min 21s\n",
      "Wall time: 7h 36min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set the random seeds\n",
    "set_seeds(42)\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "# group the hashIDs to get the unique values of hashIDs remaining in the subset  \n",
    "groups = sub_hash_id[:, 0] \n",
    "print(\"ORIGINAL POSITIVE RATIO:\", sub_label_set.mean())\n",
    "# create a StratifiedGroupKFold instance\n",
    "kf = StratifiedGroupKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# loop through the folds\n",
    "for fold, (train_ids, val_ids) in enumerate(kf.split(sub_image_set, sub_label_set, groups)):\n",
    "    print(\"Fold :\", fold+1)\n",
    "    print(\"TRAIN POSITIVE RATIO:\", sub_label_set[train_ids].mean())\n",
    "    print(\"VAL POSITIVE RATIO  :\", sub_label_set[val_ids].mean())\n",
    "    print(\"LENGTH TRAIN GROUPS :\", len(set(groups[train_ids])))\n",
    "    print(\"LENGTH VAL GROUPS   :\", len(set(groups[val_ids])))\n",
    "    \n",
    "    train_ids = sub_hash_id[:, 0][train_ids]\n",
    "    val_ids = np.unique(sub_hash_id[:, 0][val_ids])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Initialize a new wandb run for this fold\n",
    "    wandb.init(project='wze-uav-health-3classes', name=f\"fold_{fold + 1}_{extra}\")\n",
    "    \n",
    "    # 1. Split data into train and validation set\n",
    "    # Get the training and testing data for this fold\n",
    "    # Use np.isin() to create boolean arrays indicating which indices belong to train or test sets\n",
    "    train_indices = np.isin(sub_hash_id[:,0], train_ids)\n",
    "    \n",
    "    val_indices = np.zeros_like(train_indices)  # initialize to all False\n",
    "    for hash_id_val in val_ids:\n",
    "        # select one image ID randomly from either 2020 or 2021 or 2022 for each unique hash ID in the test set\n",
    "        temp = np.unique(sub_hash_id[(sub_hash_id[:, 0] == hash_id_val), 1]) # check how many years are available per hashID\n",
    "        if len(temp) == 1:\n",
    "            year = temp[0]\n",
    "        elif len(temp) == 2:\n",
    "            year = np.random.choice(temp)\n",
    "        else:\n",
    "            year = np.random.choice(temp)\n",
    "        \n",
    "        # select image ID using the conditions\n",
    "        image_ids = sub_hash_id[(sub_hash_id[:,0] == hash_id_val) & (sub_hash_id[:,1] == year), 0]\n",
    "    \n",
    "        # mark the index corresponding to the selected image ID and hash ID as True in the test indices array\n",
    "        val_indices[(sub_hash_id[:,0] == hash_id_val) & (sub_hash_id[:,1] == year) & (np.isin(sub_hash_id[:,0], image_ids))] = True \n",
    "    \n",
    "    # Reshape boolean arrays to match shape of image_set and label_set\n",
    "    train_indices = train_indices.reshape(-1, 1)\n",
    "    val_indices = val_indices.reshape(-1, 1)\n",
    "    \n",
    "    # Select images and labels for train and validation sets\n",
    "    train_image_set = sub_image_set[train_indices[:, 0]]\n",
    "    train_label_set = sub_label_set[train_indices[:, 0]]\n",
    "    train_hash_id = sub_hash_id[train_indices[:, 0]][:,0]\n",
    "    train_species_set = sub_species_set[train_indices[:, 0]]\n",
    "    val_image_set = sub_image_set[val_indices[:, 0]]\n",
    "    val_label_set = sub_label_set[val_indices[:, 0]]\n",
    "    val_hash_id = sub_hash_id[val_indices[:, 0]][:,0]\n",
    "    val_species_set = sub_species_set[val_indices[:, 0]]\n",
    "    # reshape \n",
    "    train_label_set = train_label_set.reshape(-1, 1)\n",
    "    val_label_set = val_label_set.reshape(-1, 1)\n",
    "    train_species_set = train_species_set.reshape(-1, 1)\n",
    "    val_species_set = val_species_set.reshape(-1, 1)\n",
    "    \n",
    "    # check if there are any group overlaps between the data splits\n",
    "    hash_set = set(train_hash_id)\n",
    "    val_hash_set = set(val_hash_id)\n",
    "    test_hash_set = set(test_hash_id[:, 0].flatten())\n",
    "    intersection = hash_set.intersection(val_hash_set)\n",
    "    intersection2 = test_hash_set.intersection(val_hash_set)\n",
    "    intersection3 = hash_set.intersection(test_hash_set)\n",
    "    if intersection:\n",
    "        print(f\"Hash_id values in both train and val sets: {len(intersection)}\")\n",
    "        print(f\"Hash_id values in both test and val sets: {len(intersection2)}\")\n",
    "        print(f\"Hash_id values in both train and test sets: {len(intersection3)}\")\n",
    "    else:\n",
    "        print(\"There are no same hash_id values in train, val or test datasets. The datasplit was successful\")\n",
    "    \n",
    "         \n",
    "    print(\"Check shapes:\\n\")\n",
    "    print(f\"Images train dataset: {train_image_set.shape}\")\n",
    "    print(f\"Labels train dataset: {train_label_set.shape}\\n\")\n",
    "    \n",
    "    print(f\"Images validation dataset: {val_image_set.shape}\")\n",
    "    print(f\"Labels validation dataset: {val_label_set.shape}\\n\")\n",
    "    print('-'*50)\n",
    "    print (f\"Check if the split was stratified: (random_state=42)\")\n",
    "   #print(f\"Picea abies healthy in train dataset: {np.count_nonzero(train_label_set == 0)}\")\n",
    "   #print(f\"Picea abies stressed in train dataset: {np.count_nonzero(train_label_set == 1)}\")\n",
    "   #print(f\"Pinus sylvestris healthy in train dataset: {np.count_nonzero(train_label_set == 2)}\")\n",
    "   #print(f\"Pinus sylvestris stressed in train dataset: {np.count_nonzero(train_label_set == 3)}\")\n",
    "   #print(f\"Abies alba healthy in train dataset: {np.count_nonzero(train_label_set == 4)}\")\n",
    "   #print(f\"Abies alba stressed in train dataset: {np.count_nonzero(train_label_set == 5)}\")\n",
    "   #print(f\"Fagus sylvatica healthy in train dataset: {np.count_nonzero(train_label_set == 6)}\")\n",
    "   #print(f\"Fagus sylvatica stressed in train dataset: {np.count_nonzero(train_label_set == 7)}\")\n",
    "   #print(f\"Quercus robur/petraea healthy in train dataset: {np.count_nonzero(train_label_set == 8)}\")\n",
    "   #print(f\"Quercus robur/petraea stressed in train dataset: {np.count_nonzero(train_label_set == 9)}\")\n",
    "   #print(f\"Larix spp. in train dataset: {np.count_nonzero(train_label_set == 10)}\")\n",
    "   #print(f\"Acer spp. in train dataset: {np.count_nonzero(train_label_set == 11)}\")\n",
    "   #print(f\"Betula pendula in train dataset: {np.count_nonzero(train_label_set == 12)}\")\n",
    "    print(f\"Healthy trees in train dataset: {np.count_nonzero(train_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in train dataset: {np.count_nonzero(train_label_set == 1)}\")\n",
    "    print(f\"Dead trees in train dataset: {np.count_nonzero(train_label_set == 2)}\")\n",
    "    #print(f\"Picea abies healthy in validation dataset: {np.count_nonzero(val_label_set == 0)}\")\n",
    "    #print(f\"Picea abies stressed in validation dataset: {np.count_nonzero(val_label_set == 1)}\")\n",
    "    #print(f\"Pinus sylvestris healthy in validation dataset: {np.count_nonzero(val_label_set == 2)}\")\n",
    "    #print(f\"Pinus sylvestris stressed in validation dataset: {np.count_nonzero(val_label_set == 3)}\")\n",
    "    #print(f\"Abies alba healthy in validation dataset: {np.count_nonzero(val_label_set == 4)}\")\n",
    "    #print(f\"Abies alba stressed in validation dataset: {np.count_nonzero(val_label_set == 5)}\")\n",
    "    #print(f\"Fagus sylvatica healthy in validation dataset: {np.count_nonzero(val_label_set == 6)}\")\n",
    "    #print(f\"Fagus sylvatica stressed in validation dataset: {np.count_nonzero(val_label_set == 7)}\")\n",
    "    #print(f\"Quercus robur/petraea healthy in validation dataset: {np.count_nonzero(val_label_set == 8)}\")\n",
    "    #print(f\"Quercus robur/petraea stressed in validation dataset: {np.count_nonzero(val_label_set == 9)}\")\n",
    "    #print(f\"Larix spp. in validation dataset: {np.count_nonzero(val_label_set == 10)}\")\n",
    "    #print(f\"Acer spp. in validation dataset: {np.count_nonzero(val_label_set == 11)}\")\n",
    "    #print(f\"Betula pendula in validation dataset: {np.count_nonzero(val_label_set == 12)}\")\n",
    "    print(f\"Healthy trees in validation dataset: {np.count_nonzero(val_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)}\")\n",
    "    print(f\"Dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)}\")\n",
    "    #print(f\"Ratio health trees in validation dataset: {np.count_nonzero(val_label_set == 0)/np.count_nonzero(sub_label_set == 0)}\")\n",
    "    #print(f\"Ratio moderately stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)/np.count_nonzero(sub_label_set == 1)}\")\n",
    "    #print(f\"Ratio severely stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)/np.count_nonzero(sub_label_set == 2)}\")\n",
    "    #print(f\"Ratio dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)/np.count_nonzero(sub_label_set == 3)}\")\n",
    "    print(\"-\"*50)\n",
    "   \n",
    "    # 2. Create train and validation dataset. (choose custom dataset loader with 3 - 5 classes)\n",
    "    print(f\"\\nCreating datasets for fold: {fold + 1}\\n\")\n",
    "    train_dataset = data_loader.CustomDataset(data=train_image_set, labels=train_label_set, class_names=class_names, species = train_species_set,\n",
    "                                                         transform=transform_train)\n",
    "    \n",
    "    val_dataset = data_loader.CustomDataset(data=val_image_set, labels=val_label_set, class_names=class_names,\n",
    "                                                       species = val_species_set, transform=transform)\n",
    "   \n",
    "    # 3. Create train and validation dataloader\n",
    "    # create sampler for oversampling of the minority classes\n",
    "    sampler = data_loader.data_sampler(dataset=train_dataset, class_names=class_names)\n",
    "    print(f\"Creating dataloaders for fold: {fold +1}\\n\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, generator=g,\n",
    "                              sampler=sampler, shuffle=False, drop_last=True) # shuffle false because of the sampler\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, shuffle=False,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    model = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "    #model = models.create_effnetb7(output_shape=num_classes, unfreeze=True, dropout_rate=dropout_rate, device=device)\n",
    "   \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    lr_scheduler = CustomExponentialLR(optimizer, gamma=gamma, min_lr=min_lr)\n",
    "\n",
    "    fold += 1\n",
    "    print(f\"\\n[INFO] Fold number: {fold}\")\n",
    "    print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "    print(f\"[INFO] Batch_size: {batch_size}\")\n",
    "    print(f\"[INFO] Number of bands: {n_bands}\")\n",
    "    print(f\"[INFO] Dropout rate: {dropout_rate}\")\n",
    "    print(f\"[INFO] Gamma learning rate: {gamma}\")\n",
    "    print(f\"[INFO] Memory allocated: {torch.cuda.memory_allocated()} bytes\")\n",
    "    # 4. Train model with k fold dataloaders and track experiments\n",
    "    \n",
    "    if fold == 1:\n",
    "        fold1_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "       \n",
    "    elif fold == 2:\n",
    "        fold2_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    elif fold == 3:\n",
    "        fold3_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    elif fold == 4:\n",
    "        fold4_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    else:\n",
    "        fold5_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=None, early_stop_patience = patience)\n",
    "    \n",
    "    del train_indices, val_indices, train_image_set, train_label_set, train_hash_id, train_species_set, val_image_set, val_label_set, val_hash_id, val_species_set,\n",
    "    train_dataset, val_dataset, sampler, train_dataloader, val_dataloader, model, loss_fn, optimizer, lr_scheduler\n",
    "    \n",
    "    #finish the wandb run\n",
    "    wandb.finish()\n",
    "    print(\"Deleting variables and emptying cache\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\")\n",
    "    print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609fc3db",
   "metadata": {},
   "source": [
    "#### Create test dataset and test dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0c36ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = data_loader.CustomTestDataset(\n",
    "    data = test_image_set,\n",
    "    labels = test_label_set,\n",
    "    class_names=class_names, \n",
    "    species = test_species_set,\n",
    "    kkl = None,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# create test dataloader\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             persistent_workers=True,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdaac7",
   "metadata": {},
   "source": [
    "#### Perform ensembling of the five best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67db5af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71       674\n",
      "           1       0.51      0.69      0.59       365\n",
      "           2       0.78      0.95      0.86        22\n",
      "\n",
      "    accuracy                           0.66      1061\n",
      "   macro avg       0.69      0.76      0.72      1061\n",
      "weighted avg       0.70      0.66      0.67      1061\n",
      "\n",
      "[[429 243   2]\n",
      " [109 252   4]\n",
      " [  0   1  21]]\n"
     ]
    }
   ],
   "source": [
    "# Setup the best model filepaths\n",
    "best_model1_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\models\\EffNet_b7_RGB-3classes_health_plotsplit\\1_EffNet_b7_RGB-3classes_health_plotsplit_12_epochs.pth\"\n",
    "best_model2_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\models\\EffNet_b7_RGB-3classes_health_plotsplit\\2_EffNet_b7_RGB-3classes_health_plotsplit_12_epochs.pth\"\n",
    "best_model3_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\models\\EffNet_b7_RGB-3classes_health_plotsplit\\3_EffNet_b7_RGB-3classes_health_plotsplit_5_epochs.pth\"\n",
    "best_model4_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\models\\EffNet_b7_RGB-3classes_health_plotsplit\\4_EffNet_b7_RGB-3classes_health_plotsplit_7_epochs.pth\"\n",
    "best_model5_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\models\\EffNet_b7_RGB-3classes_health_plotsplit\\5_EffNet_b7_RGB-3classes_health_plotsplit_12_epochs.pth\"\n",
    "\n",
    "# Instantiate a new instance of EffNetB7 (to load the saved state_dict() to)\n",
    "#model1 = models.create_effnetb7(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "#model2 = models.create_effnetb7(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "#model3 = models.create_effnetb7(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "#model4 = models.create_effnetb7(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "#model5 = models.create_effnetb7(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "# for custom models with more than three bands as input\n",
    "model1 = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "model2 = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "model3 = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "model4 = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "model5 = model_effnet.EfficientNet.from_pretrained('efficientnet-b7', in_channels=n_bands, num_classes=num_classes, dropout_rate=dropout_rate)\n",
    "\n",
    "# Load the saved best model state_dict()\n",
    "model1.load_state_dict(torch.load(best_model1_path))\n",
    "model2.load_state_dict(torch.load(best_model2_path))\n",
    "model3.load_state_dict(torch.load(best_model3_path))\n",
    "model4.load_state_dict(torch.load(best_model4_path))\n",
    "model5.load_state_dict(torch.load(best_model5_path))\n",
    "\n",
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)\n",
    "model4.to(device)\n",
    "model5.to(device)\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()\n",
    "\n",
    "# Initialize the lists to store the predictions\n",
    "all_preds_model1 = []\n",
    "all_preds_model2 = []\n",
    "all_preds_model3 = []\n",
    "all_preds_model4 = []\n",
    "all_preds_model5 = []\n",
    "all_true_labels = []\n",
    "\n",
    "# Loop through the test dataset and generate predictions for each model\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs, labels, species = batch\n",
    "        inputs, labels, species = inputs.to(device), labels.to(device), species\n",
    "        \n",
    "        # Generate predictions for each model\n",
    "        preds_model1 = model1(inputs)\n",
    "        preds_model2 = model2(inputs)\n",
    "        preds_model3 = model3(inputs)\n",
    "        preds_model4 = model4(inputs)\n",
    "        preds_model5 = model5(inputs)\n",
    "\n",
    "        # Append the predictions to the corresponding list\n",
    "        all_preds_model1.append(preds_model1.cpu().numpy())\n",
    "        all_preds_model2.append(preds_model2.cpu().numpy())\n",
    "        all_preds_model3.append(preds_model3.cpu().numpy())\n",
    "        all_preds_model4.append(preds_model4.cpu().numpy())\n",
    "        all_preds_model5.append(preds_model5.cpu().numpy())\n",
    "        \n",
    "        all_true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate the predictions from all the models\n",
    "all_preds_model1 = np.concatenate(all_preds_model1)\n",
    "all_preds_model2 = np.concatenate(all_preds_model2)\n",
    "all_preds_model3 = np.concatenate(all_preds_model3)\n",
    "all_preds_model4 = np.concatenate(all_preds_model4)\n",
    "all_preds_model5 = np.concatenate(all_preds_model5)\n",
    "\n",
    "all_true_labels = np.concatenate(all_true_labels)\n",
    "\n",
    "# Calculate the ensemble predictions\n",
    "ensemble_preds = np.mean([all_preds_model1, all_preds_model2, all_preds_model3, all_preds_model4, all_preds_model5], axis=0)\n",
    "ensemble_labels = np.argmax(ensemble_preds, axis=1)\n",
    "\n",
    "# Calculate the evaluation metrics for the ensemble model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(all_true_labels, ensemble_labels))\n",
    "print(confusion_matrix(all_true_labels, ensemble_labels))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dfbc663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.64      0.71       674\n",
      "           1       0.51      0.69      0.59       365\n",
      "           2       0.78      0.95      0.86        22\n",
      "\n",
      "    accuracy                           0.66      1061\n",
      "   macro avg       0.69      0.76      0.72      1061\n",
      "weighted avg       0.70      0.66      0.67      1061\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Calculate the evaluation metrics for the ensemble model\n",
    "\n",
    "report = classification_report(all_true_labels, ensemble_labels)\n",
    "print(report)\n",
    "#print(confusion_matrix(all_true_labels, ensemble_labels))\n",
    "\n",
    "# Save the report to a file\n",
    "with open(r'C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\plots\\report_RGB_health_3classes_plotsplit.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "labels = np.array([0,1,2])\n",
    "confmat = confusion_matrix(all_true_labels, ensemble_labels, labels=labels)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat, # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");\n",
    "\n",
    "# add title to confusion matrix plot\n",
    "plt.title(\"Main tree species and Health Status Classification using RGB Bands\", fontsize=16)\n",
    "\n",
    "fig.savefig(r'C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\plots\\confmat_RGB_health_3classes_plotsplit.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Create a DataFrame from the confusion matrix\n",
    "df_cm = pd.DataFrame(confmat)\n",
    "\n",
    "# Export the confusion matrix to a CSV file\n",
    "df_cm.to_csv(r'C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\plots\\confmat_RGB_health_3classes_plotsplit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab9e321",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2. Setup confusion matrix instance and compare predictions to targets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#from wze_uav.analysis import *\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds \u001b[38;5;241m=\u001b[39m make_predictions(model\u001b[38;5;241m=\u001b[39m\u001b[43mbest_model\u001b[49m,\n\u001b[0;32m      4\u001b[0m                                  test_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader, \n\u001b[0;32m      5\u001b[0m                                  device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      7\u001b[0m y_labels_tensor \u001b[38;5;241m=\u001b[39m y_labels_tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      8\u001b[0m y_pred_tensor \u001b[38;5;241m=\u001b[39m y_pred_tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "#from wze_uav.analysis import *\n",
    "y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds = make_predictions(model=best_model,\n",
    "                                 test_dataloader=test_dataloader, \n",
    "                                 device=device)\n",
    "\n",
    "y_labels_tensor = y_labels_tensor.detach().cpu().numpy()\n",
    "y_pred_tensor = y_pred_tensor.detach().cpu().numpy()\n",
    "\n",
    "#confmat = ConfusionMatrix(num_classes=num_classes, task='multiclass')\n",
    "#confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "#                         target=test_labels)\n",
    "labels = np.array([0,1,2])\n",
    "confmat = confusion_matrix(y_labels_tensor, y_pred_tensor, labels=labels)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat, # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test recall: {test_recall}\")\n",
    "print(f\"Test F1score: {test_f1_score}\")\n",
    "#print(f\"Test Kappa: {test_kappa}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Logits: {y_logit}\")\n",
    "print(f\"Test Predictions: {y_pred}\")\n",
    "print(f\"Test Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4173b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_set.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c195b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da05604",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_labels = []\n",
    "labels = np.array([0,1,2])\n",
    "test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "count = 0\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logit = model(X)\n",
    "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_labels.append(y.cpu())\n",
    "        \n",
    "        #other metrics\n",
    "        test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "        y_pred_class = y_pred.detach().cpu().numpy() \n",
    "        y_class = y.detach().cpu().numpy()\n",
    "        test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        \n",
    "        #if count >= 1:\n",
    "        #    y_set = torch.cat((y_set, y))\n",
    "        #    count = count + 1\n",
    "        #else:\n",
    "        #    y_set = y\n",
    "        #    count = count + 1\n",
    "        \n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_precision = test_precision / len(test_dataloader)\n",
    "test_recall = test_recall / len(test_dataloader)\n",
    "#test_f1_score = test_f1_score / len(test_dataloader)\n",
    "#test_kappa = test_kappa / len(dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "test_f1_score = f1_score(y_set.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=0, labels=[0,1,2])\n",
    "\n",
    "# Print classification report\n",
    "y_true = y_set.detach().cpu().numpy()\n",
    "report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae97fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebafd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make = (y_class == y_pred_class)\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8aa759",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(y_logit, dim=1).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a806154",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (y_pred == y).sum().item()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da35c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_class = y_pred.detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
