{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1acdaa3",
   "metadata": {},
   "source": [
    "# WZE-UAV Image Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2159aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import glob\n",
    "import numpy as np\n",
    "#from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0026f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torch import nn\n",
    "#from torch.utils.data import DataLoader\n",
    "#from torchvision import datasets, transforms\n",
    "#from torch.utils.data import Dataset\n",
    "#import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b160d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wze_uav.data_loader as data_loader\n",
    "import wze_uav.models as models\n",
    "from wze_uav.engine import *\n",
    "from wze_uav.utils2 import *\n",
    "from wze_uav.log_writer import create_writer\n",
    "from wze_uav.datasplit import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4fb2f",
   "metadata": {},
   "source": [
    "#### Get PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10886b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1+cu116\n",
      "torchvision version: 0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a83cf",
   "metadata": {},
   "source": [
    "#### Preparing device agnostic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d5de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Index of current divice: 0\n",
      "Number of GPUs available: 1\n",
      "GPU Model: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# ensure device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(f\"Index of current divice: {torch.cuda.current_device()}\")\n",
    "# get number of GPUs available\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "# get the name of the device\n",
    "print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6a34",
   "metadata": {},
   "source": [
    "#### Ensure reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information, see also: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds() \n",
    "\n",
    "# Set to true -> might speed up the process but should be set to False if reproducible results are desired\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be33671",
   "metadata": {},
   "source": [
    "#### Define file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30645f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# 3 channel input (r-g-b)\n",
    "data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb\"\n",
    "\n",
    "# 4 channel input (r-g-b-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-nir\"\n",
    "\n",
    "# 5 channel input (r-g-b-re-nir)\n",
    "#data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\\ROI\\rgb-re-nir\"\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560ce64",
   "metadata": {},
   "source": [
    "#### Get all file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa072e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = os.listdir(data_path)\n",
    "path_list = []\n",
    "# Iterate over all datafiles\n",
    "for year in fn_list:\n",
    "    year_dir = f'{data_path}\\\\{year}'\n",
    "    for filename in os.listdir(year_dir):\n",
    "        path = f'{year_dir}\\\\{filename}'\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3937a44",
   "metadata": {},
   "source": [
    "#### Create unique hash IDs for every individual tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a50f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1aa0b6dd2904d72b13b91436370443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating unique tree IDs...:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hashID_dict = data_loader.get_unique_treeID(path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cea00",
   "metadata": {},
   "source": [
    "#### Import all imagery, labels and other features from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e3eecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea34e710910644acb0713686cc34102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing hdf5 datasets:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_set, label_set, species_set, kkl_set, bk_set, hash_id = data_loader.hdf5_to_img_label_v2(path_list,\n",
    "                                                                                               hashID_dict,\n",
    "                                                                                               load_sets=[\"images_masked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90e2b7",
   "metadata": {},
   "source": [
    "#### Convert nbv to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0224972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = nbv_to_sst_3classes(label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4cd85",
   "metadata": {},
   "source": [
    "#### Split data and seperate a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06eda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7087 unique values within hash_id.\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (15973, 250, 250, 3)\n",
      "Labels train dataset: (15973, 1)\n",
      "\n",
      "Images test dataset: (2832, 250, 250, 3)\n",
      "Labels test dataset: (2832, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 14465\n",
      "Stressed trees in train dataset: 1240\n",
      "Dead trees in train dataset: 268\n",
      "Healthy trees in test dataset: 2551\n",
      "Stressed trees in test dataset: 237\n",
      "Dead trees in test dataset: 44\n",
      "Ratio health trees in test dataset: 0.1499177244945933\n",
      "Ratio stressed trees in test dataset: 0.16046039268788084\n",
      "Ratio dead trees in test dataset: 0.14102564102564102\n"
     ]
    }
   ],
   "source": [
    "image_set, label_set, hash_id, species_set, test_image_set, test_label_set, test_hash_id, test_species_set = data_split(image_set, label_set, hash_id, species_set, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fbb5b",
   "metadata": {},
   "source": [
    "#### Check if any hash ID is in both train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874367cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no hash_id values in both train and test datasets. The datasplit was successful\n"
     ]
    }
   ],
   "source": [
    "hash_set = set(hash_id.flatten())\n",
    "test_hash_set = set(test_hash_id.flatten())\n",
    "intersection = hash_set.intersection(test_hash_set)\n",
    "if intersection:\n",
    "    print(f\"Hash_id values in both train and test sets: {intersection}\")\n",
    "else:\n",
    "    print(\"There are no hash_id values in both train and test datasets. The datasplit was successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b64d4",
   "metadata": {},
   "source": [
    "#### Check feature distribution of the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a33ff5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset\n",
      "Test data healthy trees: 2551\n",
      "Test data stressed trees: 237\n",
      "Test data dead trees: 44\n",
      "Test data pine trees: 755\n",
      "Test data spruces: 1041\n",
      "--------------------------------------------------\n",
      "Remaining dataset\n",
      "Remaining data healthy trees: 14465\n",
      "Remaining data stressed trees: 1240\n",
      "Remaining data dead trees: 268\n",
      "Remaining data pine trees: 4036\n",
      "Remaining data spruces: 5942\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences(data, value):\n",
    "    count = 0\n",
    "    for item in data:\n",
    "        if item == value:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(\"Test dataset\")\n",
    "print(f\"Test data healthy trees: {count_occurrences(test_label_set, 0)}\")\n",
    "print(f\"Test data stressed trees: {count_occurrences(test_label_set, 1)}\")\n",
    "print(f\"Test data dead trees: {count_occurrences(test_label_set, 2)}\")\n",
    "print(f\"Test data pine trees: {count_occurrences(test_species_set, 134)}\")\n",
    "print(f\"Test data spruces: {count_occurrences(test_species_set, 118)}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Remaining dataset\")\n",
    "print(f\"Remaining data healthy trees: {count_occurrences(label_set, 0)}\")\n",
    "print(f\"Remaining data stressed trees: {count_occurrences(label_set, 1)}\")\n",
    "print(f\"Remaining data dead trees: {count_occurrences(label_set, 2)}\")\n",
    "print(f\"Remaining data pine trees: {count_occurrences(species_set, 134)}\")\n",
    "print(f\"Remaining data spruces: {count_occurrences(species_set, 118)}\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d3c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train transform with augmentation. \n",
    "transform_train = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(degrees=[0,360])])\n",
    "\n",
    "# test and val dataset transform without augmentation. \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# class names need to fit the customDataset class used e.g. 3 classes -> use CustomDataset3Classes\n",
    "#class_names = ['healthy', 'slightly_stressed', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "#class_names = ['healthy', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "class_names = ['healthy', 'stressed', 'dead']\n",
    "\n",
    "# set seeds\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "NUM_WORKERS=3 # should be changed, depending on the system used\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31779c05",
   "metadata": {},
   "source": [
    "#### Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10ae4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "# 1. Define number of epochs\n",
    "epochs = 50\n",
    "n_bands = image_set[0].shape[2] # get number of bands\n",
    "\n",
    "# 2. Define model\n",
    "num_classes = len(class_names)\n",
    "unfreeze = True # all layer weights get updated\n",
    "dropout_rate = 0.5 #define dropout rate\n",
    "model_name = \"EffNet_b7\"\n",
    "\n",
    "# 3. Define loss, optimizer and learning rate scheduler\n",
    "lr = 0.0011 # define learning rate\n",
    "gamma = 0.85 # how fast the learning rate decreases per epoch (low number=faster decrease)\n",
    "patience = 15\n",
    "#step_size = 5\n",
    "\n",
    "# 4. Create target folder name were to save the tensorboard event files\n",
    "target_dir = \"EffNet_kFold_RGB_3classes_log_evaluation\"\n",
    "experiment_name = 'kFold_RGB_3classes'\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"Memory allocated: {torch.cuda.memory_allocated()} bytes\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768b1a",
   "metadata": {},
   "source": [
    "#### Run k-Fold cross-validation on EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c29c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6023 unique values within hash_id.\n",
      "\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12770, 250, 250, 3)\n",
      "Labels train dataset: (12770, 1)\n",
      "\n",
      "Images validation dataset: (3203, 250, 250, 3)\n",
      "Labels validation dataset: (3203, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 11550\n",
      "Stressed trees in train dataset: 983\n",
      "Dead trees in train dataset: 237\n",
      "Healthy trees in validation dataset: 2915\n",
      "Stressed trees in validation dataset: 257\n",
      "Dead trees in validation dataset: 31\n",
      "Ratio health trees in validation dataset: 0.20152091254752852\n",
      "Ratio stressed trees in validation dataset: 0.20725806451612902\n",
      "Ratio dead trees in validation dataset: 0.11567164179104478\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 1\n",
      "\n",
      "Creating dataloaders for fold: 1\n",
      "\n",
      "[INFO] Created new effnet_b7 model.\n",
      "\n",
      "[INFO] Fold number: 1\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.85\n",
      "[INFO] Created SummaryWriter, saving to: EffNet_kFold_RGB_3classes_log_evaluation\\2023-04-06\\kFold_RGB_3classes\\EffNet_b7\\50_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eace5871cff45638d48205a251da8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.0011\n",
      "Train loss: 0.6712 | Train precision: 0.6925 | Train recall: 0.6929 | Train f1score: 0.6927 | Train acc: 0.6750 | Train kappa: 0.4450 \n",
      "Val loss: 0.3040 | Val precision: 0.5366 | Val recall: 0.6396 | Val f1score: 0.5179 | Val acc: 0.9072 | Val kappa: 0.2085 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.0009350000000000001\n",
      "Train loss: 0.5748 | Train precision: 0.7563 | Train recall: 0.7573 | Train f1score: 0.7567 | Train acc: 0.7274 | Train kappa: 0.5358 \n",
      "Val loss: 0.3409 | Val precision: 0.5739 | Val recall: 0.7804 | Val f1score: 0.6395 | Val acc: 0.8428 | Val kappa: 0.3251 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.00079475\n",
      "Train loss: 0.5448 | Train precision: 0.7777 | Train recall: 0.7736 | Train f1score: 0.7756 | Train acc: 0.7428 | Train kappa: 0.5575 \n",
      "Val loss: 0.4609 | Val precision: 0.6465 | Val recall: 0.7702 | Val f1score: 0.6615 | Val acc: 0.7600 | Val kappa: 0.2518 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.0006755375\n",
      "Train loss: 0.5234 | Train precision: 0.7918 | Train recall: 0.7863 | Train f1score: 0.7890 | Train acc: 0.7567 | Train kappa: 0.5854 \n",
      "Val loss: 0.3533 | Val precision: 0.7096 | Val recall: 0.7382 | Val f1score: 0.7013 | Val acc: 0.8438 | Val kappa: 0.3501 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.0005742068749999999\n",
      "Train loss: 0.4997 | Train precision: 0.8007 | Train recall: 0.7995 | Train f1score: 0.8001 | Train acc: 0.7651 | Train kappa: 0.5957 \n",
      "Val loss: 0.5441 | Val precision: 0.5788 | Val recall: 0.8065 | Val f1score: 0.6002 | Val acc: 0.6719 | Val kappa: 0.2033 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0004880758437499999\n",
      "Train loss: 0.4728 | Train precision: 0.8185 | Train recall: 0.8146 | Train f1score: 0.8165 | Train acc: 0.7788 | Train kappa: 0.6204 \n",
      "Val loss: 0.4334 | Val precision: 0.6242 | Val recall: 0.7977 | Val f1score: 0.6619 | Val acc: 0.7738 | Val kappa: 0.2714 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.0004148644671874999\n",
      "Train loss: 0.4533 | Train precision: 0.8290 | Train recall: 0.8245 | Train f1score: 0.8267 | Train acc: 0.7903 | Train kappa: 0.6406 \n",
      "Val loss: 0.5257 | Val precision: 0.5789 | Val recall: 0.8010 | Val f1score: 0.6200 | Val acc: 0.7344 | Val kappa: 0.2352 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.0003526347971093749\n",
      "Train loss: 0.4456 | Train precision: 0.8252 | Train recall: 0.8242 | Train f1score: 0.8247 | Train acc: 0.7889 | Train kappa: 0.6370 \n",
      "Val loss: 0.3804 | Val precision: 0.5865 | Val recall: 0.8021 | Val f1score: 0.6547 | Val acc: 0.8472 | Val kappa: 0.3560 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0002997395775429687\n",
      "Train loss: 0.4166 | Train precision: 0.8419 | Train recall: 0.8388 | Train f1score: 0.8403 | Train acc: 0.8048 | Train kappa: 0.6657 \n",
      "Val loss: 0.3475 | Val precision: 0.6389 | Val recall: 0.7961 | Val f1score: 0.6970 | Val acc: 0.8631 | Val kappa: 0.3716 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0002547786409115234\n",
      "Train loss: 0.4024 | Train precision: 0.8493 | Train recall: 0.8503 | Train f1score: 0.8497 | Train acc: 0.8120 | Train kappa: 0.6775 \n",
      "Val loss: 0.4723 | Val precision: 0.5999 | Val recall: 0.8173 | Val f1score: 0.6528 | Val acc: 0.7853 | Val kappa: 0.2937 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.00021656184477479486\n",
      "Train loss: 0.3852 | Train precision: 0.8565 | Train recall: 0.8574 | Train f1score: 0.8567 | Train acc: 0.8210 | Train kappa: 0.6948 \n",
      "Val loss: 0.3720 | Val precision: 0.6087 | Val recall: 0.7771 | Val f1score: 0.6625 | Val acc: 0.8369 | Val kappa: 0.3426 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00018407756805857562\n",
      "Train loss: 0.3729 | Train precision: 0.8621 | Train recall: 0.8657 | Train f1score: 0.8637 | Train acc: 0.8295 | Train kappa: 0.7092 \n",
      "Val loss: 0.3034 | Val precision: 0.6221 | Val recall: 0.7472 | Val f1score: 0.6717 | Val acc: 0.8844 | Val kappa: 0.3851 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015646593284978928\n",
      "Train loss: 0.3494 | Train precision: 0.8732 | Train recall: 0.8765 | Train f1score: 0.8746 | Train acc: 0.8401 | Train kappa: 0.7281 \n",
      "Val loss: 0.4086 | Val precision: 0.5777 | Val recall: 0.8033 | Val f1score: 0.6419 | Val acc: 0.8181 | Val kappa: 0.3170 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.0001329960429223209\n",
      "Train loss: 0.3415 | Train precision: 0.8792 | Train recall: 0.8830 | Train f1score: 0.8808 | Train acc: 0.8481 | Train kappa: 0.7394 \n",
      "Val loss: 0.3310 | Val precision: 0.6238 | Val recall: 0.7766 | Val f1score: 0.6769 | Val acc: 0.8581 | Val kappa: 0.3851 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 0.00011304663648397275\n",
      "Train loss: 0.3218 | Train precision: 0.8862 | Train recall: 0.8911 | Train f1score: 0.8883 | Train acc: 0.8557 | Train kappa: 0.7531 \n",
      "Val loss: 0.3022 | Val precision: 0.6329 | Val recall: 0.7640 | Val f1score: 0.6847 | Val acc: 0.8819 | Val kappa: 0.4021 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 9.608964101137683e-05\n",
      "Train loss: 0.3030 | Train precision: 0.8950 | Train recall: 0.8995 | Train f1score: 0.8969 | Train acc: 0.8674 | Train kappa: 0.7733 \n",
      "Val loss: 0.3714 | Val precision: 0.6139 | Val recall: 0.7990 | Val f1score: 0.6763 | Val acc: 0.8516 | Val kappa: 0.3670 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 8.16761948596703e-05\n",
      "Train loss: 0.3015 | Train precision: 0.8961 | Train recall: 0.8987 | Train f1score: 0.8969 | Train acc: 0.8669 | Train kappa: 0.7726 \n",
      "Val loss: 0.3289 | Val precision: 0.6160 | Val recall: 0.7758 | Val f1score: 0.6754 | Val acc: 0.8722 | Val kappa: 0.3732 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 6.942476563071976e-05\n",
      "Train loss: 0.2949 | Train precision: 0.9007 | Train recall: 0.9050 | Train f1score: 0.9024 | Train acc: 0.8743 | Train kappa: 0.7858 \n",
      "Val loss: 0.4090 | Val precision: 0.6011 | Val recall: 0.7823 | Val f1score: 0.6532 | Val acc: 0.8125 | Val kappa: 0.3054 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.9011050786111795e-05\n",
      "Train loss: 0.2749 | Train precision: 0.9085 | Train recall: 0.9111 | Train f1score: 0.9094 | Train acc: 0.8830 | Train kappa: 0.8002 \n",
      "Val loss: 0.4397 | Val precision: 0.5887 | Val recall: 0.7921 | Val f1score: 0.6436 | Val acc: 0.8003 | Val kappa: 0.2931 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 5.015939316819502e-05\n",
      "Train loss: 0.2750 | Train precision: 0.9083 | Train recall: 0.9113 | Train f1score: 0.9093 | Train acc: 0.8825 | Train kappa: 0.7993 \n",
      "Val loss: 0.3882 | Val precision: 0.5993 | Val recall: 0.7912 | Val f1score: 0.6601 | Val acc: 0.8334 | Val kappa: 0.3297 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 4.2635484192965766e-05\n",
      "Train loss: 0.2584 | Train precision: 0.9136 | Train recall: 0.9178 | Train f1score: 0.9152 | Train acc: 0.8905 | Train kappa: 0.8138 \n",
      "Val loss: 0.4313 | Val precision: 0.5945 | Val recall: 0.7984 | Val f1score: 0.6552 | Val acc: 0.8241 | Val kappa: 0.3272 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 3.62401615640209e-05\n",
      "Train loss: 0.2505 | Train precision: 0.9209 | Train recall: 0.9231 | Train f1score: 0.9214 | Train acc: 0.8966 | Train kappa: 0.8243 \n",
      "Val loss: 0.3970 | Val precision: 0.6287 | Val recall: 0.7983 | Val f1score: 0.6843 | Val acc: 0.8400 | Val kappa: 0.3476 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 3.080413732941777e-05\n",
      "Train loss: 0.2449 | Train precision: 0.9217 | Train recall: 0.9237 | Train f1score: 0.9222 | Train acc: 0.8984 | Train kappa: 0.8272 \n",
      "Val loss: 0.4137 | Val precision: 0.5931 | Val recall: 0.7840 | Val f1score: 0.6537 | Val acc: 0.8331 | Val kappa: 0.3236 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 2.61835167300051e-05\n",
      "Train loss: 0.2478 | Train precision: 0.9156 | Train recall: 0.9203 | Train f1score: 0.9174 | Train acc: 0.8931 | Train kappa: 0.8177 \n",
      "Val loss: 0.3742 | Val precision: 0.6171 | Val recall: 0.7939 | Val f1score: 0.6781 | Val acc: 0.8537 | Val kappa: 0.3650 \n",
      "\n",
      "Epoch: 25 \n",
      "Learning rate: 2.2255989220504335e-05\n",
      "Train loss: 0.2456 | Train precision: 0.9182 | Train recall: 0.9217 | Train f1score: 0.9194 | Train acc: 0.8951 | Train kappa: 0.8202 \n",
      "Val loss: 0.4075 | Val precision: 0.5976 | Val recall: 0.7887 | Val f1score: 0.6594 | Val acc: 0.8397 | Val kappa: 0.3377 \n",
      "\n",
      "Epoch: 26 \n",
      "Learning rate: 1.8917590837428684e-05\n",
      "Train loss: 0.2370 | Train precision: 0.9222 | Train recall: 0.9253 | Train f1score: 0.9233 | Train acc: 0.9017 | Train kappa: 0.8331 \n",
      "Val loss: 0.4009 | Val precision: 0.5971 | Val recall: 0.7868 | Val f1score: 0.6600 | Val acc: 0.8472 | Val kappa: 0.3470 \n",
      "\n",
      "Epoch: 27 \n",
      "Learning rate: 1.6079952211814382e-05\n",
      "Train loss: 0.2391 | Train precision: 0.9227 | Train recall: 0.9259 | Train f1score: 0.9238 | Train acc: 0.8998 | Train kappa: 0.8288 \n",
      "Val loss: 0.3650 | Val precision: 0.6278 | Val recall: 0.7751 | Val f1score: 0.6820 | Val acc: 0.8606 | Val kappa: 0.3653 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      "Learning rate: 1.3667959380042224e-05\n",
      "Train loss: 0.2393 | Train precision: 0.9229 | Train recall: 0.9261 | Train f1score: 0.9242 | Train acc: 0.9011 | Train kappa: 0.8314 \n",
      "Val loss: 0.3889 | Val precision: 0.6250 | Val recall: 0.7856 | Val f1score: 0.6815 | Val acc: 0.8506 | Val kappa: 0.3490 \n",
      "\n",
      "Epoch: 29 \n",
      "Learning rate: 1.161776547303589e-05\n",
      "Train loss: 0.2320 | Train precision: 0.9253 | Train recall: 0.9283 | Train f1score: 0.9264 | Train acc: 0.9037 | Train kappa: 0.8362 \n",
      "Val loss: 0.3816 | Val precision: 0.6248 | Val recall: 0.7850 | Val f1score: 0.6827 | Val acc: 0.8584 | Val kappa: 0.3608 \n",
      "\n",
      "Epoch: 30 \n",
      "Learning rate: 9.875100652080506e-06\n",
      "Train loss: 0.2253 | Train precision: 0.9276 | Train recall: 0.9310 | Train f1score: 0.9289 | Train acc: 0.9079 | Train kappa: 0.8429 \n",
      "Val loss: 0.3980 | Val precision: 0.6221 | Val recall: 0.7849 | Val f1score: 0.6781 | Val acc: 0.8453 | Val kappa: 0.3401 \n",
      "\n",
      "Early stopping after epoch 30\n",
      "--------------------------------------------------\n",
      "\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12801, 250, 250, 3)\n",
      "Labels train dataset: (12801, 1)\n",
      "\n",
      "Images validation dataset: (3172, 250, 250, 3)\n",
      "Labels validation dataset: (3172, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 11597\n",
      "Stressed trees in train dataset: 996\n",
      "Dead trees in train dataset: 208\n",
      "Healthy trees in validation dataset: 2868\n",
      "Stressed trees in validation dataset: 244\n",
      "Dead trees in validation dataset: 60\n",
      "Ratio health trees in validation dataset: 0.19827169028689942\n",
      "Ratio stressed trees in validation dataset: 0.1967741935483871\n",
      "Ratio dead trees in validation dataset: 0.22388059701492538\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 2\n",
      "\n",
      "Creating dataloaders for fold: 2\n",
      "\n",
      "[INFO] Created new effnet_b7 model.\n",
      "\n",
      "[INFO] Fold number: 2\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.85\n",
      "[INFO] Created SummaryWriter, saving to: EffNet_kFold_RGB_3classes_log_evaluation\\2023-04-06\\kFold_RGB_3classes\\EffNet_b7\\50_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601928d777d5466fb3a644ea33b74059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.0011\n",
      "Train loss: 0.6667 | Train precision: 0.6884 | Train recall: 0.6885 | Train f1score: 0.6884 | Train acc: 0.6720 | Train kappa: 0.4302 \n",
      "Val loss: 0.2791 | Val precision: 0.7224 | Val recall: 0.5243 | Val f1score: 0.5841 | Val acc: 0.9085 | Val kappa: 0.2983 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.0009350000000000001\n",
      "Train loss: 0.5659 | Train precision: 0.7653 | Train recall: 0.7613 | Train f1score: 0.7633 | Train acc: 0.7340 | Train kappa: 0.5397 \n",
      "Val loss: 0.3962 | Val precision: 0.6450 | Val recall: 0.7103 | Val f1score: 0.6561 | Val acc: 0.8220 | Val kappa: 0.3206 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.00079475\n",
      "Train loss: 0.5324 | Train precision: 0.7877 | Train recall: 0.7806 | Train f1score: 0.7840 | Train acc: 0.7492 | Train kappa: 0.5642 \n",
      "Val loss: 0.3281 | Val precision: 0.7202 | Val recall: 0.5803 | Val f1score: 0.6298 | Val acc: 0.8895 | Val kappa: 0.3386 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.0006755375\n",
      "Train loss: 0.5134 | Train precision: 0.7989 | Train recall: 0.7934 | Train f1score: 0.7961 | Train acc: 0.7563 | Train kappa: 0.5777 \n",
      "Val loss: 0.5699 | Val precision: 0.6257 | Val recall: 0.7669 | Val f1score: 0.6324 | Val acc: 0.7301 | Val kappa: 0.2670 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.0005742068749999999\n",
      "Train loss: 0.4800 | Train precision: 0.8137 | Train recall: 0.8098 | Train f1score: 0.8117 | Train acc: 0.7731 | Train kappa: 0.6037 \n",
      "Val loss: 0.5379 | Val precision: 0.6833 | Val recall: 0.7007 | Val f1score: 0.6082 | Val acc: 0.6856 | Val kappa: 0.2223 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0004880758437499999\n",
      "Train loss: 0.4743 | Train precision: 0.8186 | Train recall: 0.8118 | Train f1score: 0.8151 | Train acc: 0.7767 | Train kappa: 0.6082 \n",
      "Val loss: 0.3642 | Val precision: 0.7017 | Val recall: 0.7081 | Val f1score: 0.6778 | Val acc: 0.8343 | Val kappa: 0.3508 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.0004148644671874999\n",
      "Train loss: 0.4388 | Train precision: 0.8358 | Train recall: 0.8314 | Train f1score: 0.8336 | Train acc: 0.7941 | Train kappa: 0.6400 \n",
      "Val loss: 0.3938 | Val precision: 0.6837 | Val recall: 0.7364 | Val f1score: 0.6782 | Val acc: 0.8147 | Val kappa: 0.3350 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.0003526347971093749\n",
      "Train loss: 0.4294 | Train precision: 0.8442 | Train recall: 0.8405 | Train f1score: 0.8420 | Train acc: 0.8041 | Train kappa: 0.6600 \n",
      "Val loss: 0.4356 | Val precision: 0.6735 | Val recall: 0.7444 | Val f1score: 0.6703 | Val acc: 0.7901 | Val kappa: 0.3053 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0002997395775429687\n",
      "Train loss: 0.4027 | Train precision: 0.8467 | Train recall: 0.8453 | Train f1score: 0.8458 | Train acc: 0.8105 | Train kappa: 0.6709 \n",
      "Val loss: 0.4040 | Val precision: 0.5816 | Val recall: 0.7498 | Val f1score: 0.6287 | Val acc: 0.8138 | Val kappa: 0.3357 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0002547786409115234\n",
      "Train loss: 0.3771 | Train precision: 0.8623 | Train recall: 0.8621 | Train f1score: 0.8620 | Train acc: 0.8266 | Train kappa: 0.6991 \n",
      "Val loss: 0.4962 | Val precision: 0.6474 | Val recall: 0.7566 | Val f1score: 0.6528 | Val acc: 0.7551 | Val kappa: 0.2732 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.00021656184477479486\n",
      "Train loss: 0.3636 | Train precision: 0.8708 | Train recall: 0.8734 | Train f1score: 0.8718 | Train acc: 0.8365 | Train kappa: 0.7175 \n",
      "Val loss: 0.4271 | Val precision: 0.6462 | Val recall: 0.7541 | Val f1score: 0.6630 | Val acc: 0.7936 | Val kappa: 0.3118 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00018407756805857562\n",
      "Train loss: 0.3377 | Train precision: 0.8803 | Train recall: 0.8822 | Train f1score: 0.8810 | Train acc: 0.8467 | Train kappa: 0.7359 \n",
      "Val loss: 0.3987 | Val precision: 0.6661 | Val recall: 0.7336 | Val f1score: 0.6809 | Val acc: 0.8387 | Val kappa: 0.3556 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015646593284978928\n",
      "Train loss: 0.3286 | Train precision: 0.8844 | Train recall: 0.8870 | Train f1score: 0.8853 | Train acc: 0.8511 | Train kappa: 0.7437 \n",
      "Val loss: 0.3548 | Val precision: 0.6799 | Val recall: 0.7108 | Val f1score: 0.6829 | Val acc: 0.8539 | Val kappa: 0.3641 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.0001329960429223209\n",
      "Train loss: 0.3100 | Train precision: 0.8932 | Train recall: 0.8959 | Train f1score: 0.8939 | Train acc: 0.8625 | Train kappa: 0.7615 \n",
      "Val loss: 0.4237 | Val precision: 0.6773 | Val recall: 0.7335 | Val f1score: 0.6768 | Val acc: 0.8160 | Val kappa: 0.3296 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 0.00011304663648397275\n",
      "Train loss: 0.2983 | Train precision: 0.8995 | Train recall: 0.9014 | Train f1score: 0.8998 | Train acc: 0.8687 | Train kappa: 0.7733 \n",
      "Val loss: 0.5298 | Val precision: 0.6687 | Val recall: 0.7389 | Val f1score: 0.6503 | Val acc: 0.7412 | Val kappa: 0.2553 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 9.608964101137683e-05\n",
      "Train loss: 0.2782 | Train precision: 0.9089 | Train recall: 0.9115 | Train f1score: 0.9093 | Train acc: 0.8808 | Train kappa: 0.7951 \n",
      "Val loss: 0.4020 | Val precision: 0.6926 | Val recall: 0.7188 | Val f1score: 0.6823 | Val acc: 0.8371 | Val kappa: 0.3548 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 8.16761948596703e-05\n",
      "Train loss: 0.2766 | Train precision: 0.9083 | Train recall: 0.9103 | Train f1score: 0.9088 | Train acc: 0.8795 | Train kappa: 0.7911 \n",
      "Val loss: 0.4111 | Val precision: 0.6498 | Val recall: 0.7194 | Val f1score: 0.6643 | Val acc: 0.8286 | Val kappa: 0.3333 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 6.942476563071976e-05\n",
      "Train loss: 0.2538 | Train precision: 0.9192 | Train recall: 0.9210 | Train f1score: 0.9194 | Train acc: 0.8939 | Train kappa: 0.8161 \n",
      "Val loss: 0.4013 | Val precision: 0.6866 | Val recall: 0.7233 | Val f1score: 0.6883 | Val acc: 0.8412 | Val kappa: 0.3463 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.9011050786111795e-05\n",
      "Train loss: 0.2380 | Train precision: 0.9245 | Train recall: 0.9260 | Train f1score: 0.9248 | Train acc: 0.8993 | Train kappa: 0.8257 \n",
      "Val loss: 0.4198 | Val precision: 0.6605 | Val recall: 0.7230 | Val f1score: 0.6753 | Val acc: 0.8359 | Val kappa: 0.3353 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 5.015939316819502e-05\n",
      "Train loss: 0.2391 | Train precision: 0.9269 | Train recall: 0.9289 | Train f1score: 0.9272 | Train acc: 0.9037 | Train kappa: 0.8335 \n",
      "Val loss: 0.4611 | Val precision: 0.6727 | Val recall: 0.7349 | Val f1score: 0.6798 | Val acc: 0.8207 | Val kappa: 0.3258 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 4.2635484192965766e-05\n",
      "Train loss: 0.2114 | Train precision: 0.9328 | Train recall: 0.9356 | Train f1score: 0.9338 | Train acc: 0.9120 | Train kappa: 0.8479 \n",
      "Val loss: 0.4895 | Val precision: 0.6793 | Val recall: 0.7101 | Val f1score: 0.6718 | Val acc: 0.8261 | Val kappa: 0.3265 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 3.62401615640209e-05\n",
      "Train loss: 0.2198 | Train precision: 0.9311 | Train recall: 0.9333 | Train f1score: 0.9317 | Train acc: 0.9092 | Train kappa: 0.8433 \n",
      "Val loss: 0.4933 | Val precision: 0.6719 | Val recall: 0.6922 | Val f1score: 0.6597 | Val acc: 0.8194 | Val kappa: 0.3036 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 3.080413732941777e-05\n",
      "Train loss: 0.2082 | Train precision: 0.9358 | Train recall: 0.9370 | Train f1score: 0.9359 | Train acc: 0.9143 | Train kappa: 0.8514 \n",
      "Val loss: 0.4714 | Val precision: 0.6784 | Val recall: 0.7230 | Val f1score: 0.6841 | Val acc: 0.8359 | Val kappa: 0.3329 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 2.61835167300051e-05\n",
      "Train loss: 0.2143 | Train precision: 0.9335 | Train recall: 0.9353 | Train f1score: 0.9340 | Train acc: 0.9122 | Train kappa: 0.8483 \n",
      "Val loss: 0.4801 | Val precision: 0.6771 | Val recall: 0.7087 | Val f1score: 0.6738 | Val acc: 0.8267 | Val kappa: 0.3138 \n",
      "\n",
      "Epoch: 25 \n",
      "Learning rate: 2.2255989220504335e-05\n",
      "Train loss: 0.2003 | Train precision: 0.9408 | Train recall: 0.9415 | Train f1score: 0.9407 | Train acc: 0.9212 | Train kappa: 0.8631 \n",
      "Val loss: 0.4873 | Val precision: 0.6724 | Val recall: 0.7148 | Val f1score: 0.6762 | Val acc: 0.8273 | Val kappa: 0.3122 \n",
      "\n",
      "Epoch: 26 \n",
      "Learning rate: 1.8917590837428684e-05\n",
      "Train loss: 0.2016 | Train precision: 0.9396 | Train recall: 0.9417 | Train f1score: 0.9401 | Train acc: 0.9193 | Train kappa: 0.8601 \n",
      "Val loss: 0.4616 | Val precision: 0.6728 | Val recall: 0.6966 | Val f1score: 0.6726 | Val acc: 0.8412 | Val kappa: 0.3193 \n",
      "\n",
      "Epoch: 27 \n",
      "Learning rate: 1.6079952211814382e-05\n",
      "Train loss: 0.1910 | Train precision: 0.9428 | Train recall: 0.9451 | Train f1score: 0.9435 | Train acc: 0.9243 | Train kappa: 0.8692 \n",
      "Val loss: 0.4656 | Val precision: 0.6773 | Val recall: 0.6953 | Val f1score: 0.6741 | Val acc: 0.8412 | Val kappa: 0.3177 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      "Learning rate: 1.3667959380042224e-05\n",
      "Train loss: 0.1896 | Train precision: 0.9417 | Train recall: 0.9451 | Train f1score: 0.9430 | Train acc: 0.9245 | Train kappa: 0.8692 \n",
      "Val loss: 0.4756 | Val precision: 0.6856 | Val recall: 0.6875 | Val f1score: 0.6708 | Val acc: 0.8359 | Val kappa: 0.3106 \n",
      "\n",
      "Epoch: 29 \n",
      "Learning rate: 1.161776547303589e-05\n",
      "Train loss: 0.1945 | Train precision: 0.9426 | Train recall: 0.9445 | Train f1score: 0.9432 | Train acc: 0.9238 | Train kappa: 0.8685 \n",
      "Val loss: 0.4626 | Val precision: 0.6919 | Val recall: 0.6986 | Val f1score: 0.6813 | Val acc: 0.8444 | Val kappa: 0.3303 \n",
      "\n",
      "Epoch: 30 \n",
      "Learning rate: 9.875100652080506e-06\n",
      "Train loss: 0.1893 | Train precision: 0.9425 | Train recall: 0.9434 | Train f1score: 0.9426 | Train acc: 0.9232 | Train kappa: 0.8672 \n",
      "Val loss: 0.4852 | Val precision: 0.6783 | Val recall: 0.7052 | Val f1score: 0.6755 | Val acc: 0.8340 | Val kappa: 0.3193 \n",
      "\n",
      "Epoch: 31 \n",
      "Learning rate: 8.39383555426843e-06\n",
      "Train loss: 0.1902 | Train precision: 0.9438 | Train recall: 0.9455 | Train f1score: 0.9443 | Train acc: 0.9254 | Train kappa: 0.8718 \n",
      "Val loss: 0.5004 | Val precision: 0.6749 | Val recall: 0.6742 | Val f1score: 0.6572 | Val acc: 0.8292 | Val kappa: 0.2959 \n",
      "\n",
      "Epoch: 32 \n",
      "Learning rate: 7.134760221128165e-06\n",
      "Train loss: 0.1806 | Train precision: 0.9457 | Train recall: 0.9483 | Train f1score: 0.9466 | Train acc: 0.9277 | Train kappa: 0.8740 \n",
      "Val loss: 0.4762 | Val precision: 0.6807 | Val recall: 0.7041 | Val f1score: 0.6786 | Val acc: 0.8412 | Val kappa: 0.3275 \n",
      "\n",
      "Epoch: 33 \n",
      "Learning rate: 6.06454618795894e-06\n",
      "Train loss: 0.1848 | Train precision: 0.9431 | Train recall: 0.9453 | Train f1score: 0.9438 | Train acc: 0.9251 | Train kappa: 0.8697 \n",
      "Val loss: 0.4781 | Val precision: 0.6769 | Val recall: 0.6903 | Val f1score: 0.6714 | Val acc: 0.8422 | Val kappa: 0.3179 \n",
      "\n",
      "Early stopping after epoch 33\n",
      "--------------------------------------------------\n",
      "\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12775, 250, 250, 3)\n",
      "Labels train dataset: (12775, 1)\n",
      "\n",
      "Images validation dataset: (3198, 250, 250, 3)\n",
      "Labels validation dataset: (3198, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 11557\n",
      "Stressed trees in train dataset: 1022\n",
      "Dead trees in train dataset: 196\n",
      "Healthy trees in validation dataset: 2908\n",
      "Stressed trees in validation dataset: 218\n",
      "Dead trees in validation dataset: 72\n",
      "Ratio health trees in validation dataset: 0.20103698582786036\n",
      "Ratio stressed trees in validation dataset: 0.17580645161290323\n",
      "Ratio dead trees in validation dataset: 0.26865671641791045\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 3\n",
      "\n",
      "Creating dataloaders for fold: 3\n",
      "\n",
      "[INFO] Created new effnet_b7 model.\n",
      "\n",
      "[INFO] Fold number: 3\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.85\n",
      "[INFO] Created SummaryWriter, saving to: EffNet_kFold_RGB_3classes_log_evaluation\\2023-04-06\\kFold_RGB_3classes\\EffNet_b7\\50_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b291b01862ac4d23ae6b34908bfee94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.0011\n",
      "Train loss: 0.6836 | Train precision: 0.6781 | Train recall: 0.6790 | Train f1score: 0.6785 | Train acc: 0.6674 | Train kappa: 0.4210 \n",
      "Val loss: 0.3886 | Val precision: 0.7138 | Val recall: 0.5050 | Val f1score: 0.5576 | Val acc: 0.9205 | Val kappa: 0.2958 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.0009350000000000001\n",
      "Train loss: 0.5811 | Train precision: 0.7532 | Train recall: 0.7550 | Train f1score: 0.7540 | Train acc: 0.7315 | Train kappa: 0.5331 \n",
      "Val loss: 0.3736 | Val precision: 0.6208 | Val recall: 0.7387 | Val f1score: 0.6678 | Val acc: 0.8873 | Val kappa: 0.4139 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.00079475\n",
      "Train loss: 0.5520 | Train precision: 0.7701 | Train recall: 0.7742 | Train f1score: 0.7721 | Train acc: 0.7465 | Train kappa: 0.5550 \n",
      "Val loss: 0.4140 | Val precision: 0.5964 | Val recall: 0.7584 | Val f1score: 0.6407 | Val acc: 0.8056 | Val kappa: 0.3036 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.0006755375\n",
      "Train loss: 0.5320 | Train precision: 0.7768 | Train recall: 0.7865 | Train f1score: 0.7815 | Train acc: 0.7496 | Train kappa: 0.5622 \n",
      "Val loss: 0.4345 | Val precision: 0.7195 | Val recall: 0.7276 | Val f1score: 0.6761 | Val acc: 0.8062 | Val kappa: 0.3208 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.0005742068749999999\n",
      "Train loss: 0.5011 | Train precision: 0.8033 | Train recall: 0.8065 | Train f1score: 0.8048 | Train acc: 0.7721 | Train kappa: 0.6018 \n",
      "Val loss: 0.3693 | Val precision: 0.6448 | Val recall: 0.7662 | Val f1score: 0.6829 | Val acc: 0.8384 | Val kappa: 0.3475 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0004880758437499999\n",
      "Train loss: 0.4797 | Train precision: 0.8136 | Train recall: 0.8153 | Train f1score: 0.8144 | Train acc: 0.7787 | Train kappa: 0.6139 \n",
      "Val loss: 0.3848 | Val precision: 0.6451 | Val recall: 0.7723 | Val f1score: 0.6871 | Val acc: 0.8472 | Val kappa: 0.3670 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.0004148644671874999\n",
      "Train loss: 0.4582 | Train precision: 0.8199 | Train recall: 0.8258 | Train f1score: 0.8228 | Train acc: 0.7856 | Train kappa: 0.6250 \n",
      "Val loss: 0.6428 | Val precision: 0.6726 | Val recall: 0.8033 | Val f1score: 0.6553 | Val acc: 0.6878 | Val kappa: 0.2348 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.0003526347971093749\n",
      "Train loss: 0.4451 | Train precision: 0.8336 | Train recall: 0.8383 | Train f1score: 0.8359 | Train acc: 0.7971 | Train kappa: 0.6455 \n",
      "Val loss: 0.3631 | Val precision: 0.6878 | Val recall: 0.7965 | Val f1score: 0.7180 | Val acc: 0.8520 | Val kappa: 0.3993 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0002997395775429687\n",
      "Train loss: 0.4313 | Train precision: 0.8370 | Train recall: 0.8440 | Train f1score: 0.8404 | Train acc: 0.8044 | Train kappa: 0.6573 \n",
      "Val loss: 0.3705 | Val precision: 0.6752 | Val recall: 0.7912 | Val f1score: 0.7089 | Val acc: 0.8491 | Val kappa: 0.3906 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0002547786409115234\n",
      "Train loss: 0.4039 | Train precision: 0.8573 | Train recall: 0.8614 | Train f1score: 0.8593 | Train acc: 0.8215 | Train kappa: 0.6870 \n",
      "Val loss: 0.4375 | Val precision: 0.6959 | Val recall: 0.8046 | Val f1score: 0.7054 | Val acc: 0.8005 | Val kappa: 0.3320 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.00021656184477479486\n",
      "Train loss: 0.3964 | Train precision: 0.8567 | Train recall: 0.8611 | Train f1score: 0.8588 | Train acc: 0.8192 | Train kappa: 0.6856 \n",
      "Val loss: 0.5521 | Val precision: 0.6536 | Val recall: 0.8223 | Val f1score: 0.6636 | Val acc: 0.7314 | Val kappa: 0.2774 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00018407756805857562\n",
      "Train loss: 0.3759 | Train precision: 0.8658 | Train recall: 0.8732 | Train f1score: 0.8693 | Train acc: 0.8339 | Train kappa: 0.7099 \n",
      "Val loss: 0.3228 | Val precision: 0.7287 | Val recall: 0.7987 | Val f1score: 0.7481 | Val acc: 0.8728 | Val kappa: 0.4323 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015646593284978928\n",
      "Train loss: 0.3683 | Train precision: 0.8667 | Train recall: 0.8722 | Train f1score: 0.8693 | Train acc: 0.8362 | Train kappa: 0.7147 \n",
      "Val loss: 0.4504 | Val precision: 0.6657 | Val recall: 0.8140 | Val f1score: 0.6938 | Val acc: 0.8015 | Val kappa: 0.3379 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.0001329960429223209\n",
      "Train loss: 0.3373 | Train precision: 0.8837 | Train recall: 0.8899 | Train f1score: 0.8866 | Train acc: 0.8539 | Train kappa: 0.7455 \n",
      "Val loss: 0.4628 | Val precision: 0.6793 | Val recall: 0.8190 | Val f1score: 0.6924 | Val acc: 0.7771 | Val kappa: 0.3165 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 0.00011304663648397275\n",
      "Train loss: 0.3346 | Train precision: 0.8834 | Train recall: 0.8885 | Train f1score: 0.8855 | Train acc: 0.8544 | Train kappa: 0.7468 \n",
      "Val loss: 0.3162 | Val precision: 0.7264 | Val recall: 0.8032 | Val f1score: 0.7486 | Val acc: 0.8734 | Val kappa: 0.4378 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 9.608964101137683e-05\n",
      "Train loss: 0.3159 | Train precision: 0.8916 | Train recall: 0.8948 | Train f1score: 0.8926 | Train acc: 0.8618 | Train kappa: 0.7601 \n",
      "Val loss: 0.3607 | Val precision: 0.6950 | Val recall: 0.7893 | Val f1score: 0.7158 | Val acc: 0.8453 | Val kappa: 0.3861 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 8.16761948596703e-05\n",
      "Train loss: 0.3175 | Train precision: 0.8924 | Train recall: 0.8955 | Train f1score: 0.8935 | Train acc: 0.8615 | Train kappa: 0.7580 \n",
      "Val loss: 0.3377 | Val precision: 0.7294 | Val recall: 0.8067 | Val f1score: 0.7448 | Val acc: 0.8605 | Val kappa: 0.4205 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 6.942476563071976e-05\n",
      "Train loss: 0.2903 | Train precision: 0.9038 | Train recall: 0.9074 | Train f1score: 0.9051 | Train acc: 0.8760 | Train kappa: 0.7838 \n",
      "Val loss: 0.3561 | Val precision: 0.6898 | Val recall: 0.7948 | Val f1score: 0.7167 | Val acc: 0.8428 | Val kappa: 0.3763 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.9011050786111795e-05\n",
      "Train loss: 0.2860 | Train precision: 0.9036 | Train recall: 0.9069 | Train f1score: 0.9046 | Train acc: 0.8759 | Train kappa: 0.7836 \n",
      "Val loss: 0.3790 | Val precision: 0.7198 | Val recall: 0.8000 | Val f1score: 0.7245 | Val acc: 0.8273 | Val kappa: 0.3647 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 5.015939316819502e-05\n",
      "Train loss: 0.2825 | Train precision: 0.9044 | Train recall: 0.9084 | Train f1score: 0.9058 | Train acc: 0.8788 | Train kappa: 0.7906 \n",
      "Val loss: 0.3380 | Val precision: 0.7212 | Val recall: 0.7912 | Val f1score: 0.7391 | Val acc: 0.8640 | Val kappa: 0.4083 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 4.2635484192965766e-05\n",
      "Train loss: 0.2697 | Train precision: 0.9135 | Train recall: 0.9166 | Train f1score: 0.9143 | Train acc: 0.8883 | Train kappa: 0.8060 \n",
      "Val loss: 0.4200 | Val precision: 0.7138 | Val recall: 0.7993 | Val f1score: 0.7136 | Val acc: 0.8062 | Val kappa: 0.3367 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 3.62401615640209e-05\n",
      "Train loss: 0.2615 | Train precision: 0.9141 | Train recall: 0.9162 | Train f1score: 0.9145 | Train acc: 0.8900 | Train kappa: 0.8086 \n",
      "Val loss: 0.3872 | Val precision: 0.6995 | Val recall: 0.8065 | Val f1score: 0.7234 | Val acc: 0.8400 | Val kappa: 0.3831 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 3.080413732941777e-05\n",
      "Train loss: 0.2570 | Train precision: 0.9134 | Train recall: 0.9194 | Train f1score: 0.9159 | Train acc: 0.8929 | Train kappa: 0.8136 \n",
      "Val loss: 0.4001 | Val precision: 0.6986 | Val recall: 0.8039 | Val f1score: 0.7182 | Val acc: 0.8289 | Val kappa: 0.3651 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 2.61835167300051e-05\n",
      "Train loss: 0.2480 | Train precision: 0.9203 | Train recall: 0.9237 | Train f1score: 0.9214 | Train acc: 0.8976 | Train kappa: 0.8209 \n",
      "Val loss: 0.4019 | Val precision: 0.7071 | Val recall: 0.8075 | Val f1score: 0.7292 | Val acc: 0.8419 | Val kappa: 0.3841 \n",
      "\n",
      "Epoch: 25 \n",
      "Learning rate: 2.2255989220504335e-05\n",
      "Train loss: 0.2520 | Train precision: 0.9170 | Train recall: 0.9227 | Train f1score: 0.9192 | Train acc: 0.8965 | Train kappa: 0.8202 \n",
      "Val loss: 0.3676 | Val precision: 0.7139 | Val recall: 0.7885 | Val f1score: 0.7314 | Val acc: 0.8573 | Val kappa: 0.3975 \n",
      "\n",
      "Epoch: 26 \n",
      "Learning rate: 1.8917590837428684e-05\n",
      "Train loss: 0.2447 | Train precision: 0.9215 | Train recall: 0.9252 | Train f1score: 0.9230 | Train acc: 0.8988 | Train kappa: 0.8231 \n",
      "Val loss: 0.3945 | Val precision: 0.6961 | Val recall: 0.8004 | Val f1score: 0.7206 | Val acc: 0.8434 | Val kappa: 0.3858 \n",
      "\n",
      "Epoch: 27 \n",
      "Learning rate: 1.6079952211814382e-05\n",
      "Train loss: 0.2362 | Train precision: 0.9228 | Train recall: 0.9263 | Train f1score: 0.9240 | Train acc: 0.9041 | Train kappa: 0.8327 \n",
      "Val loss: 0.3643 | Val precision: 0.6945 | Val recall: 0.7812 | Val f1score: 0.7210 | Val acc: 0.8608 | Val kappa: 0.3968 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 \n",
      "Learning rate: 1.3667959380042224e-05\n",
      "Train loss: 0.2334 | Train precision: 0.9269 | Train recall: 0.9303 | Train f1score: 0.9279 | Train acc: 0.9058 | Train kappa: 0.8366 \n",
      "Val loss: 0.3683 | Val precision: 0.7134 | Val recall: 0.7928 | Val f1score: 0.7339 | Val acc: 0.8614 | Val kappa: 0.4089 \n",
      "\n",
      "Epoch: 29 \n",
      "Learning rate: 1.161776547303589e-05\n",
      "Train loss: 0.2348 | Train precision: 0.9242 | Train recall: 0.9281 | Train f1score: 0.9256 | Train acc: 0.9044 | Train kappa: 0.8341 \n",
      "Val loss: 0.3905 | Val precision: 0.7115 | Val recall: 0.7963 | Val f1score: 0.7316 | Val acc: 0.8554 | Val kappa: 0.4016 \n",
      "\n",
      "Epoch: 30 \n",
      "Learning rate: 9.875100652080506e-06\n",
      "Train loss: 0.2324 | Train precision: 0.9243 | Train recall: 0.9312 | Train f1score: 0.9270 | Train acc: 0.9066 | Train kappa: 0.8373 \n",
      "Val loss: 0.3850 | Val precision: 0.7178 | Val recall: 0.7833 | Val f1score: 0.7295 | Val acc: 0.8510 | Val kappa: 0.3819 \n",
      "\n",
      "Early stopping after epoch 30\n",
      "--------------------------------------------------\n",
      "\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12782, 250, 250, 3)\n",
      "Labels train dataset: (12782, 1)\n",
      "\n",
      "Images validation dataset: (3191, 250, 250, 3)\n",
      "Labels validation dataset: (3191, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 11582\n",
      "Stressed trees in train dataset: 985\n",
      "Dead trees in train dataset: 215\n",
      "Healthy trees in validation dataset: 2883\n",
      "Stressed trees in validation dataset: 255\n",
      "Dead trees in validation dataset: 53\n",
      "Ratio health trees in validation dataset: 0.19930867611475978\n",
      "Ratio stressed trees in validation dataset: 0.2056451612903226\n",
      "Ratio dead trees in validation dataset: 0.19776119402985073\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 4\n",
      "\n",
      "Creating dataloaders for fold: 4\n",
      "\n",
      "[INFO] Created new effnet_b7 model.\n",
      "\n",
      "[INFO] Fold number: 4\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.85\n",
      "[INFO] Created SummaryWriter, saving to: EffNet_kFold_RGB_3classes_log_evaluation\\2023-04-06\\kFold_RGB_3classes\\EffNet_b7\\50_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e3919257194c66800fcf820c2dc992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.0011\n",
      "Train loss: 0.6763 | Train precision: 0.6849 | Train recall: 0.6819 | Train f1score: 0.6834 | Train acc: 0.6736 | Train kappa: 0.4355 \n",
      "Val loss: 0.3048 | Val precision: 0.6988 | Val recall: 0.4977 | Val f1score: 0.5471 | Val acc: 0.9081 | Val kappa: 0.2128 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.0009350000000000001\n",
      "Train loss: 0.5783 | Train precision: 0.7599 | Train recall: 0.7588 | Train f1score: 0.7594 | Train acc: 0.7330 | Train kappa: 0.5392 \n",
      "Val loss: 0.4768 | Val precision: 0.5519 | Val recall: 0.7531 | Val f1score: 0.6001 | Val acc: 0.7734 | Val kappa: 0.2754 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.00079475\n",
      "Train loss: 0.5338 | Train precision: 0.7838 | Train recall: 0.7852 | Train f1score: 0.7845 | Train acc: 0.7505 | Train kappa: 0.5686 \n",
      "Val loss: 0.5354 | Val precision: 0.6629 | Val recall: 0.7193 | Val f1score: 0.6405 | Val acc: 0.7484 | Val kappa: 0.2602 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.0006755375\n",
      "Train loss: 0.5207 | Train precision: 0.7898 | Train recall: 0.7865 | Train f1score: 0.7880 | Train acc: 0.7547 | Train kappa: 0.5746 \n",
      "Val loss: 0.3553 | Val precision: 0.6932 | Val recall: 0.7102 | Val f1score: 0.6975 | Val acc: 0.8737 | Val kappa: 0.3861 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.0005742068749999999\n",
      "Train loss: 0.4986 | Train precision: 0.7982 | Train recall: 0.7991 | Train f1score: 0.7985 | Train acc: 0.7623 | Train kappa: 0.5875 \n",
      "Val loss: 0.4404 | Val precision: 0.5819 | Val recall: 0.7625 | Val f1score: 0.6350 | Val acc: 0.8157 | Val kappa: 0.3339 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0004880758437499999\n",
      "Train loss: 0.4657 | Train precision: 0.8207 | Train recall: 0.8197 | Train f1score: 0.8201 | Train acc: 0.7853 | Train kappa: 0.6297 \n",
      "Val loss: 0.6654 | Val precision: 0.6014 | Val recall: 0.7520 | Val f1score: 0.6039 | Val acc: 0.6998 | Val kappa: 0.2429 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.0004148644671874999\n",
      "Train loss: 0.4451 | Train precision: 0.8292 | Train recall: 0.8293 | Train f1score: 0.8292 | Train acc: 0.7912 | Train kappa: 0.6388 \n",
      "Val loss: 0.4109 | Val precision: 0.6726 | Val recall: 0.6895 | Val f1score: 0.6805 | Val acc: 0.8949 | Val kappa: 0.4036 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.0003526347971093749\n",
      "Train loss: 0.4395 | Train precision: 0.8276 | Train recall: 0.8298 | Train f1score: 0.8286 | Train acc: 0.7892 | Train kappa: 0.6342 \n",
      "Val loss: 0.3422 | Val precision: 0.6402 | Val recall: 0.7466 | Val f1score: 0.6838 | Val acc: 0.8756 | Val kappa: 0.4071 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0002997395775429687\n",
      "Train loss: 0.4190 | Train precision: 0.8370 | Train recall: 0.8407 | Train f1score: 0.8388 | Train acc: 0.7999 | Train kappa: 0.6545 \n",
      "Val loss: 0.3365 | Val precision: 0.6989 | Val recall: 0.7297 | Val f1score: 0.7127 | Val acc: 0.8860 | Val kappa: 0.4145 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0002547786409115234\n",
      "Train loss: 0.3979 | Train precision: 0.8476 | Train recall: 0.8511 | Train f1score: 0.8493 | Train acc: 0.8127 | Train kappa: 0.6740 \n",
      "Val loss: 0.3896 | Val precision: 0.6177 | Val recall: 0.7414 | Val f1score: 0.6572 | Val acc: 0.8387 | Val kappa: 0.3677 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.00021656184477479486\n",
      "Train loss: 0.3809 | Train precision: 0.8591 | Train recall: 0.8609 | Train f1score: 0.8599 | Train acc: 0.8215 | Train kappa: 0.6937 \n",
      "Val loss: 0.4207 | Val precision: 0.6540 | Val recall: 0.7196 | Val f1score: 0.6581 | Val acc: 0.8106 | Val kappa: 0.3221 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00018407756805857562\n",
      "Train loss: 0.3698 | Train precision: 0.8618 | Train recall: 0.8620 | Train f1score: 0.8617 | Train acc: 0.8263 | Train kappa: 0.7004 \n",
      "Val loss: 0.4483 | Val precision: 0.6463 | Val recall: 0.7546 | Val f1score: 0.6638 | Val acc: 0.7967 | Val kappa: 0.3219 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015646593284978928\n",
      "Train loss: 0.3443 | Train precision: 0.8791 | Train recall: 0.8804 | Train f1score: 0.8793 | Train acc: 0.8445 | Train kappa: 0.7322 \n",
      "Val loss: 0.4071 | Val precision: 0.6092 | Val recall: 0.7485 | Val f1score: 0.6529 | Val acc: 0.8273 | Val kappa: 0.3441 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.0001329960429223209\n",
      "Train loss: 0.3325 | Train precision: 0.8805 | Train recall: 0.8858 | Train f1score: 0.8825 | Train acc: 0.8509 | Train kappa: 0.7435 \n",
      "Val loss: 0.4166 | Val precision: 0.6869 | Val recall: 0.7240 | Val f1score: 0.6737 | Val acc: 0.8059 | Val kappa: 0.3151 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 0.00011304663648397275\n",
      "Train loss: 0.3168 | Train precision: 0.8908 | Train recall: 0.8924 | Train f1score: 0.8911 | Train acc: 0.8591 | Train kappa: 0.7581 \n",
      "Val loss: 0.4311 | Val precision: 0.6479 | Val recall: 0.7392 | Val f1score: 0.6623 | Val acc: 0.8040 | Val kappa: 0.3195 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 9.608964101137683e-05\n",
      "Train loss: 0.3053 | Train precision: 0.8911 | Train recall: 0.8957 | Train f1score: 0.8929 | Train acc: 0.8610 | Train kappa: 0.7610 \n",
      "Val loss: 0.4395 | Val precision: 0.5890 | Val recall: 0.7233 | Val f1score: 0.6263 | Val acc: 0.8059 | Val kappa: 0.3043 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 8.16761948596703e-05\n",
      "Train loss: 0.2946 | Train precision: 0.9032 | Train recall: 0.9041 | Train f1score: 0.9028 | Train acc: 0.8734 | Train kappa: 0.7820 \n",
      "Val loss: 0.3961 | Val precision: 0.6528 | Val recall: 0.7244 | Val f1score: 0.6744 | Val acc: 0.8444 | Val kappa: 0.3539 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 6.942476563071976e-05\n",
      "Train loss: 0.2887 | Train precision: 0.9038 | Train recall: 0.9083 | Train f1score: 0.9053 | Train acc: 0.8788 | Train kappa: 0.7922 \n",
      "Val loss: 0.4484 | Val precision: 0.6391 | Val recall: 0.7284 | Val f1score: 0.6545 | Val acc: 0.8005 | Val kappa: 0.3025 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.9011050786111795e-05\n",
      "Train loss: 0.2724 | Train precision: 0.9075 | Train recall: 0.9107 | Train f1score: 0.9087 | Train acc: 0.8800 | Train kappa: 0.7919 \n",
      "Val loss: 0.4448 | Val precision: 0.6408 | Val recall: 0.7116 | Val f1score: 0.6529 | Val acc: 0.8103 | Val kappa: 0.3011 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 5.015939316819502e-05\n",
      "Train loss: 0.2655 | Train precision: 0.9114 | Train recall: 0.9167 | Train f1score: 0.9135 | Train acc: 0.8875 | Train kappa: 0.8066 \n",
      "Val loss: 0.4515 | Val precision: 0.6489 | Val recall: 0.7138 | Val f1score: 0.6553 | Val acc: 0.8033 | Val kappa: 0.2950 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 4.2635484192965766e-05\n",
      "Train loss: 0.2683 | Train precision: 0.9118 | Train recall: 0.9155 | Train f1score: 0.9127 | Train acc: 0.8866 | Train kappa: 0.8049 \n",
      "Val loss: 0.4180 | Val precision: 0.6246 | Val recall: 0.7062 | Val f1score: 0.6501 | Val acc: 0.8305 | Val kappa: 0.3149 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 3.62401615640209e-05\n",
      "Train loss: 0.2547 | Train precision: 0.9139 | Train recall: 0.9172 | Train f1score: 0.9147 | Train acc: 0.8888 | Train kappa: 0.8095 \n",
      "Val loss: 0.4208 | Val precision: 0.6471 | Val recall: 0.7105 | Val f1score: 0.6637 | Val acc: 0.8403 | Val kappa: 0.3452 \n",
      "\n",
      "Epoch: 23 \n",
      "Learning rate: 3.080413732941777e-05\n",
      "Train loss: 0.2453 | Train precision: 0.9198 | Train recall: 0.9252 | Train f1score: 0.9219 | Train acc: 0.8974 | Train kappa: 0.8225 \n",
      "Val loss: 0.4016 | Val precision: 0.6614 | Val recall: 0.7053 | Val f1score: 0.6737 | Val acc: 0.8551 | Val kappa: 0.3610 \n",
      "\n",
      "Epoch: 24 \n",
      "Learning rate: 2.61835167300051e-05\n",
      "Train loss: 0.2454 | Train precision: 0.9195 | Train recall: 0.9239 | Train f1score: 0.9209 | Train acc: 0.8971 | Train kappa: 0.8220 \n",
      "Val loss: 0.4073 | Val precision: 0.6796 | Val recall: 0.7180 | Val f1score: 0.6861 | Val acc: 0.8463 | Val kappa: 0.3481 \n",
      "\n",
      "Early stopping after epoch 24\n",
      "--------------------------------------------------\n",
      "\n",
      "Check shapes:\n",
      "\n",
      "Images train dataset: (12764, 250, 250, 3)\n",
      "Labels train dataset: (12764, 1)\n",
      "\n",
      "Images validation dataset: (3209, 250, 250, 3)\n",
      "Labels validation dataset: (3209, 1)\n",
      "\n",
      "--------------------------------------------------\n",
      "Check if the split was stratified: (random_state=42)\n",
      "Healthy trees in train dataset: 11574\n",
      "Stressed trees in train dataset: 974\n",
      "Dead trees in train dataset: 216\n",
      "Healthy trees in validation dataset: 2891\n",
      "Stressed trees in validation dataset: 266\n",
      "Dead trees in validation dataset: 52\n",
      "Ratio health trees in validation dataset: 0.19986173522295195\n",
      "Ratio stressed trees in validation dataset: 0.21451612903225806\n",
      "Ratio dead trees in validation dataset: 0.19402985074626866\n",
      "--------------------------------------------------\n",
      "\n",
      "Creating datasets for fold: 5\n",
      "\n",
      "Creating dataloaders for fold: 5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnet_b7 model.\n",
      "\n",
      "[INFO] Fold number: 5\n",
      "[INFO] Number of epochs: 50\n",
      "[INFO] Batch_size: 32\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.5\n",
      "[INFO] Gamma learning rate: 0.85\n",
      "[INFO] Created SummaryWriter, saving to: EffNet_kFold_RGB_3classes_log_evaluation\\2023-04-06\\kFold_RGB_3classes\\EffNet_b7\\50_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b01893d7b24b96bf6b9e6dc67200ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "Learning rate: 0.0011\n",
      "Train loss: 0.6714 | Train precision: 0.6793 | Train recall: 0.6816 | Train f1score: 0.6804 | Train acc: 0.6734 | Train kappa: 0.4327 \n",
      "Val loss: 0.3849 | Val precision: 0.5366 | Val recall: 0.6524 | Val f1score: 0.5478 | Val acc: 0.8850 | Val kappa: 0.2761 \n",
      "\n",
      "Epoch: 2 \n",
      "Learning rate: 0.0009350000000000001\n",
      "Train loss: 0.5693 | Train precision: 0.7605 | Train recall: 0.7636 | Train f1score: 0.7620 | Train acc: 0.7330 | Train kappa: 0.5407 \n",
      "Val loss: 0.3818 | Val precision: 0.5829 | Val recall: 0.7309 | Val f1score: 0.6347 | Val acc: 0.8313 | Val kappa: 0.3074 \n",
      "\n",
      "Epoch: 3 \n",
      "Learning rate: 0.00079475\n",
      "Train loss: 0.5423 | Train precision: 0.7774 | Train recall: 0.7804 | Train f1score: 0.7787 | Train acc: 0.7498 | Train kappa: 0.5666 \n",
      "Val loss: 0.4456 | Val precision: 0.6619 | Val recall: 0.7544 | Val f1score: 0.6895 | Val acc: 0.8209 | Val kappa: 0.3154 \n",
      "\n",
      "Epoch: 4 \n",
      "Learning rate: 0.0006755375\n",
      "Train loss: 0.5096 | Train precision: 0.7995 | Train recall: 0.7995 | Train f1score: 0.7995 | Train acc: 0.7681 | Train kappa: 0.5977 \n",
      "Val loss: 0.6104 | Val precision: 0.6723 | Val recall: 0.7687 | Val f1score: 0.6486 | Val acc: 0.6862 | Val kappa: 0.2301 \n",
      "\n",
      "Epoch: 5 \n",
      "Learning rate: 0.0005742068749999999\n",
      "Train loss: 0.4955 | Train precision: 0.8107 | Train recall: 0.8097 | Train f1score: 0.8102 | Train acc: 0.7794 | Train kappa: 0.6175 \n",
      "Val loss: 0.5874 | Val precision: 0.5954 | Val recall: 0.7850 | Val f1score: 0.6173 | Val acc: 0.6991 | Val kappa: 0.2367 \n",
      "\n",
      "Epoch: 6 \n",
      "Learning rate: 0.0004880758437499999\n",
      "Train loss: 0.4633 | Train precision: 0.8313 | Train recall: 0.8284 | Train f1score: 0.8298 | Train acc: 0.7977 | Train kappa: 0.6500 \n",
      "Val loss: 0.5481 | Val precision: 0.5483 | Val recall: 0.7793 | Val f1score: 0.5887 | Val acc: 0.7269 | Val kappa: 0.2566 \n",
      "\n",
      "Epoch: 7 \n",
      "Learning rate: 0.0004148644671874999\n",
      "Train loss: 0.4552 | Train precision: 0.8306 | Train recall: 0.8289 | Train f1score: 0.8298 | Train acc: 0.7952 | Train kappa: 0.6463 \n",
      "Val loss: 0.3065 | Val precision: 0.6885 | Val recall: 0.7317 | Val f1score: 0.7087 | Val acc: 0.8825 | Val kappa: 0.3833 \n",
      "\n",
      "Epoch: 8 \n",
      "Learning rate: 0.0003526347971093749\n",
      "Train loss: 0.4291 | Train precision: 0.8421 | Train recall: 0.8404 | Train f1score: 0.8412 | Train acc: 0.8057 | Train kappa: 0.6630 \n",
      "Val loss: 0.5065 | Val precision: 0.6535 | Val recall: 0.7717 | Val f1score: 0.6769 | Val acc: 0.7816 | Val kappa: 0.2909 \n",
      "\n",
      "Epoch: 9 \n",
      "Learning rate: 0.0002997395775429687\n",
      "Train loss: 0.4090 | Train precision: 0.8522 | Train recall: 0.8517 | Train f1score: 0.8520 | Train acc: 0.8182 | Train kappa: 0.6880 \n",
      "Val loss: 0.4306 | Val precision: 0.6894 | Val recall: 0.7827 | Val f1score: 0.7041 | Val acc: 0.7991 | Val kappa: 0.3192 \n",
      "\n",
      "Epoch: 10 \n",
      "Learning rate: 0.0002547786409115234\n",
      "Train loss: 0.3857 | Train precision: 0.8624 | Train recall: 0.8646 | Train f1score: 0.8634 | Train acc: 0.8310 | Train kappa: 0.7086 \n",
      "Val loss: 0.4203 | Val precision: 0.6360 | Val recall: 0.7718 | Val f1score: 0.6698 | Val acc: 0.7912 | Val kappa: 0.3006 \n",
      "\n",
      "Epoch: 11 \n",
      "Learning rate: 0.00021656184477479486\n",
      "Train loss: 0.3794 | Train precision: 0.8616 | Train recall: 0.8654 | Train f1score: 0.8635 | Train acc: 0.8295 | Train kappa: 0.7059 \n",
      "Val loss: 0.4707 | Val precision: 0.5964 | Val recall: 0.7899 | Val f1score: 0.6445 | Val acc: 0.7831 | Val kappa: 0.3102 \n",
      "\n",
      "Epoch: 12 \n",
      "Learning rate: 0.00018407756805857562\n",
      "Train loss: 0.3493 | Train precision: 0.8749 | Train recall: 0.8810 | Train f1score: 0.8778 | Train acc: 0.8449 | Train kappa: 0.7328 \n",
      "Val loss: 0.4492 | Val precision: 0.6601 | Val recall: 0.7785 | Val f1score: 0.6817 | Val acc: 0.7816 | Val kappa: 0.2985 \n",
      "\n",
      "Epoch: 13 \n",
      "Learning rate: 0.00015646593284978928\n",
      "Train loss: 0.3502 | Train precision: 0.8762 | Train recall: 0.8793 | Train f1score: 0.8775 | Train acc: 0.8445 | Train kappa: 0.7317 \n",
      "Val loss: 0.3950 | Val precision: 0.6188 | Val recall: 0.7670 | Val f1score: 0.6669 | Val acc: 0.8244 | Val kappa: 0.3370 \n",
      "\n",
      "Epoch: 14 \n",
      "Learning rate: 0.0001329960429223209\n",
      "Train loss: 0.3233 | Train precision: 0.8867 | Train recall: 0.8913 | Train f1score: 0.8887 | Train acc: 0.8569 | Train kappa: 0.7531 \n",
      "Val loss: 0.3886 | Val precision: 0.6305 | Val recall: 0.7462 | Val f1score: 0.6692 | Val acc: 0.8250 | Val kappa: 0.3180 \n",
      "\n",
      "Epoch: 15 \n",
      "Learning rate: 0.00011304663648397275\n",
      "Train loss: 0.3085 | Train precision: 0.8932 | Train recall: 0.8970 | Train f1score: 0.8950 | Train acc: 0.8650 | Train kappa: 0.7689 \n",
      "Val loss: 0.4057 | Val precision: 0.6143 | Val recall: 0.7574 | Val f1score: 0.6629 | Val acc: 0.8291 | Val kappa: 0.3323 \n",
      "\n",
      "Epoch: 16 \n",
      "Learning rate: 9.608964101137683e-05\n",
      "Train loss: 0.2996 | Train precision: 0.8983 | Train recall: 0.9021 | Train f1score: 0.8999 | Train acc: 0.8717 | Train kappa: 0.7807 \n",
      "Val loss: 0.4526 | Val precision: 0.6444 | Val recall: 0.7599 | Val f1score: 0.6736 | Val acc: 0.7959 | Val kappa: 0.2938 \n",
      "\n",
      "Epoch: 17 \n",
      "Learning rate: 8.16761948596703e-05\n",
      "Train loss: 0.2806 | Train precision: 0.9056 | Train recall: 0.9088 | Train f1score: 0.9070 | Train acc: 0.8790 | Train kappa: 0.7912 \n",
      "Val loss: 0.4401 | Val precision: 0.6365 | Val recall: 0.7590 | Val f1score: 0.6758 | Val acc: 0.8213 | Val kappa: 0.3229 \n",
      "\n",
      "Epoch: 18 \n",
      "Learning rate: 6.942476563071976e-05\n",
      "Train loss: 0.2611 | Train precision: 0.9134 | Train recall: 0.9171 | Train f1score: 0.9150 | Train acc: 0.8901 | Train kappa: 0.8107 \n",
      "Val loss: 0.4924 | Val precision: 0.6514 | Val recall: 0.7659 | Val f1score: 0.6802 | Val acc: 0.7997 | Val kappa: 0.3024 \n",
      "\n",
      "Epoch: 19 \n",
      "Learning rate: 5.9011050786111795e-05\n",
      "Train loss: 0.2552 | Train precision: 0.9171 | Train recall: 0.9206 | Train f1score: 0.9185 | Train acc: 0.8937 | Train kappa: 0.8175 \n",
      "Val loss: 0.4522 | Val precision: 0.6540 | Val recall: 0.7596 | Val f1score: 0.6850 | Val acc: 0.8166 | Val kappa: 0.3168 \n",
      "\n",
      "Epoch: 20 \n",
      "Learning rate: 5.015939316819502e-05\n",
      "Train loss: 0.2500 | Train precision: 0.9192 | Train recall: 0.9236 | Train f1score: 0.9211 | Train acc: 0.8972 | Train kappa: 0.8233 \n",
      "Val loss: 0.4312 | Val precision: 0.6669 | Val recall: 0.7581 | Val f1score: 0.6960 | Val acc: 0.8309 | Val kappa: 0.3321 \n",
      "\n",
      "Epoch: 21 \n",
      "Learning rate: 4.2635484192965766e-05\n",
      "Train loss: 0.2462 | Train precision: 0.9216 | Train recall: 0.9246 | Train f1score: 0.9228 | Train acc: 0.8987 | Train kappa: 0.8252 \n",
      "Val loss: 0.4547 | Val precision: 0.6453 | Val recall: 0.7485 | Val f1score: 0.6800 | Val acc: 0.8266 | Val kappa: 0.3157 \n",
      "\n",
      "Epoch: 22 \n",
      "Learning rate: 3.62401615640209e-05\n",
      "Train loss: 0.2285 | Train precision: 0.9253 | Train recall: 0.9289 | Train f1score: 0.9267 | Train acc: 0.9054 | Train kappa: 0.8374 \n",
      "Val loss: 0.4300 | Val precision: 0.6639 | Val recall: 0.7496 | Val f1score: 0.6948 | Val acc: 0.8419 | Val kappa: 0.3379 \n",
      "\n",
      "Early stopping after epoch 22\n",
      "--------------------------------------------------\n",
      "\n",
      "CPU times: total: 20h 24min 19s\n",
      "Wall time: 21h 31min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set the random seeds\n",
    "set_seeds(42)\n",
    "\n",
    "# Define the number of folds\n",
    "num_folds = 5\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "unique_values = np.unique(hash_id) # now there are less unique values left because we seperated the test dataset\n",
    "num_unique = len(unique_values)\n",
    "print(f\"There are {num_unique} unique values within hash_id.\\n\")\n",
    "\n",
    "# Loop over each fold\n",
    "for fold, (train_ids, val_ids) in enumerate(kf.split(unique_values)):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # 1. Split data into train and validation set\n",
    "    # Get the training and testing data for this fold\n",
    "    # Use np.isin() to create boolean arrays indicating which indices belong to train or test sets\n",
    "    train_indices = np.isin(hash_id, unique_values[train_ids])\n",
    "    val_indices = np.isin(hash_id, unique_values[val_ids])\n",
    "    \n",
    "    # Reshape boolean arrays to match shape of image_set and label_set\n",
    "    train_indices = train_indices.reshape(-1, 1)\n",
    "    val_indices = val_indices.reshape(-1, 1)\n",
    "    \n",
    "    # Select images and labels for train and validation sets\n",
    "    train_image_set = image_set[train_indices[:, 0]]\n",
    "    train_label_set = label_set[train_indices[:, 0]]\n",
    "    train_hash_id = hash_id[train_indices[:, 0]]\n",
    "    train_species_set = species_set[train_indices[:, 0]]\n",
    "    val_image_set = image_set[val_indices[:, 0]]\n",
    "    val_label_set = label_set[val_indices[:, 0]]\n",
    "    val_hash_id = hash_id[val_indices[:, 0]]\n",
    "    val_species_set = species_set[val_indices[:, 0]]\n",
    "    train_label_set = train_label_set.reshape(-1, 1)\n",
    "    val_label_set = val_label_set.reshape(-1, 1)\n",
    "    train_hash_id = train_hash_id.reshape(-1, 1)\n",
    "    val_hash_id = val_hash_id.reshape(-1, 1)\n",
    "    train_species_set = train_species_set.reshape(-1, 1)\n",
    "    val_species_set = val_species_set.reshape(-1, 1)\n",
    "            \n",
    "    print(\"Check shapes:\\n\")\n",
    "    print(f\"Images train dataset: {train_image_set.shape}\")\n",
    "    print(f\"Labels train dataset: {train_label_set.shape}\\n\")\n",
    "    \n",
    "    print(f\"Images validation dataset: {val_image_set.shape}\")\n",
    "    print(f\"Labels validation dataset: {val_label_set.shape}\\n\")\n",
    "    print('-'*50)\n",
    "    print (f\"Check if the split was stratified: (random_state=42)\")\n",
    "    print(f\"Healthy trees in train dataset: {np.count_nonzero(train_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in train dataset: {np.count_nonzero(train_label_set == 1)}\")\n",
    "    print(f\"Dead trees in train dataset: {np.count_nonzero(train_label_set == 2)}\")\n",
    "    print(f\"Healthy trees in validation dataset: {np.count_nonzero(val_label_set == 0)}\")\n",
    "    print(f\"Stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)}\")\n",
    "    print(f\"Dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)}\")\n",
    "    print(f\"Ratio health trees in validation dataset: {np.count_nonzero(val_label_set == 0)/np.count_nonzero(label_set == 0)}\")\n",
    "    print(f\"Ratio stressed trees in validation dataset: {np.count_nonzero(val_label_set == 1)/np.count_nonzero(label_set == 1)}\")\n",
    "    print(f\"Ratio dead trees in validation dataset: {np.count_nonzero(val_label_set == 2)/np.count_nonzero(label_set == 2)}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # 2. Create train and validation dataset. (choose custom dataset loader with 3 - 5 classes)\n",
    "    print(f\"\\nCreating datasets for fold: {fold + 1}\\n\")\n",
    "    train_dataset = data_loader.CustomDataset3Classes_v2(data=train_image_set, labels=train_label_set, class_names=class_names, species = train_species_set,\n",
    "                                                         transform=transform_train)\n",
    "    \n",
    "    val_dataset = data_loader.CustomDataset3Classes_v2(data=val_image_set, labels=val_label_set, class_names=class_names,\n",
    "                                                       species = val_species_set, transform=transform)\n",
    "    \n",
    "    # 3. Create train and validation dataloader\n",
    "    # create sampler for oversampling of the minority classes\n",
    "    sampler = data_loader.data_sampler(dataset=train_dataset, class_names=class_names)\n",
    "    print(f\"Creating dataloaders for fold: {fold +1}\\n\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, generator=g,\n",
    "                              sampler=sampler, shuffle=False, drop_last=True) # shuffle false because of the sampler\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, shuffle=False,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    model = models.create_effnetb7(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    #lr_scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "    \n",
    "    fold += 1\n",
    "    print(f\"\\n[INFO] Fold number: {fold}\")\n",
    "    print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "    print(f\"[INFO] Batch_size: {batch_size}\")\n",
    "    print(f\"[INFO] Number of bands: {n_bands}\")\n",
    "    print(f\"[INFO] Dropout rate: {dropout_rate}\")\n",
    "    print(f\"[INFO] Gamma learning rate: {gamma}\")\n",
    "    # 4. Train model with k fold dataloaders and track experiments\n",
    "    if fold == 1:\n",
    "        fold1_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(target_dir=target_dir, experiment_name=experiment_name, model_name=model_name, extra=f\"{epochs}_epochs\"), early_stop_patience = patience)\n",
    "    elif fold == 2:\n",
    "        fold2_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(target_dir=target_dir, experiment_name=experiment_name, model_name=model_name, extra=f\"{epochs}_epochs\"), early_stop_patience = patience)\n",
    "    elif fold == 3:\n",
    "        fold3_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(target_dir=target_dir, experiment_name=experiment_name, model_name=model_name, extra=f\"{epochs}_epochs\"), early_stop_patience = patience)\n",
    "    elif fold == 4:\n",
    "        fold4_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(target_dir=target_dir, experiment_name=experiment_name, model_name=model_name, extra=f\"{epochs}_epochs\"), early_stop_patience = patience)\n",
    "    else:\n",
    "        fold5_results = train(model=model, model_name=model_name, n_bands=n_bands, batch_size=batch_size,train_dataloader=train_dataloader, val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer, loss_fn=loss_fn, lr_scheduler=lr_scheduler, num_classes=num_classes, epochs=epochs, experiment_num=fold, device=device,\n",
    "                        writer=create_writer(target_dir=target_dir, experiment_name=experiment_name, model_name=model_name, extra=f\"{epochs}_epochs\"), early_stop_patience = patience)\n",
    "    \n",
    "    del train_indices, val_indices, train_image_set, train_label_set, train_hash_id, train_species_set, val_image_set, val_label_set, val_hash_id, val_species_set,\n",
    "    train_dataset, val_dataset, sampler, train_dataloader, val_dataloader, model, loss_fn, optimizer, lr_scheduler\n",
    "    print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c36ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = data_loader.CustomDataset3Classes(\n",
    "    data = test_image_set,\n",
    "    labels = test_label_set,\n",
    "    class_names=class_names, \n",
    "    species = test_species_set,\n",
    "    kkl = test_kkl_set,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# create test dataloader\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             persistent_workers=True,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67db5af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnet_b0 model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the best model filepath\n",
    "best_model_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\effnet_b0\\01_18_epochs.pth\"\n",
    "\n",
    "# Instantiate a new instance of EffNetB0 (to load the saved state_dict() to)\n",
    "unfreeze=True\n",
    "best_model = models.create_effnetb0(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "\n",
    "# Load the saved best model state_dict()\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dfbc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, \n",
    "                     test_dataloader: torch.utils.data.DataLoader,\n",
    "                     device: torch.device):\n",
    "    # 1. Make predictions with trained model\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "            # Send data and targets to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Do the forward pass\n",
    "            y_logit = model(X)\n",
    "            # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "            y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "            # Put predictions on CPU for evaluation\n",
    "            y_preds.append(y_pred.cpu())\n",
    "            y_labels.append(y.cpu())\n",
    "            \n",
    "            #other metrics\n",
    "            test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "            y_pred_class = y_pred.detach().cpu().numpy() \n",
    "            y_class = y.detach().cpu().numpy()\n",
    "            labels = np.array([0])\n",
    "            test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "            \n",
    "            #if count >= 1:\n",
    "            #    y_set = torch.cat((y_set, y))\n",
    "            #    count = count + 1\n",
    "            #else:\n",
    "            #    y_set = y\n",
    "            #    count = count + 1\n",
    "            \n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "    test_precision = test_precision / len(test_dataloader)\n",
    "    test_recall = test_recall / len(test_dataloader)\n",
    "    test_f1_score = test_f1_score / len(test_dataloader)\n",
    "    #test_kappa = test_kappa / len(dataloader)\n",
    "    test_acc = test_acc / len(test_dataloader)\n",
    "    # Concatenate list of predictions into a tensor\n",
    "    y_pred_tensor = torch.cat(y_preds)\n",
    "    y_labels_tensor = torch.cat(y_labels)\n",
    "    test_f1_score = f1_score(y_labels_tensor.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=1, labels=[0,1,2])\n",
    "    \n",
    "    # Print classification report\n",
    "    y_true = y_labels_tensor.detach().cpu().numpy()\n",
    "    report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    return y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aab9e321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b3144341ab41f3b234434aa09299e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.95      0.88      0.92      2228\n",
      "    stressed       0.32      0.56      0.41       226\n",
      "        dead       0.84      0.86      0.85        42\n",
      "\n",
      "    accuracy                           0.85      2496\n",
      "   macro avg       0.70      0.77      0.72      2496\n",
      "weighted avg       0.89      0.85      0.87      2496\n",
      "\n",
      "Test loss: 0.0\n",
      "Test precision: 0.4154684139459786\n",
      "Test recall: 0.41671078506014464\n",
      "Test F1score: 0.7247865216737815\n",
      "Test Accuracy: 0.8525641025641025\n",
      "Test Logits: tensor([[ 1.7014,  0.8877, -5.1889],\n",
      "        [ 2.3632,  0.8889, -6.1630],\n",
      "        [ 2.2219,  0.9962, -6.0906],\n",
      "        [-0.6744,  0.1306,  0.6790],\n",
      "        [ 0.9584,  1.0023, -4.1342],\n",
      "        [ 1.1653,  0.9413, -4.2456],\n",
      "        [ 1.9196,  1.0043, -5.6535],\n",
      "        [ 0.5722,  0.7214, -2.7888],\n",
      "        [ 2.0116,  1.1527, -6.1480],\n",
      "        [ 2.0599,  1.0727, -6.0320],\n",
      "        [ 2.1480,  0.9218, -5.8122],\n",
      "        [ 1.8820,  0.8687, -5.2790],\n",
      "        [ 1.5475,  1.0596, -5.1709],\n",
      "        [ 1.8884,  0.9385, -5.4567],\n",
      "        [ 1.7652,  1.0623, -5.5407],\n",
      "        [ 1.1063,  0.8732, -4.0481]], device='cuda:0')\n",
      "Test Predictions: tensor([0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Test Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "#from wze_uav.analysis import *\n",
    "y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds = make_predictions(model=best_model,\n",
    "                                 test_dataloader=test_dataloader, \n",
    "                                 device=device)\n",
    "\n",
    "y_labels_tensor = y_labels_tensor.detach().cpu().numpy()\n",
    "y_pred_tensor = y_pred_tensor.detach().cpu().numpy()\n",
    "\n",
    "#confmat = ConfusionMatrix(num_classes=num_classes, task='multiclass')\n",
    "#confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "#                         target=test_labels)\n",
    "labels = np.array([0,1,2])\n",
    "confmat = confusion_matrix(y_labels_tensor, y_pred_tensor, labels=labels)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat, # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test recall: {test_recall}\")\n",
    "print(f\"Test F1score: {test_f1_score}\")\n",
    "#print(f\"Test Kappa: {test_kappa}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Logits: {y_logit}\")\n",
    "print(f\"Test Predictions: {y_pred}\")\n",
    "print(f\"Test Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d4173b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7588116f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_set\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_set' is not defined"
     ]
    }
   ],
   "source": [
    "y_set.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c195b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6da05604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a223988f3a8b4b2eae8b8b3b3f7776de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.94      0.90      0.92      2228\n",
      "    stressed       0.42      0.31      0.35       226\n",
      "        dead       0.19      0.83      0.32        42\n",
      "\n",
      "    accuracy                           0.85      2496\n",
      "   macro avg       0.52      0.68      0.53      2496\n",
      "weighted avg       0.88      0.85      0.86      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "y_labels = []\n",
    "labels = np.array([0,1,2])\n",
    "test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "count = 0\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logit = model(X)\n",
    "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_labels.append(y.cpu())\n",
    "        \n",
    "        #other metrics\n",
    "        test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "        y_pred_class = y_pred.detach().cpu().numpy() \n",
    "        y_class = y.detach().cpu().numpy()\n",
    "        test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        \n",
    "        #if count >= 1:\n",
    "        #    y_set = torch.cat((y_set, y))\n",
    "        #    count = count + 1\n",
    "        #else:\n",
    "        #    y_set = y\n",
    "        #    count = count + 1\n",
    "        \n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_precision = test_precision / len(test_dataloader)\n",
    "test_recall = test_recall / len(test_dataloader)\n",
    "#test_f1_score = test_f1_score / len(test_dataloader)\n",
    "#test_kappa = test_kappa / len(dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "test_f1_score = f1_score(y_set.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=0, labels=[0,1,2])\n",
    "\n",
    "# Print classification report\n",
    "y_true = y_set.detach().cpu().numpy()\n",
    "report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ae97fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528680154128826"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ebafd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make = (y_class == y_pred_class)\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f8aa759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(y_logit, dim=1).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f90a54b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a806154",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (y_pred == y).sum().item()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1da35c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_class = y_pred.detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "602e096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
