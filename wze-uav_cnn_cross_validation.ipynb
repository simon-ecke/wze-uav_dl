{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1acdaa3",
   "metadata": {},
   "source": [
    "# WZE-UAV Image Classification using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2159aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2554cd7b2e0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import mlxtend\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "x = (1,3)\n",
    "y = (1,3)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0026f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchinfo import summary\n",
    "from torchmetrics import *\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b160d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wze_uav.data_loader as data_loader\n",
    "import wze_uav.visualization as visualization\n",
    "import wze_uav.models as models\n",
    "from wze_uav.engine import *\n",
    "from wze_uav.utils2 import *\n",
    "from wze_uav.log_writer import create_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4fb2f",
   "metadata": {},
   "source": [
    "#### Get PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10886b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1+cu116\n",
      "torchvision version: 0.14.1+cu116\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a83cf",
   "metadata": {},
   "source": [
    "#### Preparing device agnostic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d5de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Index of current divice: 0\n",
      "Number of GPUs available: 1\n",
      "GPU Model: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "# ensure device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# get index of currently selected device\n",
    "print(f\"Index of current divice: {torch.cuda.current_device()}\")\n",
    "# get number of GPUs available\n",
    "print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "# get the name of the device\n",
    "print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6a34",
   "metadata": {},
   "source": [
    "#### Ensure reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4656a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more information, see also: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Set seeds\n",
    "def set_seeds(seed: int=0):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 0.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# seed for numpy\n",
    "np.random.seed(0)\n",
    "# avoiding non-deterministic algorithms\n",
    "#torch.use_deterministic_algorithms(True)\n",
    "# Set to true -> might speed up the process but should be set to False if reproducible results are desired\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be33671",
   "metadata": {},
   "source": [
    "#### Define file directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30645f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds() # ensure reproducibility\n",
    "\n",
    "data_path = r\"D:\\Drohnendaten\\10_WZE-UAV\\Auswertung_findatree\\Datasplit\"\n",
    "\n",
    "test_data_path = r\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba3011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4560ce64",
   "metadata": {},
   "source": [
    "#### Create hashID for spatial seperation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = os.listdir(data_path)\n",
    "# Initialize dictionary to store groups of files with the same name\n",
    "file_groups = {}\n",
    "\n",
    "# Iterate over all datafiles\n",
    "for year in fn_list:\n",
    "    year_dir = f'{data_path}\\\\{year}'\n",
    "    for filename in os.listdir(year_dir):\n",
    "        # Generate unique identifier for file based on its name\n",
    "        identifier = hashlib.md5(filename.encode()).hexdigest()\n",
    "\n",
    "        # Add file to appropriate group based on identifier\n",
    "        if identifier in file_groups:\n",
    "            file_groups[identifier][year] = os.path.join(year_dir, filename)\n",
    "        else:\n",
    "            file_groups[identifier] = {year: os.path.join(year_dir, filename)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17de035",
   "metadata": {},
   "source": [
    "#### Prepare k-folds for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = file_groups\n",
    "\n",
    "# create lists of hashIDs and file paths\n",
    "hashIDs = []\n",
    "file_paths = []\n",
    "for hashID, files in data_dict.items():\n",
    "    for year, file_path in files.items():\n",
    "        hashIDs.append(hashID)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "# define the number of folds for k-fold cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# create the k-fold cross-validator with GroupKFold\n",
    "kf = GroupKFold(n_splits=num_folds)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b8c5e",
   "metadata": {},
   "source": [
    "#### Define model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be97e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "###### define Parameters######\n",
    "NUM_WORKERS=3 # should be changed, depending on the system used\n",
    "batch_size=16\n",
    "n_bands = 3 # define number of bands\n",
    "num_classes = len(classes)\n",
    "dropout_rate = 0.3 #define dropout rate\n",
    "unfreeze = True\n",
    "gamma = 0.65 # how fast the learning rate decreases per epoch (low number=faster decrease)\n",
    "weights = 2 # weight for the focal loss to give more importance to the minority classes\n",
    "#step_size = 1\n",
    "##############################\n",
    "\n",
    "\n",
    "classes = train_dataset.class_names\n",
    "num_classes = len(classes) # get output_shape (number of classes) as an argument for the model\n",
    "\n",
    "\n",
    "# train transform with augmentation. \n",
    "transform_train = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(p=0.5), transforms.RandomVerticalFlip(p=0.5), transforms.RandomRotation(degrees=[-90,90])])\n",
    "\n",
    "# test and val dataset transform without augmentation. \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "#class names need to fit the customDataset class used e.g. 3 classes -> use CustomDataset3Classes\n",
    "#class_names = ['healthy', 'slightly_stressed', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "#class_names = ['healthy', 'moderately_stressed', 'highly_stressed', 'dead']\n",
    "class_names = ['healthy', 'stressed', 'dead']\n",
    "\n",
    "# Define number of epochs per fold\n",
    "num_epochs = num_epochs\n",
    "\n",
    "# Create target folder name were to save the tensorboard event files\n",
    "target_dir = \"TEST_log_evaluation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d55d6",
   "metadata": {},
   "source": [
    "#### Perform k-fold cross validation and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "set_seeds()\n",
    "# group files with same names from each year based on their hashID to ensure spatial seperation of train and validation data\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(file_paths, groups=hashIDs)): \n",
    "    # get the train and validation file paths using the indices\n",
    "    train_files = [file_paths[i] for i in train_idx]\n",
    "    val_files = [file_paths[i] for i in val_idx]\n",
    "   \n",
    "    train_image_set, train_label_set, train_species_set, train_kkl_set, train_bk_set = data_loader.hdf5_to_img_label(train_files, load_sets = [\"images_masked\"])\n",
    "    val_image_set, val_label_set, val_species_set, val_kkl_set, val_bk_set = data_loader.hdf5_to_img_label(val_files, load_sets = [\"images_masked\"])\n",
    "    \n",
    "    # create PyTorch dataset - choose custom dataset loader with 3 - 5 classes\n",
    "    train_dataset = data_loader.CustomDataset3Classes(data = train_image_set, labels = train_label_set, class_names=class_names, species = train_species_set, kkl = train_kkl_set, transform=transform_train)\n",
    "    val_dataset = data_loader.CustomDataset3Classes(data = val_image_set, labels = val_label_set, class_names=class_names, species = val_species_set, kkl = val_kkl_set, transform=transform)\n",
    "     \n",
    "    # create sampler to handle class imbalance by oversampling the minority classes - will be used as argument in the train_dataloader\n",
    "    sampler = data_loader.data_sampler(labels_tensor=train_dataset.labels, class_names=class_names)\n",
    "    \n",
    "    # create PyTorch dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, generator=g, sampler=sampler, shuffle=False, drop_last=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, persistent_workers=True, pin_memory=True, num_workers=NUM_WORKERS, shuffle=False, drop_last=True)\n",
    "    \n",
    "    # set the initial learning rate\n",
    "    lr = 0.005\n",
    "    \n",
    "    model = create_effnetb2(output_shape=num_classes, dropout_rate=0.3, unfreeze=True, device=device)\n",
    "    model_name = \"Fold_\" + str(fold) + \"_EffNet_b2\"\n",
    "\n",
    "    # Create loss and optimizer\n",
    "    loss_fn = FocalLoss(weights=weights)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "    lr_scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "    \n",
    "    # Loop through each number of epochs within the fold\n",
    "    for epochs in num_epochs:\n",
    "    \n",
    "        # Create information print outs\n",
    "        experiment_number += 1\n",
    "        print(f\"[INFO] K-fold: {fold}\")\n",
    "        print(f\"[INFO] Model: {model_name}\")\n",
    "        print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "        print(f\"[INFO] Batch_size: {batch_size}\")\n",
    "        print(f\"[INFO] Number of bands: {n_bands}\")\n",
    "        print(f\"[INFO] Dropout rate: {dropout_rate}\")\n",
    "        print(f\"[INFO] Gamma learning rate: {gamma}\")\n",
    "        print(f\"[INFO] Gamma FocalLoss: {weights}\")\n",
    "        \n",
    "        # Train target model with target dataloaders and track experiments\n",
    "        results = train(model=model,\n",
    "                        model_name=model_name,\n",
    "                        n_bands=n_bands,\n",
    "                        batch_size=batch_size,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        val_dataloader=val_dataloader, \n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        lr_scheduler=lr_scheduler,\n",
    "                        num_classes=num_classes,\n",
    "                        epochs=epochs,\n",
    "                        device=device,\n",
    "                        writer=create_writer(target_dir=target_dir,\n",
    "                                             experiment_name='Evaluating_hyperparameters',\n",
    "                                             model_name=model_name,\n",
    "                                             extra=f\"{fold}_fold_{epochs}_epochs\"))\n",
    "        \n",
    "        # 10. Save the model to file so we can get back the best model\n",
    "        save_filepath = f\"01_{model_name}_{epochs}_epochs.pth\"\n",
    "        save_model(model=model,\n",
    "                   target_dir=\"finished_models\",\n",
    "                   model_name=save_filepath)\n",
    "        print(\"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1813c163",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Experiment number: 1\n",
      "[INFO] Model: effnet_b0\n",
      "[INFO] Number of epochs: 20\n",
      "[INFO] Batch_size: 16\n",
      "[INFO] Number of bands: 3\n",
      "[INFO] Dropout rate: 0.3\n",
      "[INFO] Gamma learning rate: 0.65\n",
      "[INFO] Gamma FocalLoss: 2\n",
      "[INFO] Created new effnet_b0 model.\n",
      "[INFO] Created SummaryWriter, saving to: TEST_log_evaluation\\2023-03-29\\Evaluating_hyperparameters\\effnet_b0\\20_epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e9515405c149fd9512a85e9b8bd9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.005\n",
      "Epoch: 1 \n",
      "Train loss: 0.2624 | Train precision: 0.6566 | Train recall: 0.6441 | Train f1score: 0.5644 | Train acc: 0.5865 \n",
      "Val loss: 0.4467 | Val precision: 0.7400 | Val recall: 0.3993 | Val f1score: 0.2868 | Val acc: 0.5076 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 2 \n",
      "Train loss: 0.2162 | Train precision: 0.6950 | Train recall: 0.6915 | Train f1score: 0.6277 | Train acc: 0.6252 \n",
      "Val loss: 0.1991 | Val precision: 0.8084 | Val recall: 0.6648 | Val f1score: 0.5962 | Val acc: 0.6674 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 3 \n",
      "Train loss: 0.2082 | Train precision: 0.7041 | Train recall: 0.7095 | Train f1score: 0.6507 | Train acc: 0.6477 \n",
      "Val loss: 0.2792 | Val precision: 0.8189 | Val recall: 0.5549 | Val f1score: 0.4953 | Val acc: 0.7410 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 4 \n",
      "Train loss: 0.2015 | Train precision: 0.7245 | Train recall: 0.7250 | Train f1score: 0.6755 | Train acc: 0.6651 \n",
      "Val loss: 0.1810 | Val precision: 0.8115 | Val recall: 0.6890 | Val f1score: 0.6186 | Val acc: 0.6562 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 5 \n",
      "Train loss: 0.1978 | Train precision: 0.7273 | Train recall: 0.7297 | Train f1score: 0.6825 | Train acc: 0.6703 \n",
      "Val loss: 0.1411 | Val precision: 0.8461 | Val recall: 0.8483 | Val f1score: 0.7187 | Val acc: 0.8934 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 6 \n",
      "Train loss: 0.1917 | Train precision: 0.7279 | Train recall: 0.7330 | Train f1score: 0.6883 | Train acc: 0.6715 \n",
      "Val loss: 0.5837 | Val precision: 0.7266 | Val recall: 0.5505 | Val f1score: 0.3739 | Val acc: 0.5118 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 7 \n",
      "Train loss: 0.1913 | Train precision: 0.7386 | Train recall: 0.7418 | Train f1score: 0.6975 | Train acc: 0.6796 \n",
      "Val loss: 0.1172 | Val precision: 0.8666 | Val recall: 0.7834 | Val f1score: 0.7299 | Val acc: 0.8399 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 8 \n",
      "Train loss: 0.1937 | Train precision: 0.7283 | Train recall: 0.7384 | Train f1score: 0.6895 | Train acc: 0.6723 \n",
      "Val loss: 0.1028 | Val precision: 0.8445 | Val recall: 0.9606 | Val f1score: 0.8225 | Val acc: 0.9323 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 9 \n",
      "Train loss: 0.1822 | Train precision: 0.7418 | Train recall: 0.7433 | Train f1score: 0.7037 | Train acc: 0.6806 \n",
      "Val loss: 0.2644 | Val precision: 0.7381 | Val recall: 0.6327 | Val f1score: 0.4712 | Val acc: 0.3705 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 10 \n",
      "Train loss: 0.1831 | Train precision: 0.7488 | Train recall: 0.7528 | Train f1score: 0.7136 | Train acc: 0.6913 \n",
      "Val loss: 0.2444 | Val precision: 0.7965 | Val recall: 0.5950 | Val f1score: 0.5014 | Val acc: 0.5674 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 11 \n",
      "Train loss: 0.1837 | Train precision: 0.7500 | Train recall: 0.7499 | Train f1score: 0.7100 | Train acc: 0.6859 \n",
      "Val loss: 0.1743 | Val precision: 0.8328 | Val recall: 0.6690 | Val f1score: 0.6148 | Val acc: 0.7340 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 12 \n",
      "Train loss: 0.1785 | Train precision: 0.7547 | Train recall: 0.7568 | Train f1score: 0.7180 | Train acc: 0.6933 \n",
      "Val loss: 0.1942 | Val precision: 0.8350 | Val recall: 0.6596 | Val f1score: 0.5934 | Val acc: 0.6622 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 13 \n",
      "Train loss: 0.1759 | Train precision: 0.7552 | Train recall: 0.7578 | Train f1score: 0.7181 | Train acc: 0.6979 \n",
      "Val loss: 0.1997 | Val precision: 0.8339 | Val recall: 0.6654 | Val f1score: 0.5993 | Val acc: 0.6566 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 14 \n",
      "Train loss: 0.1782 | Train precision: 0.7579 | Train recall: 0.7625 | Train f1score: 0.7230 | Train acc: 0.6993 \n",
      "Val loss: 0.2358 | Val precision: 0.7976 | Val recall: 0.6512 | Val f1score: 0.5519 | Val acc: 0.5507 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 15 \n",
      "Train loss: 0.1753 | Train precision: 0.7545 | Train recall: 0.7598 | Train f1score: 0.7155 | Train acc: 0.6965 \n",
      "Val loss: 0.3303 | Val precision: 0.6961 | Val recall: 0.6712 | Val f1score: 0.4153 | Val acc: 0.1896 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 16 \n",
      "Train loss: 0.1781 | Train precision: 0.7533 | Train recall: 0.7534 | Train f1score: 0.7148 | Train acc: 0.6923 \n",
      "Val loss: 0.2563 | Val precision: 0.8222 | Val recall: 0.5806 | Val f1score: 0.5105 | Val acc: 0.6392 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 17 \n",
      "Train loss: 0.1733 | Train precision: 0.7635 | Train recall: 0.7678 | Train f1score: 0.7302 | Train acc: 0.7079 \n",
      "Val loss: 0.1489 | Val precision: 0.8639 | Val recall: 0.7388 | Val f1score: 0.6870 | Val acc: 0.7750 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 18 \n",
      "Train loss: 0.1739 | Train precision: 0.7707 | Train recall: 0.7692 | Train f1score: 0.7343 | Train acc: 0.7079 \n",
      "Val loss: 1.0525 | Val precision: 0.5688 | Val recall: 0.3603 | Val f1score: 0.0595 | Val acc: 0.0594 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 19 \n",
      "Train loss: 0.1782 | Train precision: 0.7600 | Train recall: 0.7601 | Train f1score: 0.7209 | Train acc: 0.7011 \n",
      "Val loss: 0.1747 | Val precision: 0.8213 | Val recall: 0.7143 | Val f1score: 0.6479 | Val acc: 0.8003 \n",
      "\n",
      "Learning rate: 0.005\n",
      "Epoch: 20 \n",
      "Train loss: 0.1688 | Train precision: 0.7747 | Train recall: 0.7768 | Train f1score: 0.7444 | Train acc: 0.7185 \n",
      "Val loss: 0.1413 | Val precision: 0.8698 | Val recall: 0.7514 | Val f1score: 0.7058 | Val acc: 0.7944 \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "CPU times: total: 24min 8s\n",
      "Wall time: 22min 36s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c36ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = data_loader.CustomDataset3Classes(\n",
    "    data = test_image_set,\n",
    "    labels = test_label_set,\n",
    "    class_names=class_names, \n",
    "    species = test_species_set,\n",
    "    kkl = test_kkl_set,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# create test dataloader\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             persistent_workers=True,\n",
    "                             pin_memory=True,\n",
    "                             num_workers=NUM_WORKERS,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67db5af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnet_b0 model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the best model filepath\n",
    "best_model_path = r\"C:\\Users\\lwfeckesim\\01_PyTorch\\wze-uav\\wze-uav-master\\effnet_b0\\01_18_epochs.pth\"\n",
    "\n",
    "# Instantiate a new instance of EffNetB0 (to load the saved state_dict() to)\n",
    "unfreeze=True\n",
    "best_model = models.create_effnetb0(output_shape=num_classes, unfreeze=unfreeze, dropout_rate=dropout_rate, device=device)\n",
    "\n",
    "# Load the saved best model state_dict()\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6dfbc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, \n",
    "                     test_dataloader: torch.utils.data.DataLoader,\n",
    "                     device: torch.device):\n",
    "    # 1. Make predictions with trained model\n",
    "    y_preds = []\n",
    "    y_labels = []\n",
    "    test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "            # Send data and targets to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Do the forward pass\n",
    "            y_logit = model(X)\n",
    "            # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "            y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "            # Put predictions on CPU for evaluation\n",
    "            y_preds.append(y_pred.cpu())\n",
    "            y_labels.append(y.cpu())\n",
    "            \n",
    "            #other metrics\n",
    "            test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "            y_pred_class = y_pred.detach().cpu().numpy() \n",
    "            y_class = y.detach().cpu().numpy()\n",
    "            labels = np.array([0])\n",
    "            test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=0, labels=[0,1,2])\n",
    "            #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "            \n",
    "            #if count >= 1:\n",
    "            #    y_set = torch.cat((y_set, y))\n",
    "            #    count = count + 1\n",
    "            #else:\n",
    "            #    y_set = y\n",
    "            #    count = count + 1\n",
    "            \n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "    test_precision = test_precision / len(test_dataloader)\n",
    "    test_recall = test_recall / len(test_dataloader)\n",
    "    test_f1_score = test_f1_score / len(test_dataloader)\n",
    "    #test_kappa = test_kappa / len(dataloader)\n",
    "    test_acc = test_acc / len(test_dataloader)\n",
    "    # Concatenate list of predictions into a tensor\n",
    "    y_pred_tensor = torch.cat(y_preds)\n",
    "    y_labels_tensor = torch.cat(y_labels)\n",
    "    test_f1_score = f1_score(y_labels_tensor.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=1, labels=[0,1,2])\n",
    "    \n",
    "    # Print classification report\n",
    "    y_true = y_labels_tensor.detach().cpu().numpy()\n",
    "    report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "    print(report)\n",
    "    \n",
    "    return y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aab9e321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b3144341ab41f3b234434aa09299e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.95      0.88      0.92      2228\n",
      "    stressed       0.32      0.56      0.41       226\n",
      "        dead       0.84      0.86      0.85        42\n",
      "\n",
      "    accuracy                           0.85      2496\n",
      "   macro avg       0.70      0.77      0.72      2496\n",
      "weighted avg       0.89      0.85      0.87      2496\n",
      "\n",
      "Test loss: 0.0\n",
      "Test precision: 0.4154684139459786\n",
      "Test recall: 0.41671078506014464\n",
      "Test F1score: 0.7247865216737815\n",
      "Test Accuracy: 0.8525641025641025\n",
      "Test Logits: tensor([[ 1.7014,  0.8877, -5.1889],\n",
      "        [ 2.3632,  0.8889, -6.1630],\n",
      "        [ 2.2219,  0.9962, -6.0906],\n",
      "        [-0.6744,  0.1306,  0.6790],\n",
      "        [ 0.9584,  1.0023, -4.1342],\n",
      "        [ 1.1653,  0.9413, -4.2456],\n",
      "        [ 1.9196,  1.0043, -5.6535],\n",
      "        [ 0.5722,  0.7214, -2.7888],\n",
      "        [ 2.0116,  1.1527, -6.1480],\n",
      "        [ 2.0599,  1.0727, -6.0320],\n",
      "        [ 2.1480,  0.9218, -5.8122],\n",
      "        [ 1.8820,  0.8687, -5.2790],\n",
      "        [ 1.5475,  1.0596, -5.1709],\n",
      "        [ 1.8884,  0.9385, -5.4567],\n",
      "        [ 1.7652,  1.0623, -5.5407],\n",
      "        [ 1.1063,  0.8732, -4.0481]], device='cuda:0')\n",
      "Test Predictions: tensor([0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "Test Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "#from wze_uav.analysis import *\n",
    "y_pred_tensor, y_labels_tensor, test_loss, test_recall, test_precision, test_f1_score, test_acc, y_logit, y_pred, y, y_preds = make_predictions(model=best_model,\n",
    "                                 test_dataloader=test_dataloader, \n",
    "                                 device=device)\n",
    "\n",
    "y_labels_tensor = y_labels_tensor.detach().cpu().numpy()\n",
    "y_pred_tensor = y_pred_tensor.detach().cpu().numpy()\n",
    "\n",
    "#confmat = ConfusionMatrix(num_classes=num_classes, task='multiclass')\n",
    "#confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "#                         target=test_labels)\n",
    "labels = np.array([0,1,2])\n",
    "confmat = confusion_matrix(y_labels_tensor, y_pred_tensor, labels=labels)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat, # matplotlib likes working with NumPy \n",
    "    class_names=class_names, # turn the row and column labels into class names\n",
    "    figsize=(10, 7)\n",
    ");\n",
    "\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test precision: {test_precision}\")\n",
    "print(f\"Test recall: {test_recall}\")\n",
    "print(f\"Test F1score: {test_f1_score}\")\n",
    "#print(f\"Test Kappa: {test_kappa}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "print(f\"Test Logits: {y_logit}\")\n",
    "print(f\"Test Predictions: {y_pred}\")\n",
    "print(f\"Test Labels: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d4173b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7588116f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_set\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_set' is not defined"
     ]
    }
   ],
   "source": [
    "y_set.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c195b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ec08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6da05604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a223988f3a8b4b2eae8b8b3b3f7776de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.94      0.90      0.92      2228\n",
      "    stressed       0.42      0.31      0.35       226\n",
      "        dead       0.19      0.83      0.32        42\n",
      "\n",
      "    accuracy                           0.85      2496\n",
      "   macro avg       0.52      0.68      0.53      2496\n",
      "weighted avg       0.88      0.85      0.86      2496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "y_labels = []\n",
    "labels = np.array([0,1,2])\n",
    "test_loss, test_precision, test_recall, test_f1_score, test_acc = 0, 0, 0, 0, 0\n",
    "count = 0\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logit = model(X)\n",
    "        # Turn predictions from logits -> prediction probabilities -> predictions labels\n",
    "        y_pred = torch.softmax(y_logit, dim=1).argmax(dim=1)\n",
    "        # Put predictions on CPU for evaluation\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_labels.append(y.cpu())\n",
    "        \n",
    "        #other metrics\n",
    "        test_acc += ((y_pred == y).sum().item()/len(y_pred))\n",
    "        y_pred_class = y_pred.detach().cpu().numpy() \n",
    "        y_class = y.detach().cpu().numpy()\n",
    "        test_precision += precision_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        test_recall += recall_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        #test_f1_score += f1_score(y_class, y_pred_class, average='macro', zero_division=1, labels=labels)\n",
    "        \n",
    "        #if count >= 1:\n",
    "        #    y_set = torch.cat((y_set, y))\n",
    "        #    count = count + 1\n",
    "        #else:\n",
    "        #    y_set = y\n",
    "        #    count = count + 1\n",
    "        \n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_precision = test_precision / len(test_dataloader)\n",
    "test_recall = test_recall / len(test_dataloader)\n",
    "#test_f1_score = test_f1_score / len(test_dataloader)\n",
    "#test_kappa = test_kappa / len(dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "# Concatenate list of predictions into a tensor\n",
    "y_pred_tensor = torch.cat(y_preds)\n",
    "test_f1_score = f1_score(y_set.detach().cpu().numpy(), y_pred_tensor.cpu().numpy(), average='macro', zero_division=0, labels=[0,1,2])\n",
    "\n",
    "# Print classification report\n",
    "y_true = y_set.detach().cpu().numpy()\n",
    "report = classification_report(y_true, y_pred_tensor.cpu().numpy(), target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ae97fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528680154128826"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ebafd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make = (y_class == y_pred_class)\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f8aa759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(y_logit, dim=1).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f90a54b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a806154",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (y_pred == y).sum().item()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1da35c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1eb246e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_pred_class = y_pred.detach().cpu().numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "602e096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1af09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
